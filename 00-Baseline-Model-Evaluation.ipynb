{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"0-Baseline-Model-Evaluation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOJZRPDb0xLC4gW9O+wSSFx"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_uPkLIlOsBRT"},"source":["# Evaluating baseline models\n","* __Objective__: Evaluating the models described in the paper _Before Name-calling: Dynamics and Triggers of Ad Hominem Fallacies in Web Argumentation_ using same methods as descirbed in the paper to check the consistency of the results\n","* __Functionalities__: Allows evalauting baseline models \n","* __File Manager__: Google Drive\n","* __Runtime Type__: GPU\n","* __Notes__: To run this notebook, uncomment `line:268` and comment `line:269` in [this](https://github.com/utkarsh512/Ad-hominem-fallacies/blob/master/experiments/classification_experiments.py) script"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuvQ2wQYou73","executionInfo":{"status":"ok","timestamp":1615640605405,"user_tz":-330,"elapsed":63199,"user":{"displayName":"Utkarsh Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4WnjwP-2YGoFk8O-jMTl4jmo7YjKJ6PEf7WDUbw=s64","userId":"14292413845157007490"}},"outputId":"ffcdd5eb-2f60-4b61-9433-5e7fb83bb01c"},"source":["# mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_q4VXdX1o5p7","executionInfo":{"status":"ok","timestamp":1615645523004,"user_tz":-330,"elapsed":37277,"user":{"displayName":"Utkarsh Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4WnjwP-2YGoFk8O-jMTl4jmo7YjKJ6PEf7WDUbw=s64","userId":"14292413845157007490"}},"outputId":"e89ac442-5e11-49d4-bb9d-186afae55e2d"},"source":["%%shell\n","cd /content/gdrive/'My Drive'/\n","rm -rf Ad-hominem-fallacies\n","git clone https://github.com/utkarsh512/Ad-hominem-fallacies.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'Ad-hominem-fallacies'...\n","remote: Enumerating objects: 46, done.\u001b[K\n","remote: Counting objects: 100% (46/46), done.\u001b[K\n","remote: Compressing objects: 100% (46/46), done.\u001b[K\n","remote: Total 152 (delta 25), reused 0 (delta 0), pack-reused 106\u001b[K\n","Receiving objects: 100% (152/152), 37.45 MiB | 10.90 MiB/s, done.\n","Resolving deltas: 100% (50/50), done.\n","Checking out files: 100% (77/77), done.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cH8F7I0pINZ","executionInfo":{"status":"ok","timestamp":1615645610358,"user_tz":-330,"elapsed":70637,"user":{"displayName":"Utkarsh Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4WnjwP-2YGoFk8O-jMTl4jmo7YjKJ6PEf7WDUbw=s64","userId":"14292413845157007490"}},"outputId":"e666f55b-843b-4c67-fce6-4aca02fa02b8"},"source":["%%shell\n","cd /content/gdrive/'My Drive'/Ad-hominem-fallacies/experiments\n","pip install virtualenv\n","virtualenv env --python=python3\n","source env/bin/activate\n","pip install lda scipy==1.1.0 nltk==3.2.5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (20.4.2)\n","Requirement already satisfied: appdirs<2,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.4.4)\n","Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (0.3.1)\n","Requirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.0.12)\n","Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.15.0)\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->virtualenv) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->virtualenv) (3.4.1)\n","created virtual environment CPython3.7.10.final.0-64 in 6234ms\n","  creator CPython3Posix(dest=/content/gdrive/My Drive/Ad-hominem-fallacies/experiments/env, clear=False, no_vcs_ignore=False, global=False)\n","  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n","    added seed packages: pip==21.0.1, setuptools==53.0.0, wheel==0.36.2\n","  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator\n","Collecting lda\n","  Using cached lda-2.0.0-cp37-cp37m-manylinux1_x86_64.whl (351 kB)\n","Collecting scipy==1.1.0\n","  Using cached scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n","Collecting nltk==3.2.5\n","  Using cached nltk-3.2.5-py3-none-any.whl\n","Collecting six\n","  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n","Collecting numpy>=1.8.2\n","  Using cached numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n","Collecting pbr<4,>=0.6\n","  Using cached pbr-3.1.1-py2.py3-none-any.whl (99 kB)\n","Installing collected packages: six, pbr, numpy, scipy, nltk, lda\n","Successfully installed lda-2.0.0 nltk-3.2.5 numpy-1.20.1 pbr-3.1.1 scipy-1.1.0 six-1.15.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZoaT5qxTpQ-6","executionInfo":{"status":"ok","timestamp":1615645630874,"user_tz":-330,"elapsed":13328,"user":{"displayName":"Utkarsh Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4WnjwP-2YGoFk8O-jMTl4jmo7YjKJ6PEf7WDUbw=s64","userId":"14292413845157007490"}},"outputId":"d5e8fa93-d894-4690-93ff-af6cd47a29c4"},"source":["%%shell\n","cd /content/gdrive/'My Drive'/Ad-hominem-fallacies/experiments\n","wget https://public.ukp.informatik.tu-darmstadt.de/ih/RedditChangeMyView2017/en-top100k.embeddings.pkl.gz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-13 14:26:57--  https://public.ukp.informatik.tu-darmstadt.de/ih/RedditChangeMyView2017/en-top100k.embeddings.pkl.gz\n","Resolving public.ukp.informatik.tu-darmstadt.de (public.ukp.informatik.tu-darmstadt.de)... 130.83.167.186\n","Connecting to public.ukp.informatik.tu-darmstadt.de (public.ukp.informatik.tu-darmstadt.de)|130.83.167.186|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 152970296 (146M) [application/octet-stream]\n","Saving to: ‘en-top100k.embeddings.pkl.gz’\n","\n","en-top100k.embeddin 100%[===================>] 145.88M  20.1MB/s    in 11s     \n","\n","2021-03-13 14:27:09 (13.1 MB/s) - ‘en-top100k.embeddings.pkl.gz’ saved [152970296/152970296]\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZfs6W5spwPw","executionInfo":{"status":"ok","timestamp":1615645679411,"user_tz":-330,"elapsed":36316,"user":{"displayName":"Utkarsh Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4WnjwP-2YGoFk8O-jMTl4jmo7YjKJ6PEf7WDUbw=s64","userId":"14292413845157007490"}},"outputId":"e88b40bc-88a7-4030-9355-1667aabc2dc4"},"source":["%%shell\n","cd /content/gdrive/'My Drive'/Ad-hominem-fallacies/experiments\n","tar -xvf sampled-threads-ah-delta-context3.tar.bz2 -C data/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sampled-threads-ah-delta-context3/\n","sampled-threads-ah-delta-context3/1213_delta_t1_dm10vxo.json\n","sampled-threads-ah-delta-context3/175_ah_t1_dlqrux0.json\n","sampled-threads-ah-delta-context3/647_ah_t1_cqy072s.json\n","sampled-threads-ah-delta-context3/261_ah_t1_cj87dst.json\n","sampled-threads-ah-delta-context3/134_delta_t1_dmnatwa.json\n","sampled-threads-ah-delta-context3/1070_ah_t1_di63b9y.json\n","sampled-threads-ah-delta-context3/846_ah_t1_cvyhbbh.json\n","sampled-threads-ah-delta-context3/575_delta_t1_cgjh9o2.json\n","sampled-threads-ah-delta-context3/284_ah_t1_d98wq0g.json\n","sampled-threads-ah-delta-context3/473_ah_t1_cjkayyc.json\n","sampled-threads-ah-delta-context3/871_delta_t1_djbfsuw.json\n","sampled-threads-ah-delta-context3/222_ah_t1_dlq9jlp.json\n","sampled-threads-ah-delta-context3/482_ah_t1_clrfkvu.json\n","sampled-threads-ah-delta-context3/1103_delta_t1_dmk47tv.json\n","sampled-threads-ah-delta-context3/821_ah_t1_cyb6qi4.json\n","sampled-threads-ah-delta-context3/157_delta_t1_cz0o1gz.json\n","sampled-threads-ah-delta-context3/280_ah_t1_d1gsg0i.json\n","sampled-threads-ah-delta-context3/1114_delta_t1_dkz6ij7.json\n","sampled-threads-ah-delta-context3/291_ah_t1_cwyfwds.json\n","sampled-threads-ah-delta-context3/551_delta_t1_db37o3u.json\n","sampled-threads-ah-delta-context3/308_ah_t1_d3s6bpa.json\n","sampled-threads-ah-delta-context3/686_delta_t1_cb9q9vz.json\n","sampled-threads-ah-delta-context3/64_ah_t1_dn7v1d2.json\n","sampled-threads-ah-delta-context3/792_ah_t1_dmfebte.json\n","sampled-threads-ah-delta-context3/865_ah_t1_cqyjpel.json\n","sampled-threads-ah-delta-context3/1117_ah_t1_d02r5f8.json\n","sampled-threads-ah-delta-context3/6_delta_t1_cu9omp7.json\n","sampled-threads-ah-delta-context3/315_ah_t1_d9vuw2p.json\n","sampled-threads-ah-delta-context3/1033_ah_t1_df80y7e.json\n","sampled-threads-ah-delta-context3/963_ah_t1_daw0128.json\n","sampled-threads-ah-delta-context3/195_delta_t1_crcwhyd.json\n","sampled-threads-ah-delta-context3/571_delta_t1_cc0e6s0.json\n","sampled-threads-ah-delta-context3/72_delta_t1_d17ilya.json\n","sampled-threads-ah-delta-context3/1089_delta_t1_dgadf90.json\n","sampled-threads-ah-delta-context3/564_delta_t1_cjwb0qb.json\n","sampled-threads-ah-delta-context3/408_ah_t1_dc201wj.json\n","sampled-threads-ah-delta-context3/86_ah_t1_d4m70l7.json\n","sampled-threads-ah-delta-context3/622_delta_t1_cki8rm6.json\n","sampled-threads-ah-delta-context3/157_ah_t1_cudvgcn.json\n","sampled-threads-ah-delta-context3/728_delta_t1_czikipe.json\n","sampled-threads-ah-delta-context3/1278_ah_t1_djte9xq.json\n","sampled-threads-ah-delta-context3/149_ah_t1_dcyi8ch.json\n","sampled-threads-ah-delta-context3/779_ah_t1_dl66hcq.json\n","sampled-threads-ah-delta-context3/506_ah_t1_d492xor.json\n","sampled-threads-ah-delta-context3/1277_ah_t1_dbt581e.json\n","sampled-threads-ah-delta-context3/343_ah_t1_djoctg3.json\n","sampled-threads-ah-delta-context3/1166_delta_t1_csrd67y.json\n","sampled-threads-ah-delta-context3/125_ah_t1_czgyvma.json\n","sampled-threads-ah-delta-context3/744_delta_t1_dlamoay.json\n","sampled-threads-ah-delta-context3/133_delta_t1_cpistdp.json\n","sampled-threads-ah-delta-context3/479_ah_t1_dk80cue.json\n","sampled-threads-ah-delta-context3/648_ah_t1_cko83bl.json\n","sampled-threads-ah-delta-context3/312_ah_t1_d2h9m8y.json\n","sampled-threads-ah-delta-context3/1203_ah_t1_dk13p85.json\n","sampled-threads-ah-delta-context3/457_ah_t1_dhdlxij.json\n","sampled-threads-ah-delta-context3/515_ah_t1_djpfbva.json\n","sampled-threads-ah-delta-context3/903_delta_t1_d8rl4e6.json\n","sampled-threads-ah-delta-context3/304_ah_t1_df2e66e.json\n","sampled-threads-ah-delta-context3/597_ah_t1_d76rmcd.json\n","sampled-threads-ah-delta-context3/224_delta_t1_cx2pp2o.json\n","sampled-threads-ah-delta-context3/47_delta_t1_crwte9c.json\n","sampled-threads-ah-delta-context3/228_ah_t1_d6q2dh8.json\n","sampled-threads-ah-delta-context3/659_delta_t1_chwzf6f.json\n","sampled-threads-ah-delta-context3/80_ah_t1_de92cak.json\n","sampled-threads-ah-delta-context3/872_delta_t1_ctsvyic.json\n","sampled-threads-ah-delta-context3/95_ah_t1_cokvmf9.json\n","sampled-threads-ah-delta-context3/914_delta_t1_d8lvw0x.json\n","sampled-threads-ah-delta-context3/355_ah_t1_d6txh2j.json\n","sampled-threads-ah-delta-context3/624_delta_t1_cvcpdrv.json\n","sampled-threads-ah-delta-context3/244_ah_t1_dheb883.json\n","sampled-threads-ah-delta-context3/84_ah_t1_ctj6vu5.json\n","sampled-threads-ah-delta-context3/293_ah_t1_d4svrgf.json\n","sampled-threads-ah-delta-context3/1286_delta_t1_d0coqrn.json\n","sampled-threads-ah-delta-context3/68_delta_t1_dcrd6ok.json\n","sampled-threads-ah-delta-context3/313_delta_t1_d9546fg.json\n","sampled-threads-ah-delta-context3/1219_ah_t1_d7udasc.json\n","sampled-threads-ah-delta-context3/512_ah_t1_dgam2z6.json\n","sampled-threads-ah-delta-context3/359_ah_t1_dm8a3y7.json\n","sampled-threads-ah-delta-context3/1032_delta_t1_czs2iah.json\n","sampled-threads-ah-delta-context3/573_ah_t1_d2oy658.json\n","sampled-threads-ah-delta-context3/757_ah_t1_d85pb3o.json\n","sampled-threads-ah-delta-context3/504_delta_t1_d1v9ws5.json\n","sampled-threads-ah-delta-context3/635_ah_t1_dfpi0p2.json\n","sampled-threads-ah-delta-context3/125_delta_t1_dgt5p70.json\n","sampled-threads-ah-delta-context3/1049_ah_t1_diar98q.json\n","sampled-threads-ah-delta-context3/1194_delta_t1_cq4aus6.json\n","sampled-threads-ah-delta-context3/1283_ah_t1_d5nm2se.json\n","sampled-threads-ah-delta-context3/716_delta_t1_cn4sadr.json\n","sampled-threads-ah-delta-context3/1075_delta_t1_djxdr9q.json\n","sampled-threads-ah-delta-context3/977_delta_t1_cxecen3.json\n","sampled-threads-ah-delta-context3/682_ah_t1_cleydoe.json\n","sampled-threads-ah-delta-context3/1084_delta_t1_cmw6gyp.json\n","sampled-threads-ah-delta-context3/554_ah_t1_csawwmw.json\n","sampled-threads-ah-delta-context3/1165_delta_t1_cqj0vbp.json\n","sampled-threads-ah-delta-context3/656_ah_t1_ckdrhqa.json\n","sampled-threads-ah-delta-context3/444_delta_t1_dlbwt1v.json\n","sampled-threads-ah-delta-context3/829_delta_t1_d44ggl8.json\n","sampled-threads-ah-delta-context3/1105_delta_t1_d7gbf0g.json\n","sampled-threads-ah-delta-context3/955_delta_t1_dhpd9eu.json\n","sampled-threads-ah-delta-context3/671_delta_t1_cija7k4.json\n","sampled-threads-ah-delta-context3/837_delta_t1_crneckx.json\n","sampled-threads-ah-delta-context3/235_delta_t1_devpybq.json\n","sampled-threads-ah-delta-context3/268_delta_t1_cuw1coi.json\n","sampled-threads-ah-delta-context3/648_delta_t1_dchm67f.json\n","sampled-threads-ah-delta-context3/700_delta_t1_daxhogh.json\n","sampled-threads-ah-delta-context3/623_delta_t1_ce5rcps.json\n","sampled-threads-ah-delta-context3/658_ah_t1_cq5ifqi.json\n","sampled-threads-ah-delta-context3/612_delta_t1_cto5mir.json\n","sampled-threads-ah-delta-context3/1143_delta_t1_cunwpo4.json\n","sampled-threads-ah-delta-context3/670_delta_t1_chkrx9q.json\n","sampled-threads-ah-delta-context3/441_delta_t1_cnannue.json\n","sampled-threads-ah-delta-context3/222_delta_t1_dfamxt5.json\n","sampled-threads-ah-delta-context3/1058_delta_t1_d2r96wh.json\n","sampled-threads-ah-delta-context3/1248_delta_t1_dbw9va1.json\n","sampled-threads-ah-delta-context3/128_delta_t1_cgmuhbv.json\n","sampled-threads-ah-delta-context3/398_ah_t1_cknsdsm.json\n","sampled-threads-ah-delta-context3/1168_delta_t1_dm2gisq.json\n","sampled-threads-ah-delta-context3/854_ah_t1_d7i8wbm.json\n","sampled-threads-ah-delta-context3/1249_delta_t1_cw0xsa5.json\n","sampled-threads-ah-delta-context3/511_delta_t1_d22ljd9.json\n","sampled-threads-ah-delta-context3/986_delta_t1_cc7v1at.json\n","sampled-threads-ah-delta-context3/892_ah_t1_dcv5pki.json\n","sampled-threads-ah-delta-context3/496_delta_t1_cus34g7.json\n","sampled-threads-ah-delta-context3/744_ah_t1_cy2g15y.json\n","sampled-threads-ah-delta-context3/531_ah_t1_dg14gvn.json\n","sampled-threads-ah-delta-context3/165_ah_t1_cwlyywd.json\n","sampled-threads-ah-delta-context3/1225_delta_t1_df3p9ng.json\n","sampled-threads-ah-delta-context3/1187_ah_t1_d7bvbh7.json\n","sampled-threads-ah-delta-context3/488_delta_t1_ddl2duw.json\n","sampled-threads-ah-delta-context3/318_ah_t1_cytpz6n.json\n","sampled-threads-ah-delta-context3/316_delta_t1_dgytu22.json\n","sampled-threads-ah-delta-context3/831_ah_t1_d7nmy27.json\n","sampled-threads-ah-delta-context3/1287_ah_t1_cjnfj27.json\n","sampled-threads-ah-delta-context3/1284_delta_t1_dingeqw.json\n","sampled-threads-ah-delta-context3/576_ah_t1_db92lfx.json\n","sampled-threads-ah-delta-context3/862_delta_t1_d6w1cvg.json\n","sampled-threads-ah-delta-context3/347_delta_t1_dj439gn.json\n","sampled-threads-ah-delta-context3/1114_ah_t1_delxf3h.json\n","sampled-threads-ah-delta-context3/16_ah_t1_dk6lp55.json\n","sampled-threads-ah-delta-context3/592_ah_t1_dgpqqbn.json\n","sampled-threads-ah-delta-context3/732_ah_t1_cx8wd21.json\n","sampled-threads-ah-delta-context3/251_ah_t1_deavyif.json\n","sampled-threads-ah-delta-context3/214_ah_t1_ck8f23e.json\n","sampled-threads-ah-delta-context3/654_delta_t1_cpar23c.json\n","sampled-threads-ah-delta-context3/649_ah_t1_cqmoq70.json\n","sampled-threads-ah-delta-context3/344_delta_t1_ccdj11i.json\n","sampled-threads-ah-delta-context3/180_ah_t1_cj6w1nh.json\n","sampled-threads-ah-delta-context3/365_delta_t1_crodlyd.json\n","sampled-threads-ah-delta-context3/782_delta_t1_cyciv7n.json\n","sampled-threads-ah-delta-context3/1084_ah_t1_cscvq2n.json\n","sampled-threads-ah-delta-context3/451_delta_t1_cyxb1p8.json\n","sampled-threads-ah-delta-context3/97_delta_t1_cvtswhx.json\n","sampled-threads-ah-delta-context3/201_delta_t1_clnnn7w.json\n","sampled-threads-ah-delta-context3/35_delta_t1_cjmiqg3.json\n","sampled-threads-ah-delta-context3/720_ah_t1_dk50zlh.json\n","sampled-threads-ah-delta-context3/1192_ah_t1_dawnmse.json\n","sampled-threads-ah-delta-context3/1021_delta_t1_clkve20.json\n","sampled-threads-ah-delta-context3/472_delta_t1_comrhp4.json\n","sampled-threads-ah-delta-context3/711_delta_t1_cybdi0o.json\n","sampled-threads-ah-delta-context3/795_ah_t1_dmxkj7g.json\n","sampled-threads-ah-delta-context3/1095_delta_t1_d3lmtyu.json\n","sampled-threads-ah-delta-context3/21_delta_t1_ccvg7zq.json\n","sampled-threads-ah-delta-context3/799_delta_t1_cu0q2kb.json\n","sampled-threads-ah-delta-context3/420_delta_t1_diuyyf8.json\n","sampled-threads-ah-delta-context3/598_delta_t1_d08xrmh.json\n","sampled-threads-ah-delta-context3/855_ah_t1_dmwg8w7.json\n","sampled-threads-ah-delta-context3/1271_delta_t1_d9zxciv.json\n","sampled-threads-ah-delta-context3/1030_delta_t1_d6t6txv.json\n","sampled-threads-ah-delta-context3/445_ah_t1_dn66fpv.json\n","sampled-threads-ah-delta-context3/1042_ah_t1_ctsjghr.json\n","sampled-threads-ah-delta-context3/686_ah_t1_dhl4m4b.json\n","sampled-threads-ah-delta-context3/924_ah_t1_d1k52dg.json\n","sampled-threads-ah-delta-context3/121_ah_t1_dlmn3i0.json\n","sampled-threads-ah-delta-context3/618_delta_t1_dec70l5.json\n","sampled-threads-ah-delta-context3/946_delta_t1_cqu1g26.json\n","sampled-threads-ah-delta-context3/1188_ah_t1_dlfasez.json\n","sampled-threads-ah-delta-context3/1261_ah_t1_cxrpg8d.json\n","sampled-threads-ah-delta-context3/1152_delta_t1_cipaycb.json\n","sampled-threads-ah-delta-context3/281_delta_t1_ctzu8nt.json\n","sampled-threads-ah-delta-context3/405_ah_t1_dizg8c6.json\n","sampled-threads-ah-delta-context3/1004_delta_t1_djfur1e.json\n","sampled-threads-ah-delta-context3/870_delta_t1_ddnvy1w.json\n","sampled-threads-ah-delta-context3/362_ah_t1_cw1ad31.json\n","sampled-threads-ah-delta-context3/498_delta_t1_cazyax0.json\n","sampled-threads-ah-delta-context3/907_ah_t1_db8m111.json\n","sampled-threads-ah-delta-context3/1120_ah_t1_d871ydm.json\n","sampled-threads-ah-delta-context3/256_ah_t1_ckcql6j.json\n","sampled-threads-ah-delta-context3/1_delta_t1_cu24il3.json\n","sampled-threads-ah-delta-context3/1253_delta_t1_dbomjii.json\n","sampled-threads-ah-delta-context3/666_ah_t1_dg8y4i9.json\n","sampled-threads-ah-delta-context3/94_ah_t1_cj878fx.json\n","sampled-threads-ah-delta-context3/925_ah_t1_czhozxn.json\n","sampled-threads-ah-delta-context3/778_ah_t1_d3eeop9.json\n","sampled-threads-ah-delta-context3/1069_ah_t1_dkhyzzy.json\n","sampled-threads-ah-delta-context3/306_ah_t1_cno24ka.json\n","sampled-threads-ah-delta-context3/1270_ah_t1_d276ao7.json\n","sampled-threads-ah-delta-context3/543_delta_t1_d2ya52f.json\n","sampled-threads-ah-delta-context3/253_delta_t1_dirjv3p.json\n","sampled-threads-ah-delta-context3/174_delta_t1_cxuwwcb.json\n","sampled-threads-ah-delta-context3/557_delta_t1_cj6rcn4.json\n","sampled-threads-ah-delta-context3/594_delta_t1_cha53z6.json\n","sampled-threads-ah-delta-context3/263_ah_t1_dn9m609.json\n","sampled-threads-ah-delta-context3/156_ah_t1_ddgk00n.json\n","sampled-threads-ah-delta-context3/904_ah_t1_d1ui1cn.json\n","sampled-threads-ah-delta-context3/1055_ah_t1_d51p7aj.json\n","sampled-threads-ah-delta-context3/741_ah_t1_cwjj646.json\n","sampled-threads-ah-delta-context3/672_ah_t1_cu00gxz.json\n","sampled-threads-ah-delta-context3/265_delta_t1_d6lcbrw.json\n","sampled-threads-ah-delta-context3/246_ah_t1_dmitgvo.json\n","sampled-threads-ah-delta-context3/410_delta_t1_d6bw96k.json\n","sampled-threads-ah-delta-context3/62_delta_t1_dhorh6d.json\n","sampled-threads-ah-delta-context3/392_ah_t1_dmslul5.json\n","sampled-threads-ah-delta-context3/414_ah_t1_d9pmjhv.json\n","sampled-threads-ah-delta-context3/1144_delta_t1_chimu8l.json\n","sampled-threads-ah-delta-context3/844_ah_t1_d11zgc1.json\n","sampled-threads-ah-delta-context3/690_delta_t1_dava3wf.json\n","sampled-threads-ah-delta-context3/1111_ah_t1_d8lkian.json\n","sampled-threads-ah-delta-context3/552_delta_t1_ci8xxkj.json\n","sampled-threads-ah-delta-context3/912_ah_t1_dizyld7.json\n","sampled-threads-ah-delta-context3/948_delta_t1_cejeb6k.json\n","sampled-threads-ah-delta-context3/528_ah_t1_cl4rdny.json\n","sampled-threads-ah-delta-context3/323_delta_t1_d2mfiiw.json\n","sampled-threads-ah-delta-context3/734_ah_t1_cw6ac77.json\n","sampled-threads-ah-delta-context3/320_ah_t1_czfqvm2.json\n","sampled-threads-ah-delta-context3/1086_delta_t1_d4nvshd.json\n","sampled-threads-ah-delta-context3/713_delta_t1_cp0nvxh.json\n","sampled-threads-ah-delta-context3/1023_delta_t1_cfkdeqd.json\n","sampled-threads-ah-delta-context3/185_delta_t1_cgd7j7b.json\n","sampled-threads-ah-delta-context3/797_ah_t1_dlj9akx.json\n","sampled-threads-ah-delta-context3/1288_delta_t1_cx66p2u.json\n","sampled-threads-ah-delta-context3/754_delta_t1_cigbh1n.json\n","sampled-threads-ah-delta-context3/6_ah_t1_damekm5.json\n","sampled-threads-ah-delta-context3/427_delta_t1_cdmfniv.json\n","sampled-threads-ah-delta-context3/1237_ah_t1_ct1ar79.json\n","sampled-threads-ah-delta-context3/440_ah_t1_cosqnmg.json\n","sampled-threads-ah-delta-context3/339_delta_t1_cj6sflw.json\n","sampled-threads-ah-delta-context3/348_ah_t1_cwq21ns.json\n","sampled-threads-ah-delta-context3/152_delta_t1_dh1pt8r.json\n","sampled-threads-ah-delta-context3/1125_ah_t1_dmikagc.json\n","sampled-threads-ah-delta-context3/288_delta_t1_df4y3uw.json\n","sampled-threads-ah-delta-context3/908_ah_t1_dek9cze.json\n","sampled-threads-ah-delta-context3/435_ah_t1_csjrhv2.json\n","sampled-threads-ah-delta-context3/727_delta_t1_cf3217k.json\n","sampled-threads-ah-delta-context3/490_delta_t1_cec9js6.json\n","sampled-threads-ah-delta-context3/719_ah_t1_d2akid1.json\n","sampled-threads-ah-delta-context3/802_ah_t1_d7azjns.json\n","sampled-threads-ah-delta-context3/888_delta_t1_clacirn.json\n","sampled-threads-ah-delta-context3/759_ah_t1_ddxy48x.json\n","sampled-threads-ah-delta-context3/216_ah_t1_dfxkl86.json\n","sampled-threads-ah-delta-context3/562_delta_t1_cmbg67o.json\n","sampled-threads-ah-delta-context3/60_ah_t1_d8n86w7.json\n","sampled-threads-ah-delta-context3/293_delta_t1_dgnqlcu.json\n","sampled-threads-ah-delta-context3/244_delta_t1_ctprx6e.json\n","sampled-threads-ah-delta-context3/617_delta_t1_cqfjq4h.json\n","sampled-threads-ah-delta-context3/809_delta_t1_cobhakm.json\n","sampled-threads-ah-delta-context3/20_ah_t1_d2tr7sn.json\n","sampled-threads-ah-delta-context3/640_ah_t1_d54a12a.json\n","sampled-threads-ah-delta-context3/307_ah_t1_d2cdqz8.json\n","sampled-threads-ah-delta-context3/240_delta_t1_d4ecx56.json\n","sampled-threads-ah-delta-context3/664_ah_t1_d3dvlu6.json\n","sampled-threads-ah-delta-context3/259_ah_t1_defvdne.json\n","sampled-threads-ah-delta-context3/336_ah_t1_dlcfehx.json\n","sampled-threads-ah-delta-context3/747_ah_t1_d6rmxmu.json\n","sampled-threads-ah-delta-context3/490_ah_t1_dmhu8eu.json\n","sampled-threads-ah-delta-context3/961_delta_t1_cfb7qi8.json\n","sampled-threads-ah-delta-context3/1208_ah_t1_dggxbat.json\n","sampled-threads-ah-delta-context3/1290_ah_t1_djhwlwz.json\n","sampled-threads-ah-delta-context3/618_ah_t1_d9bnttn.json\n","sampled-threads-ah-delta-context3/621_ah_t1_ctsnska.json\n","sampled-threads-ah-delta-context3/944_ah_t1_dd9lpvz.json\n","sampled-threads-ah-delta-context3/1208_delta_t1_cgxq4g9.json\n","sampled-threads-ah-delta-context3/803_ah_t1_d5uis62.json\n","sampled-threads-ah-delta-context3/174_ah_t1_cj990f1.json\n","sampled-threads-ah-delta-context3/507_delta_t1_ctl27gu.json\n","sampled-threads-ah-delta-context3/1002_ah_t1_d1w9bwk.json\n","sampled-threads-ah-delta-context3/1211_ah_t1_d7c6m08.json\n","sampled-threads-ah-delta-context3/1051_delta_t1_cioevt6.json\n","sampled-threads-ah-delta-context3/731_ah_t1_d9w67nx.json\n","sampled-threads-ah-delta-context3/846_delta_t1_d9v08nj.json\n","sampled-threads-ah-delta-context3/365_ah_t1_cliz7kc.json\n","sampled-threads-ah-delta-context3/103_delta_t1_d1golfl.json\n","sampled-threads-ah-delta-context3/565_delta_t1_camqket.json\n","sampled-threads-ah-delta-context3/289_ah_t1_d4xwguy.json\n","sampled-threads-ah-delta-context3/523_ah_t1_ddzceh8.json\n","sampled-threads-ah-delta-context3/1022_delta_t1_dalj8k8.json\n","sampled-threads-ah-delta-context3/945_ah_t1_d0wjen4.json\n","sampled-threads-ah-delta-context3/151_ah_t1_ckj35zz.json\n","sampled-threads-ah-delta-context3/1082_ah_t1_dbpvfyl.json\n","sampled-threads-ah-delta-context3/579_delta_t1_crmwjn4.json\n","sampled-threads-ah-delta-context3/86_delta_t1_djz0eep.json\n","sampled-threads-ah-delta-context3/343_delta_t1_ctx8v7k.json\n","sampled-threads-ah-delta-context3/1110_ah_t1_dl40wzj.json\n","sampled-threads-ah-delta-context3/42_ah_t1_ck3z2za.json\n","sampled-threads-ah-delta-context3/73_ah_t1_djzy50v.json\n","sampled-threads-ah-delta-context3/590_delta_t1_d177bp1.json\n","sampled-threads-ah-delta-context3/418_ah_t1_crdk8bu.json\n","sampled-threads-ah-delta-context3/428_delta_t1_d2g0ycd.json\n","sampled-threads-ah-delta-context3/289_delta_t1_dd71fai.json\n","sampled-threads-ah-delta-context3/691_ah_t1_dhiu57t.json\n","sampled-threads-ah-delta-context3/186_ah_t1_dktcro6.json\n","sampled-threads-ah-delta-context3/76_delta_t1_cy7htto.json\n","sampled-threads-ah-delta-context3/777_delta_t1_csyxqkl.json\n","sampled-threads-ah-delta-context3/265_ah_t1_csfkbul.json\n","sampled-threads-ah-delta-context3/408_delta_t1_d13rojy.json\n","sampled-threads-ah-delta-context3/1017_ah_t1_dmcg1a0.json\n","sampled-threads-ah-delta-context3/233_delta_t1_cgiw03g.json\n","sampled-threads-ah-delta-context3/721_ah_t1_cztoz4x.json\n","sampled-threads-ah-delta-context3/957_ah_t1_d5t08b8.json\n","sampled-threads-ah-delta-context3/478_ah_t1_d9kss42.json\n","sampled-threads-ah-delta-context3/105_delta_t1_dhlbof1.json\n","sampled-threads-ah-delta-context3/126_delta_t1_cgo1bnm.json\n","sampled-threads-ah-delta-context3/29_ah_t1_d3n8z22.json\n","sampled-threads-ah-delta-context3/1252_ah_t1_d03dn3y.json\n","sampled-threads-ah-delta-context3/1111_delta_t1_cbjjzio.json\n","sampled-threads-ah-delta-context3/384_ah_t1_czc73ey.json\n","sampled-threads-ah-delta-context3/1259_delta_t1_ce47z6l.json\n","sampled-threads-ah-delta-context3/967_delta_t1_cmzllm8.json\n","sampled-threads-ah-delta-context3/212_ah_t1_dl0tfy6.json\n","sampled-threads-ah-delta-context3/527_ah_t1_czd3b6u.json\n","sampled-threads-ah-delta-context3/1280_ah_t1_d6erg9b.json\n","sampled-threads-ah-delta-context3/236_ah_t1_davdrzd.json\n","sampled-threads-ah-delta-context3/195_ah_t1_djntjib.json\n","sampled-threads-ah-delta-context3/713_ah_t1_ddwnbvz.json\n","sampled-threads-ah-delta-context3/848_ah_t1_d7dg2jm.json\n","sampled-threads-ah-delta-context3/981_delta_t1_cuh5hbx.json\n","sampled-threads-ah-delta-context3/516_delta_t1_ddnlnj6.json\n","sampled-threads-ah-delta-context3/839_ah_t1_ddkr9ji.json\n","sampled-threads-ah-delta-context3/1290_delta_t1_dhvx7m0.json\n","sampled-threads-ah-delta-context3/790_delta_t1_ddjpllf.json\n","sampled-threads-ah-delta-context3/1041_delta_t1_cqmx0uc.json\n","sampled-threads-ah-delta-context3/341_ah_t1_dn5wm4i.json\n","sampled-threads-ah-delta-context3/146_ah_t1_cvfak11.json\n","sampled-threads-ah-delta-context3/1278_delta_t1_diwxgs7.json\n","sampled-threads-ah-delta-context3/178_delta_t1_dlovba7.json\n","sampled-threads-ah-delta-context3/922_delta_t1_dfecdat.json\n","sampled-threads-ah-delta-context3/241_delta_t1_cc6m6dq.json\n","sampled-threads-ah-delta-context3/25_ah_t1_cwnumdy.json\n","sampled-threads-ah-delta-context3/306_delta_t1_dkr427h.json\n","sampled-threads-ah-delta-context3/546_ah_t1_de9zu5i.json\n","sampled-threads-ah-delta-context3/493_ah_t1_dlrh3cc.json\n","sampled-threads-ah-delta-context3/947_delta_t1_d4ruy8f.json\n","sampled-threads-ah-delta-context3/276_ah_t1_cqe9qr3.json\n","sampled-threads-ah-delta-context3/906_ah_t1_cu61w9m.json\n","sampled-threads-ah-delta-context3/421_ah_t1_dbeed4l.json\n","sampled-threads-ah-delta-context3/505_ah_t1_cou6uj1.json\n","sampled-threads-ah-delta-context3/736_ah_t1_dmnmfcg.json\n","sampled-threads-ah-delta-context3/637_ah_t1_czdlyxa.json\n","sampled-threads-ah-delta-context3/336_delta_t1_ceo1uyt.json\n","sampled-threads-ah-delta-context3/266_ah_t1_cjx4evh.json\n","sampled-threads-ah-delta-context3/920_delta_t1_deyknda.json\n","sampled-threads-ah-delta-context3/227_delta_t1_chxihg3.json\n","sampled-threads-ah-delta-context3/271_ah_t1_cw9odwx.json\n","sampled-threads-ah-delta-context3/1098_delta_t1_dksnahj.json\n","sampled-threads-ah-delta-context3/536_ah_t1_d86rj6d.json\n","sampled-threads-ah-delta-context3/1106_delta_t1_cwxv1yf.json\n","sampled-threads-ah-delta-context3/698_delta_t1_d6rukxf.json\n","sampled-threads-ah-delta-context3/144_ah_t1_dav3f1b.json\n","sampled-threads-ah-delta-context3/560_ah_t1_cjme4qv.json\n","sampled-threads-ah-delta-context3/119_ah_t1_dbcpvfs.json\n","sampled-threads-ah-delta-context3/1189_delta_t1_datbmt3.json\n","sampled-threads-ah-delta-context3/629_ah_t1_d5yi2y1.json\n","sampled-threads-ah-delta-context3/194_delta_t1_cld101l.json\n","sampled-threads-ah-delta-context3/877_ah_t1_d3qymq1.json\n","sampled-threads-ah-delta-context3/1045_delta_t1_cgd84zz.json\n","sampled-threads-ah-delta-context3/890_delta_t1_ccwl01b.json\n","sampled-threads-ah-delta-context3/1009_delta_t1_ck87n8v.json\n","sampled-threads-ah-delta-context3/1220_delta_t1_de4p2b6.json\n","sampled-threads-ah-delta-context3/449_ah_t1_d5t18nx.json\n","sampled-threads-ah-delta-context3/775_ah_t1_cxbk1br.json\n","sampled-threads-ah-delta-context3/956_ah_t1_dmzwdhv.json\n","sampled-threads-ah-delta-context3/641_ah_t1_d0vwkyn.json\n","sampled-threads-ah-delta-context3/595_ah_t1_d78n35e.json\n","sampled-threads-ah-delta-context3/693_delta_t1_ceo3bj1.json\n","sampled-threads-ah-delta-context3/1265_ah_t1_cu60rnu.json\n","sampled-threads-ah-delta-context3/900_ah_t1_daejbih.json\n","sampled-threads-ah-delta-context3/568_ah_t1_cji308v.json\n","sampled-threads-ah-delta-context3/989_delta_t1_cqoduo4.json\n","sampled-threads-ah-delta-context3/722_ah_t1_dbmbal4.json\n","sampled-threads-ah-delta-context3/1182_delta_t1_ck1zate.json\n","sampled-threads-ah-delta-context3/290_delta_t1_ch0daf9.json\n","sampled-threads-ah-delta-context3/103_ah_t1_djnkv8a.json\n","sampled-threads-ah-delta-context3/929_delta_t1_ci1h8fz.json\n","sampled-threads-ah-delta-context3/1116_ah_t1_d2jlx2g.json\n","sampled-threads-ah-delta-context3/707_ah_t1_dewnwx7.json\n","sampled-threads-ah-delta-context3/1161_ah_t1_dm7bb2e.json\n","sampled-threads-ah-delta-context3/1059_ah_t1_djgbe7k.json\n","sampled-threads-ah-delta-context3/406_ah_t1_dk1o4x7.json\n","sampled-threads-ah-delta-context3/1219_delta_t1_d4ih9oq.json\n","sampled-threads-ah-delta-context3/1246_ah_t1_cne25ec.json\n","sampled-threads-ah-delta-context3/215_ah_t1_djfr8pe.json\n","sampled-threads-ah-delta-context3/332_delta_t1_djvb3hx.json\n","sampled-threads-ah-delta-context3/667_delta_t1_dm7v2pj.json\n","sampled-threads-ah-delta-context3/1130_ah_t1_dkznx2h.json\n","sampled-threads-ah-delta-context3/977_ah_t1_clhcn8b.json\n","sampled-threads-ah-delta-context3/950_delta_t1_cao6v11.json\n","sampled-threads-ah-delta-context3/715_delta_t1_cmbfvhj.json\n","sampled-threads-ah-delta-context3/311_delta_t1_ctkb4wy.json\n","sampled-threads-ah-delta-context3/849_ah_t1_cuk6pm7.json\n","sampled-threads-ah-delta-context3/335_delta_t1_caqtsq2.json\n","sampled-threads-ah-delta-context3/220_delta_t1_cwnb98d.json\n","sampled-threads-ah-delta-context3/1119_ah_t1_ctj8eo2.json\n","sampled-threads-ah-delta-context3/255_delta_t1_dlq2ts4.json\n","sampled-threads-ah-delta-context3/325_delta_t1_dm3ru09.json\n","sampled-threads-ah-delta-context3/138_delta_t1_cg5dqyq.json\n","sampled-threads-ah-delta-context3/603_ah_t1_cw49q4i.json\n","sampled-threads-ah-delta-context3/516_ah_t1_cut7ase.json\n","sampled-threads-ah-delta-context3/1044_delta_t1_ccxncje.json\n","sampled-threads-ah-delta-context3/1180_delta_t1_d6yypr9.json\n","sampled-threads-ah-delta-context3/1027_ah_t1_d5n01h6.json\n","sampled-threads-ah-delta-context3/949_delta_t1_clccj3q.json\n","sampled-threads-ah-delta-context3/1210_delta_t1_dfm78jr.json\n","sampled-threads-ah-delta-context3/963_delta_t1_clabvl3.json\n","sampled-threads-ah-delta-context3/473_delta_t1_ckcsvcb.json\n","sampled-threads-ah-delta-context3/1096_ah_t1_ct4adkd.json\n","sampled-threads-ah-delta-context3/30_ah_t1_daemhr3.json\n","sampled-threads-ah-delta-context3/882_ah_t1_d311xsf.json\n","sampled-threads-ah-delta-context3/299_ah_t1_czl8nft.json\n","sampled-threads-ah-delta-context3/965_ah_t1_con2du5.json\n","sampled-threads-ah-delta-context3/910_ah_t1_cjiqwj3.json\n","sampled-threads-ah-delta-context3/372_ah_t1_cizdy3e.json\n","sampled-threads-ah-delta-context3/1181_delta_t1_cugf2po.json\n","sampled-threads-ah-delta-context3/1237_delta_t1_dgfxbzu.json\n","sampled-threads-ah-delta-context3/543_ah_t1_dk5z3so.json\n","sampled-threads-ah-delta-context3/857_ah_t1_d49xta3.json\n","sampled-threads-ah-delta-context3/636_ah_t1_dffdc5v.json\n","sampled-threads-ah-delta-context3/1109_delta_t1_cte1akc.json\n","sampled-threads-ah-delta-context3/1215_delta_t1_dkz96nw.json\n","sampled-threads-ah-delta-context3/354_delta_t1_dkzfmqk.json\n","sampled-threads-ah-delta-context3/46_delta_t1_csah2cy.json\n","sampled-threads-ah-delta-context3/1105_ah_t1_d26gkkb.json\n","sampled-threads-ah-delta-context3/852_delta_t1_crfegvw.json\n","sampled-threads-ah-delta-context3/359_delta_t1_dhv9pji.json\n","sampled-threads-ah-delta-context3/631_ah_t1_dbz1fei.json\n","sampled-threads-ah-delta-context3/929_ah_t1_d3wc4ut.json\n","sampled-threads-ah-delta-context3/539_delta_t1_dbb7piq.json\n","sampled-threads-ah-delta-context3/1051_ah_t1_d2tsxmm.json\n","sampled-threads-ah-delta-context3/475_delta_t1_cbj95tk.json\n","sampled-threads-ah-delta-context3/353_ah_t1_d5n9mxh.json\n","sampled-threads-ah-delta-context3/171_delta_t1_cb8sq7s.json\n","sampled-threads-ah-delta-context3/507_ah_t1_d34l3zp.json\n","sampled-threads-ah-delta-context3/660_ah_t1_d4xyfdy.json\n","sampled-threads-ah-delta-context3/443_ah_t1_czyllyi.json\n","sampled-threads-ah-delta-context3/890_ah_t1_cm5o0r3.json\n","sampled-threads-ah-delta-context3/22_delta_t1_dlm6ap3.json\n","sampled-threads-ah-delta-context3/729_delta_t1_cj3p4np.json\n","sampled-threads-ah-delta-context3/50_ah_t1_czflwon.json\n","sampled-threads-ah-delta-context3/586_ah_t1_cym18gd.json\n","sampled-threads-ah-delta-context3/1138_ah_t1_dhw0ltn.json\n","sampled-threads-ah-delta-context3/238_delta_t1_cbud30g.json\n","sampled-threads-ah-delta-context3/203_ah_t1_d70pcob.json\n","sampled-threads-ah-delta-context3/1095_ah_t1_d0vcccv.json\n","sampled-threads-ah-delta-context3/75_delta_t1_d8mbhg6.json\n","sampled-threads-ah-delta-context3/569_delta_t1_di6va3m.json\n","sampled-threads-ah-delta-context3/1048_ah_t1_dg6irb1.json\n","sampled-threads-ah-delta-context3/1220_ah_t1_d9k89ww.json\n","sampled-threads-ah-delta-context3/1038_ah_t1_dlcumtz.json\n","sampled-threads-ah-delta-context3/349_ah_t1_ddzvp8t.json\n","sampled-threads-ah-delta-context3/23_delta_t1_dh02fpn.json\n","sampled-threads-ah-delta-context3/1199_ah_t1_czsvng2.json\n","sampled-threads-ah-delta-context3/1250_delta_t1_djfdg0i.json\n","sampled-threads-ah-delta-context3/404_delta_t1_cmik258.json\n","sampled-threads-ah-delta-context3/944_delta_t1_d9twgsz.json\n","sampled-threads-ah-delta-context3/923_delta_t1_czdlpmx.json\n","sampled-threads-ah-delta-context3/904_delta_t1_csabqmw.json\n","sampled-threads-ah-delta-context3/645_ah_t1_dlb6ali.json\n","sampled-threads-ah-delta-context3/312_delta_t1_d9xn4bk.json\n","sampled-threads-ah-delta-context3/262_delta_t1_dfmyamt.json\n","sampled-threads-ah-delta-context3/936_ah_t1_d4jnl7w.json\n","sampled-threads-ah-delta-context3/99_ah_t1_dds0vfe.json\n","sampled-threads-ah-delta-context3/132_delta_t1_dlgt2bu.json\n","sampled-threads-ah-delta-context3/575_ah_t1_dfw7r8d.json\n","sampled-threads-ah-delta-context3/76_ah_t1_d48dgv5.json\n","sampled-threads-ah-delta-context3/1133_ah_t1_d1g0jaa.json\n","sampled-threads-ah-delta-context3/509_ah_t1_d4381ug.json\n","sampled-threads-ah-delta-context3/531_delta_t1_d5r4cft.json\n","sampled-threads-ah-delta-context3/51_delta_t1_del4oxu.json\n","sampled-threads-ah-delta-context3/581_delta_t1_cqqimy5.json\n","sampled-threads-ah-delta-context3/1275_ah_t1_dl3nlyu.json\n","sampled-threads-ah-delta-context3/1159_delta_t1_d9bsvy6.json\n","sampled-threads-ah-delta-context3/673_ah_t1_cyewk7u.json\n","sampled-threads-ah-delta-context3/701_ah_t1_cxl3ita.json\n","sampled-threads-ah-delta-context3/1214_ah_t1_d0n7iz4.json\n","sampled-threads-ah-delta-context3/745_delta_t1_clya6rm.json\n","sampled-threads-ah-delta-context3/1117_delta_t1_cvs2va2.json\n","sampled-threads-ah-delta-context3/1131_delta_t1_de19tgz.json\n","sampled-threads-ah-delta-context3/61_ah_t1_d0ak0os.json\n","sampled-threads-ah-delta-context3/106_ah_t1_cj7kcot.json\n","sampled-threads-ah-delta-context3/1169_delta_t1_dd2qafn.json\n","sampled-threads-ah-delta-context3/541_ah_t1_cwqgo44.json\n","sampled-threads-ah-delta-context3/696_ah_t1_cvns6nd.json\n","sampled-threads-ah-delta-context3/30_delta_t1_dlvfn2v.json\n","sampled-threads-ah-delta-context3/81_ah_t1_d5rrv8s.json\n","sampled-threads-ah-delta-context3/1116_delta_t1_dkgf5h2.json\n","sampled-threads-ah-delta-context3/1223_ah_t1_di3ie1k.json\n","sampled-threads-ah-delta-context3/699_ah_t1_cwd5rc2.json\n","sampled-threads-ah-delta-context3/183_delta_t1_d6h0x11.json\n","sampled-threads-ah-delta-context3/139_delta_t1_cfb6w7c.json\n","sampled-threads-ah-delta-context3/64_delta_t1_dkwf2yh.json\n","sampled-threads-ah-delta-context3/577_ah_t1_dk6t201.json\n","sampled-threads-ah-delta-context3/1251_delta_t1_cyfx3p7.json\n","sampled-threads-ah-delta-context3/1080_ah_t1_d04mvp7.json\n","sampled-threads-ah-delta-context3/1088_delta_t1_cxc93ba.json\n","sampled-threads-ah-delta-context3/41_ah_t1_dhnf6r4.json\n","sampled-threads-ah-delta-context3/662_delta_t1_cb132tw.json\n","sampled-threads-ah-delta-context3/92_ah_t1_dmag7bn.json\n","sampled-threads-ah-delta-context3/251_delta_t1_d29pw1j.json\n","sampled-threads-ah-delta-context3/546_delta_t1_cmp5ppu.json\n","sampled-threads-ah-delta-context3/601_ah_t1_d9bdy7p.json\n","sampled-threads-ah-delta-context3/1040_delta_t1_cis8xc7.json\n","sampled-threads-ah-delta-context3/769_delta_t1_cf0e8n2.json\n","sampled-threads-ah-delta-context3/313_ah_t1_ck5q7ej.json\n","sampled-threads-ah-delta-context3/350_delta_t1_dl8r1pt.json\n","sampled-threads-ah-delta-context3/1148_ah_t1_dcq7gkh.json\n","sampled-threads-ah-delta-context3/909_delta_t1_diuzvdf.json\n","sampled-threads-ah-delta-context3/724_delta_t1_dj04ggb.json\n","sampled-threads-ah-delta-context3/39_ah_t1_d9ydcxf.json\n","sampled-threads-ah-delta-context3/11_ah_t1_dbaac4a.json\n","sampled-threads-ah-delta-context3/377_ah_t1_db77aem.json\n","sampled-threads-ah-delta-context3/188_delta_t1_diqgcu7.json\n","sampled-threads-ah-delta-context3/48_delta_t1_cg16xwn.json\n","sampled-threads-ah-delta-context3/145_ah_t1_ckggicn.json\n","sampled-threads-ah-delta-context3/1263_delta_t1_d5d8oav.json\n","sampled-threads-ah-delta-context3/1149_ah_t1_df4lli3.json\n","sampled-threads-ah-delta-context3/707_delta_t1_cpet2nu.json\n","sampled-threads-ah-delta-context3/751_delta_t1_cjl702a.json\n","sampled-threads-ah-delta-context3/448_delta_t1_ccu8tjy.json\n","sampled-threads-ah-delta-context3/1247_ah_t1_czjf0e7.json\n","sampled-threads-ah-delta-context3/807_delta_t1_d9dgr00.json\n","sampled-threads-ah-delta-context3/1257_delta_t1_dk6nyfk.json\n","sampled-threads-ah-delta-context3/1221_delta_t1_comrw46.json\n","sampled-threads-ah-delta-context3/316_ah_t1_csjkiq7.json\n","sampled-threads-ah-delta-context3/677_ah_t1_d0xbdru.json\n","sampled-threads-ah-delta-context3/895_ah_t1_csl8h3u.json\n","sampled-threads-ah-delta-context3/494_ah_t1_divohzz.json\n","sampled-threads-ah-delta-context3/718_delta_t1_dh3d1uu.json\n","sampled-threads-ah-delta-context3/1267_delta_t1_d4kwrad.json\n","sampled-threads-ah-delta-context3/578_ah_t1_dgxgmp7.json\n","sampled-threads-ah-delta-context3/591_delta_t1_cwasojq.json\n","sampled-threads-ah-delta-context3/296_ah_t1_ckqj3je.json\n","sampled-threads-ah-delta-context3/1136_delta_t1_d9ct55a.json\n","sampled-threads-ah-delta-context3/919_ah_t1_d1sswix.json\n","sampled-threads-ah-delta-context3/349_delta_t1_d2cbezb.json\n","sampled-threads-ah-delta-context3/793_delta_t1_d9hevda.json\n","sampled-threads-ah-delta-context3/442_delta_t1_cr7k7do.json\n","sampled-threads-ah-delta-context3/117_ah_t1_cwledck.json\n","sampled-threads-ah-delta-context3/635_delta_t1_ckhgm1h.json\n","sampled-threads-ah-delta-context3/626_ah_t1_d9t7mep.json\n","sampled-threads-ah-delta-context3/676_delta_t1_dmlylpv.json\n","sampled-threads-ah-delta-context3/879_delta_t1_cga7sga.json\n","sampled-threads-ah-delta-context3/210_delta_t1_cb9glw3.json\n","sampled-threads-ah-delta-context3/69_delta_t1_cen83km.json\n","sampled-threads-ah-delta-context3/468_delta_t1_d59mjv7.json\n","sampled-threads-ah-delta-context3/1014_ah_t1_dbl0nu5.json\n","sampled-threads-ah-delta-context3/892_delta_t1_dm9wtu1.json\n","sampled-threads-ah-delta-context3/1153_delta_t1_d6dhls8.json\n","sampled-threads-ah-delta-context3/190_delta_t1_db6i83e.json\n","sampled-threads-ah-delta-context3/1282_delta_t1_ce6n5d6.json\n","sampled-threads-ah-delta-context3/708_ah_t1_ck91k4x.json\n","sampled-threads-ah-delta-context3/486_ah_t1_dii9yks.json\n","sampled-threads-ah-delta-context3/243_ah_t1_crv1fxa.json\n","sampled-threads-ah-delta-context3/391_delta_t1_d5okjxz.json\n","sampled-threads-ah-delta-context3/354_ah_t1_dgdx6sx.json\n","sampled-threads-ah-delta-context3/1253_ah_t1_d97v24w.json\n","sampled-threads-ah-delta-context3/759_delta_t1_dnballu.json\n","sampled-threads-ah-delta-context3/1119_delta_t1_dh8bfta.json\n","sampled-threads-ah-delta-context3/137_delta_t1_dfqajkd.json\n","sampled-threads-ah-delta-context3/1155_delta_t1_cyb5925.json\n","sampled-threads-ah-delta-context3/253_ah_t1_daoazgy.json\n","sampled-threads-ah-delta-context3/258_ah_t1_ddrldex.json\n","sampled-threads-ah-delta-context3/526_ah_t1_clpmsgk.json\n","sampled-threads-ah-delta-context3/338_delta_t1_dn1dl7t.json\n","sampled-threads-ah-delta-context3/466_ah_t1_cjeasok.json\n","sampled-threads-ah-delta-context3/166_delta_t1_cut7fn2.json\n","sampled-threads-ah-delta-context3/38_delta_t1_dkdzm1n.json\n","sampled-threads-ah-delta-context3/878_ah_t1_djt2kza.json\n","sampled-threads-ah-delta-context3/1147_ah_t1_cqlqtya.json\n","sampled-threads-ah-delta-context3/979_delta_t1_djtv4zp.json\n","sampled-threads-ah-delta-context3/991_delta_t1_cdyaiu3.json\n","sampled-threads-ah-delta-context3/483_ah_t1_dfafrgg.json\n","sampled-threads-ah-delta-context3/935_ah_t1_deq4iex.json\n","sampled-threads-ah-delta-context3/341_delta_t1_ce6u7q2.json\n","sampled-threads-ah-delta-context3/1125_delta_t1_dcq4oin.json\n","sampled-threads-ah-delta-context3/403_ah_t1_cwhnoxp.json\n","sampled-threads-ah-delta-context3/978_ah_t1_cxs0rk8.json\n","sampled-threads-ah-delta-context3/795_delta_t1_djvpstq.json\n","sampled-threads-ah-delta-context3/357_ah_t1_cxd3g40.json\n","sampled-threads-ah-delta-context3/331_delta_t1_d44nxbe.json\n","sampled-threads-ah-delta-context3/909_ah_t1_cqlfhpv.json\n","sampled-threads-ah-delta-context3/180_delta_t1_dknw70h.json\n","sampled-threads-ah-delta-context3/101_ah_t1_d3rzxgp.json\n","sampled-threads-ah-delta-context3/912_delta_t1_de4ogep.json\n","sampled-threads-ah-delta-context3/883_delta_t1_djvpacp.json\n","sampled-threads-ah-delta-context3/832_delta_t1_dfx13ik.json\n","sampled-threads-ah-delta-context3/725_delta_t1_d9vv81j.json\n","sampled-threads-ah-delta-context3/1008_ah_t1_d1vsx8z.json\n","sampled-threads-ah-delta-context3/779_delta_t1_cl9naqv.json\n","sampled-threads-ah-delta-context3/489_ah_t1_dij6cj9.json\n","sampled-threads-ah-delta-context3/221_delta_t1_caogdby.json\n","sampled-threads-ah-delta-context3/873_ah_t1_cs3ulgv.json\n","sampled-threads-ah-delta-context3/272_delta_t1_cus306w.json\n","sampled-threads-ah-delta-context3/560_delta_t1_cwn95qu.json\n","sampled-threads-ah-delta-context3/437_ah_t1_d704r6g.json\n","sampled-threads-ah-delta-context3/893_ah_t1_d0xcdjc.json\n","sampled-threads-ah-delta-context3/186_delta_t1_cvhkga9.json\n","sampled-threads-ah-delta-context3/71_ah_t1_d67fio9.json\n","sampled-threads-ah-delta-context3/1094_delta_t1_ck60r6w.json\n","sampled-threads-ah-delta-context3/570_delta_t1_ck8b1lf.json\n","sampled-threads-ah-delta-context3/124_ah_t1_dgtfges.json\n","sampled-threads-ah-delta-context3/1001_ah_t1_d92nfmh.json\n","sampled-threads-ah-delta-context3/688_ah_t1_dg5pmfd.json\n","sampled-threads-ah-delta-context3/254_delta_t1_dig60k2.json\n","sampled-threads-ah-delta-context3/1272_delta_t1_czm99hv.json\n","sampled-threads-ah-delta-context3/605_delta_t1_ctm5cou.json\n","sampled-threads-ah-delta-context3/813_delta_t1_dij8yub.json\n","sampled-threads-ah-delta-context3/563_ah_t1_ddk7ego.json\n","sampled-threads-ah-delta-context3/1020_delta_t1_cdy2o2r.json\n","sampled-threads-ah-delta-context3/678_delta_t1_cmmju6y.json\n","sampled-threads-ah-delta-context3/660_delta_t1_di1p2t9.json\n","sampled-threads-ah-delta-context3/1132_delta_t1_cc0dtfg.json\n","sampled-threads-ah-delta-context3/696_delta_t1_ctxbxt5.json\n","sampled-threads-ah-delta-context3/269_ah_t1_d2jnnib.json\n","sampled-threads-ah-delta-context3/322_ah_t1_dlp0cvr.json\n","sampled-threads-ah-delta-context3/712_delta_t1_cxmkueu.json\n","sampled-threads-ah-delta-context3/1075_ah_t1_cizswtq.json\n","sampled-threads-ah-delta-context3/1043_ah_t1_dmyrjq0.json\n","sampled-threads-ah-delta-context3/239_ah_t1_ck06wsz.json\n","sampled-threads-ah-delta-context3/1069_delta_t1_dfddwsk.json\n","sampled-threads-ah-delta-context3/510_delta_t1_ck2mewv.json\n","sampled-threads-ah-delta-context3/840_ah_t1_di41gxx.json\n","sampled-threads-ah-delta-context3/1139_delta_t1_csmr6c0.json\n","sampled-threads-ah-delta-context3/373_ah_t1_dfl11k6.json\n","sampled-threads-ah-delta-context3/207_delta_t1_devm9oe.json\n","sampled-threads-ah-delta-context3/983_ah_t1_ctrc32x.json\n","sampled-threads-ah-delta-context3/702_ah_t1_clbuf8g.json\n","sampled-threads-ah-delta-context3/1049_delta_t1_djfwc9y.json\n","sampled-threads-ah-delta-context3/710_ah_t1_d4vri90.json\n","sampled-threads-ah-delta-context3/404_ah_t1_cp5yyii.json\n","sampled-threads-ah-delta-context3/636_delta_t1_dho7tq7.json\n","sampled-threads-ah-delta-context3/116_ah_t1_cp4rg51.json\n","sampled-threads-ah-delta-context3/539_ah_t1_cy2xblx.json\n","sampled-threads-ah-delta-context3/843_delta_t1_dltqzci.json\n","sampled-threads-ah-delta-context3/242_ah_t1_dieb87v.json\n","sampled-threads-ah-delta-context3/1153_ah_t1_cnw9n2b.json\n","sampled-threads-ah-delta-context3/55_ah_t1_dff13d1.json\n","sampled-threads-ah-delta-context3/1234_delta_t1_cvct01i.json\n","sampled-threads-ah-delta-context3/946_ah_t1_d0c7adl.json\n","sampled-threads-ah-delta-context3/346_ah_t1_cjqnev5.json\n","sampled-threads-ah-delta-context3/63_delta_t1_cc3l0hm.json\n","sampled-threads-ah-delta-context3/1221_ah_t1_dl21fur.json\n","sampled-threads-ah-delta-context3/419_ah_t1_djzkzjx.json\n","sampled-threads-ah-delta-context3/74_ah_t1_d5pa2dc.json\n","sampled-threads-ah-delta-context3/508_delta_t1_cylhvfu.json\n","sampled-threads-ah-delta-context3/675_delta_t1_dguqm0u.json\n","sampled-threads-ah-delta-context3/402_delta_t1_dee57mc.json\n","sampled-threads-ah-delta-context3/783_ah_t1_dcurm1l.json\n","sampled-threads-ah-delta-context3/994_ah_t1_dffj69j.json\n","sampled-threads-ah-delta-context3/913_ah_t1_cmeatbn.json\n","sampled-threads-ah-delta-context3/1162_ah_t1_dh8d9n5.json\n","sampled-threads-ah-delta-context3/464_delta_t1_ciwnrca.json\n","sampled-threads-ah-delta-context3/400_ah_t1_di7m39x.json\n","sampled-threads-ah-delta-context3/737_delta_t1_disclpb.json\n","sampled-threads-ah-delta-context3/1066_ah_t1_ct3ajm1.json\n","sampled-threads-ah-delta-context3/32_delta_t1_cvtpsfg.json\n","sampled-threads-ah-delta-context3/684_delta_t1_dgt1jzp.json\n","sampled-threads-ah-delta-context3/853_delta_t1_cb0trrl.json\n","sampled-threads-ah-delta-context3/915_delta_t1_coz4udt.json\n","sampled-threads-ah-delta-context3/409_ah_t1_dbdt9kl.json\n","sampled-threads-ah-delta-context3/487_delta_t1_da0cn7l.json\n","sampled-threads-ah-delta-context3/794_ah_t1_cvsq957.json\n","sampled-threads-ah-delta-context3/1193_ah_t1_cob7rd6.json\n","sampled-threads-ah-delta-context3/1161_delta_t1_cshne6b.json\n","sampled-threads-ah-delta-context3/1148_delta_t1_cmwv63x.json\n","sampled-threads-ah-delta-context3/192_delta_t1_dgqitvv.json\n","sampled-threads-ah-delta-context3/663_ah_t1_dimhfme.json\n","sampled-threads-ah-delta-context3/43_ah_t1_dfmtzwy.json\n","sampled-threads-ah-delta-context3/942_ah_t1_dj2e6u6.json\n","sampled-threads-ah-delta-context3/604_delta_t1_d6qpafn.json\n","sampled-threads-ah-delta-context3/85_delta_t1_dnars9u.json\n","sampled-threads-ah-delta-context3/1156_delta_t1_d9863hk.json\n","sampled-threads-ah-delta-context3/382_ah_t1_dn4qv51.json\n","sampled-threads-ah-delta-context3/220_ah_t1_d67fo3c.json\n","sampled-threads-ah-delta-context3/1226_ah_t1_dmyz0bs.json\n","sampled-threads-ah-delta-context3/1228_delta_t1_d7ararw.json\n","sampled-threads-ah-delta-context3/430_delta_t1_dnbjdw4.json\n","sampled-threads-ah-delta-context3/197_delta_t1_cpwf39m.json\n","sampled-threads-ah-delta-context3/9_ah_t1_cyculk9.json\n","sampled-threads-ah-delta-context3/822_ah_t1_div1tx6.json\n","sampled-threads-ah-delta-context3/164_delta_t1_cljwx94.json\n","sampled-threads-ah-delta-context3/625_delta_t1_d9ztkpe.json\n","sampled-threads-ah-delta-context3/158_ah_t1_d4n0u4u.json\n","sampled-threads-ah-delta-context3/510_ah_t1_csv0okn.json\n","sampled-threads-ah-delta-context3/1262_ah_t1_dhja2eu.json\n","sampled-threads-ah-delta-context3/760_ah_t1_d3r5lw2.json\n","sampled-threads-ah-delta-context3/661_ah_t1_ddtcp45.json\n","sampled-threads-ah-delta-context3/128_ah_t1_csjrpxl.json\n","sampled-threads-ah-delta-context3/1255_delta_t1_di18irl.json\n","sampled-threads-ah-delta-context3/1076_delta_t1_crcwng3.json\n","sampled-threads-ah-delta-context3/452_ah_t1_d7h6fol.json\n","sampled-threads-ah-delta-context3/88_ah_t1_dk11drr.json\n","sampled-threads-ah-delta-context3/1098_ah_t1_d821pfn.json\n","sampled-threads-ah-delta-context3/735_ah_t1_cm65c90.json\n","sampled-threads-ah-delta-context3/839_delta_t1_csfosq4.json\n","sampled-threads-ah-delta-context3/838_ah_t1_det302v.json\n","sampled-threads-ah-delta-context3/160_delta_t1_cpx39qo.json\n","sampled-threads-ah-delta-context3/9_delta_t1_d85wmwf.json\n","sampled-threads-ah-delta-context3/412_ah_t1_cy6zgg1.json\n","sampled-threads-ah-delta-context3/1277_delta_t1_cvmco3e.json\n","sampled-threads-ah-delta-context3/1249_ah_t1_d09rs5v.json\n","sampled-threads-ah-delta-context3/366_delta_t1_ci0mvqo.json\n","sampled-threads-ah-delta-context3/979_ah_t1_dj7yhve.json\n","sampled-threads-ah-delta-context3/375_delta_t1_caxt1ar.json\n","sampled-threads-ah-delta-context3/396_delta_t1_d4royem.json\n","sampled-threads-ah-delta-context3/1284_ah_t1_cyyc4yw.json\n","sampled-threads-ah-delta-context3/768_delta_t1_di4i436.json\n","sampled-threads-ah-delta-context3/828_delta_t1_dlk85eo.json\n","sampled-threads-ah-delta-context3/1059_delta_t1_cb8njlz.json\n","sampled-threads-ah-delta-context3/171_ah_t1_d1smmbq.json\n","sampled-threads-ah-delta-context3/1204_delta_t1_dds05d3.json\n","sampled-threads-ah-delta-context3/990_ah_t1_ddcy9rd.json\n","sampled-threads-ah-delta-context3/205_ah_t1_ctvb2fh.json\n","sampled-threads-ah-delta-context3/115_ah_t1_cxx6thw.json\n","sampled-threads-ah-delta-context3/553_ah_t1_cqp7vwf.json\n","sampled-threads-ah-delta-context3/971_ah_t1_d6h87tj.json\n","sampled-threads-ah-delta-context3/330_ah_t1_clmpp56.json\n","sampled-threads-ah-delta-context3/722_delta_t1_d2mlt6l.json\n","sampled-threads-ah-delta-context3/1155_ah_t1_d9po5dw.json\n","sampled-threads-ah-delta-context3/555_ah_t1_djgcow3.json\n","sampled-threads-ah-delta-context3/649_delta_t1_ct3o5fa.json\n","sampled-threads-ah-delta-context3/692_ah_t1_cypmdzy.json\n","sampled-threads-ah-delta-context3/83_delta_t1_cym0hmh.json\n","sampled-threads-ah-delta-context3/1038_delta_t1_cozhx48.json\n","sampled-threads-ah-delta-context3/580_delta_t1_dj7qapn.json\n","sampled-threads-ah-delta-context3/283_ah_t1_clrclte.json\n","sampled-threads-ah-delta-context3/1185_ah_t1_dg9xang.json\n","sampled-threads-ah-delta-context3/544_delta_t1_daerw2g.json\n","sampled-threads-ah-delta-context3/1174_ah_t1_d0ommfs.json\n","sampled-threads-ah-delta-context3/203_delta_t1_d4ay2if.json\n","sampled-threads-ah-delta-context3/93_ah_t1_dmyi3vw.json\n","sampled-threads-ah-delta-context3/1137_ah_t1_dbb0os0.json\n","sampled-threads-ah-delta-context3/515_delta_t1_d9xdf7b.json\n","sampled-threads-ah-delta-context3/1222_ah_t1_dkkmmwi.json\n","sampled-threads-ah-delta-context3/704_ah_t1_d0rmohr.json\n","sampled-threads-ah-delta-context3/147_ah_t1_d5yv9a8.json\n","sampled-threads-ah-delta-context3/124_delta_t1_cvhkli9.json\n","sampled-threads-ah-delta-context3/420_ah_t1_dh03nkh.json\n","sampled-threads-ah-delta-context3/398_delta_t1_ccfhbkp.json\n","sampled-threads-ah-delta-context3/781_ah_t1_cmlmi0n.json\n","sampled-threads-ah-delta-context3/1102_delta_t1_dm1ne9o.json\n","sampled-threads-ah-delta-context3/346_delta_t1_ckg2lo8.json\n","sampled-threads-ah-delta-context3/989_ah_t1_dk2sc4u.json\n","sampled-threads-ah-delta-context3/529_delta_t1_cn6mkr8.json\n","sampled-threads-ah-delta-context3/391_ah_t1_cnsc03k.json\n","sampled-threads-ah-delta-context3/1077_delta_t1_d9kf384.json\n","sampled-threads-ah-delta-context3/1055_delta_t1_coutf1j.json\n","sampled-threads-ah-delta-context3/606_ah_t1_dihjmm3.json\n","sampled-threads-ah-delta-context3/368_delta_t1_cfdtel3.json\n","sampled-threads-ah-delta-context3/1216_delta_t1_dn0dswx.json\n","sampled-threads-ah-delta-context3/801_delta_t1_cmzanx8.json\n","sampled-threads-ah-delta-context3/93_delta_t1_cx2g21b.json\n","sampled-threads-ah-delta-context3/1201_ah_t1_dmbogjo.json\n","sampled-threads-ah-delta-context3/104_delta_t1_cr5q1mf.json\n","sampled-threads-ah-delta-context3/89_ah_t1_d1sdcpf.json\n","sampled-threads-ah-delta-context3/460_delta_t1_cst9fyd.json\n","sampled-threads-ah-delta-context3/1270_delta_t1_carr2uc.json\n","sampled-threads-ah-delta-context3/1074_delta_t1_ci5npnd.json\n","sampled-threads-ah-delta-context3/1177_ah_t1_d0mip5s.json\n","sampled-threads-ah-delta-context3/400_delta_t1_dhmfphk.json\n","sampled-threads-ah-delta-context3/1244_delta_t1_cj6ss57.json\n","sampled-threads-ah-delta-context3/474_delta_t1_cgtpoek.json\n","sampled-threads-ah-delta-context3/1195_ah_t1_dfjmngf.json\n","sampled-threads-ah-delta-context3/131_delta_t1_cbvxw29.json\n","sampled-threads-ah-delta-context3/211_ah_t1_csbendl.json\n","sampled-threads-ah-delta-context3/1042_delta_t1_dd15gdz.json\n","sampled-threads-ah-delta-context3/1015_delta_t1_cik92q4.json\n","sampled-threads-ah-delta-context3/1027_delta_t1_dif4dn1.json\n","sampled-threads-ah-delta-context3/824_ah_t1_cvoj5re.json\n","sampled-threads-ah-delta-context3/928_delta_t1_didwvxq.json\n","sampled-threads-ah-delta-context3/492_delta_t1_dgr34pm.json\n","sampled-threads-ah-delta-context3/943_delta_t1_df92qgb.json\n","sampled-threads-ah-delta-context3/823_delta_t1_cgmqm3y.json\n","sampled-threads-ah-delta-context3/1047_delta_t1_d9urlc0.json\n","sampled-threads-ah-delta-context3/150_ah_t1_d8tfczk.json\n","sampled-threads-ah-delta-context3/138_ah_t1_cj43k0j.json\n","sampled-threads-ah-delta-context3/173_delta_t1_clnppd4.json\n","sampled-threads-ah-delta-context3/1079_delta_t1_cpd0rtm.json\n","sampled-threads-ah-delta-context3/237_delta_t1_cpsptil.json\n","sampled-threads-ah-delta-context3/828_ah_t1_dl593ue.json\n","sampled-threads-ah-delta-context3/373_delta_t1_cqh3ex9.json\n","sampled-threads-ah-delta-context3/630_delta_t1_dess6cs.json\n","sampled-threads-ah-delta-context3/1261_delta_t1_df0316q.json\n","sampled-threads-ah-delta-context3/906_delta_t1_cnlxsel.json\n","sampled-threads-ah-delta-context3/1041_ah_t1_d0drvg1.json\n","sampled-threads-ah-delta-context3/545_ah_t1_dbkfdyc.json\n","sampled-threads-ah-delta-context3/328_ah_t1_d001ip1.json\n","sampled-threads-ah-delta-context3/469_ah_t1_ckyfxbd.json\n","sampled-threads-ah-delta-context3/674_delta_t1_din8qfv.json\n","sampled-threads-ah-delta-context3/1172_delta_t1_d1ztv9k.json\n","sampled-threads-ah-delta-context3/63_ah_t1_cwophda.json\n","sampled-threads-ah-delta-context3/455_ah_t1_crv1vbz.json\n","sampled-threads-ah-delta-context3/868_ah_t1_czx6f1o.json\n","sampled-threads-ah-delta-context3/495_delta_t1_djk7zf5.json\n","sampled-threads-ah-delta-context3/501_delta_t1_d2ths2y.json\n","sampled-threads-ah-delta-context3/209_ah_t1_dmio60c.json\n","sampled-threads-ah-delta-context3/1256_ah_t1_d87yruu.json\n","sampled-threads-ah-delta-context3/7_ah_t1_d0gxnse.json\n","sampled-threads-ah-delta-context3/724_ah_t1_cvohlk6.json\n","sampled-threads-ah-delta-context3/1179_ah_t1_cw22xii.json\n","sampled-threads-ah-delta-context3/1045_ah_t1_cnm3efw.json\n","sampled-threads-ah-delta-context3/952_ah_t1_deytcu8.json\n","sampled-threads-ah-delta-context3/1207_ah_t1_cq6jcz0.json\n","sampled-threads-ah-delta-context3/901_delta_t1_dc00b3p.json\n","sampled-threads-ah-delta-context3/1060_ah_t1_dcb1s8v.json\n","sampled-threads-ah-delta-context3/454_delta_t1_d8v2x1z.json\n","sampled-threads-ah-delta-context3/90_delta_t1_d1649nb.json\n","sampled-threads-ah-delta-context3/834_ah_t1_coy7tqo.json\n","sampled-threads-ah-delta-context3/1093_delta_t1_d165gx5.json\n","sampled-threads-ah-delta-context3/776_delta_t1_cg00gpy.json\n","sampled-threads-ah-delta-context3/1213_ah_t1_dlfw9hg.json\n","sampled-threads-ah-delta-context3/1285_ah_t1_csetpds.json\n","sampled-threads-ah-delta-context3/309_delta_t1_de9b1w5.json\n","sampled-threads-ah-delta-context3/784_ah_t1_cpg3suy.json\n","sampled-threads-ah-delta-context3/521_delta_t1_dfqu9q1.json\n","sampled-threads-ah-delta-context3/816_ah_t1_cmkq0mq.json\n","sampled-threads-ah-delta-context3/246_delta_t1_coj5meb.json\n","sampled-threads-ah-delta-context3/1036_delta_t1_d4ruv3h.json\n","sampled-threads-ah-delta-context3/657_delta_t1_dcj0mn6.json\n","sampled-threads-ah-delta-context3/819_delta_t1_dk34pxl.json\n","sampled-threads-ah-delta-context3/803_delta_t1_dl9vb83.json\n","sampled-threads-ah-delta-context3/46_ah_t1_d09k4et.json\n","sampled-threads-ah-delta-context3/152_ah_t1_d54pxfi.json\n","sampled-threads-ah-delta-context3/742_ah_t1_d6qfv32.json\n","sampled-threads-ah-delta-context3/802_delta_t1_cdcger4.json\n","sampled-threads-ah-delta-context3/1276_ah_t1_dlh2adc.json\n","sampled-threads-ah-delta-context3/333_ah_t1_d03zl37.json\n","sampled-threads-ah-delta-context3/880_delta_t1_cygizfs.json\n","sampled-threads-ah-delta-context3/1077_ah_t1_dhkbwrw.json\n","sampled-threads-ah-delta-context3/616_delta_t1_dn9wygj.json\n","sampled-threads-ah-delta-context3/38_ah_t1_dbq1kai.json\n","sampled-threads-ah-delta-context3/94_delta_t1_ctukrmp.json\n","sampled-threads-ah-delta-context3/1048_delta_t1_cl88izb.json\n","sampled-threads-ah-delta-context3/1056_delta_t1_cayipgd.json\n","sampled-threads-ah-delta-context3/1234_ah_t1_dmqilqj.json\n","sampled-threads-ah-delta-context3/943_ah_t1_diq8nom.json\n","sampled-threads-ah-delta-context3/1217_delta_t1_dc9m81v.json\n","sampled-threads-ah-delta-context3/812_ah_t1_d7s16sq.json\n","sampled-threads-ah-delta-context3/801_ah_t1_ctgpw5a.json\n","sampled-threads-ah-delta-context3/997_delta_t1_cubplma.json\n","sampled-threads-ah-delta-context3/118_delta_t1_ctw9cin.json\n","sampled-threads-ah-delta-context3/959_ah_t1_dl216r2.json\n","sampled-threads-ah-delta-context3/1154_ah_t1_dlbiiu3.json\n","sampled-threads-ah-delta-context3/793_ah_t1_cx1kav3.json\n","sampled-threads-ah-delta-context3/796_ah_t1_dcuwvw5.json\n","sampled-threads-ah-delta-context3/545_delta_t1_dft2x26.json\n","sampled-threads-ah-delta-context3/1182_ah_t1_cnp0p7x.json\n","sampled-threads-ah-delta-context3/1040_ah_t1_dmydapx.json\n","sampled-threads-ah-delta-context3/387_ah_t1_dlqnfwn.json\n","sampled-threads-ah-delta-context3/805_delta_t1_caop01n.json\n","sampled-threads-ah-delta-context3/447_delta_t1_dm0102p.json\n","sampled-threads-ah-delta-context3/458_delta_t1_d5ucejo.json\n","sampled-threads-ah-delta-context3/163_ah_t1_cyc51lh.json\n","sampled-threads-ah-delta-context3/252_ah_t1_d682ne0.json\n","sampled-threads-ah-delta-context3/80_delta_t1_cukdj0k.json\n","sampled-threads-ah-delta-context3/7_delta_t1_cmv1xfd.json\n","sampled-threads-ah-delta-context3/56_ah_t1_ckhaab4.json\n","sampled-threads-ah-delta-context3/1260_ah_t1_d0mfgwx.json\n","sampled-threads-ah-delta-context3/809_ah_t1_d1ril1j.json\n","sampled-threads-ah-delta-context3/300_delta_t1_cprbwm5.json\n","sampled-threads-ah-delta-context3/1224_delta_t1_d0vkhfj.json\n","sampled-threads-ah-delta-context3/41_delta_t1_d8aucqp.json\n","sampled-threads-ah-delta-context3/201_ah_t1_d40vriv.json\n","sampled-threads-ah-delta-context3/999_ah_t1_dleefwd.json\n","sampled-threads-ah-delta-context3/411_delta_t1_cvlmsxa.json\n","sampled-threads-ah-delta-context3/1192_delta_t1_di9exes.json\n","sampled-threads-ah-delta-context3/880_ah_t1_czbskav.json\n","sampled-threads-ah-delta-context3/614_delta_t1_dla8cdm.json\n","sampled-threads-ah-delta-context3/970_delta_t1_dis2b41.json\n","sampled-threads-ah-delta-context3/1033_delta_t1_da4qmch.json\n","sampled-threads-ah-delta-context3/396_ah_t1_de2x1z6.json\n","sampled-threads-ah-delta-context3/582_ah_t1_csda4p2.json\n","sampled-threads-ah-delta-context3/1073_delta_t1_d3arm6k.json\n","sampled-threads-ah-delta-context3/585_ah_t1_csr662u.json\n","sampled-threads-ah-delta-context3/432_delta_t1_cfdnxiy.json\n","sampled-threads-ah-delta-context3/430_ah_t1_cj9kuyu.json\n","sampled-threads-ah-delta-context3/417_delta_t1_cdbro9q.json\n","sampled-threads-ah-delta-context3/844_delta_t1_dcpriu7.json\n","sampled-threads-ah-delta-context3/962_delta_t1_dbe6rvn.json\n","sampled-threads-ah-delta-context3/231_delta_t1_df1p75e.json\n","sampled-threads-ah-delta-context3/144_delta_t1_ciydh2t.json\n","sampled-threads-ah-delta-context3/632_ah_t1_d4t4v9p.json\n","sampled-threads-ah-delta-context3/794_delta_t1_dfarp8c.json\n","sampled-threads-ah-delta-context3/469_delta_t1_d4elqwp.json\n","sampled-threads-ah-delta-context3/337_ah_t1_d86d3sm.json\n","sampled-threads-ah-delta-context3/967_ah_t1_dnagn35.json\n","sampled-threads-ah-delta-context3/645_delta_t1_djs87ui.json\n","sampled-threads-ah-delta-context3/1005_delta_t1_cfjqxyk.json\n","sampled-threads-ah-delta-context3/947_ah_t1_dloanvt.json\n","sampled-threads-ah-delta-context3/450_delta_t1_cbp4xis.json\n","sampled-threads-ah-delta-context3/940_ah_t1_diac6kd.json\n","sampled-threads-ah-delta-context3/524_ah_t1_cu5b377.json\n","sampled-threads-ah-delta-context3/355_delta_t1_cqs0ono.json\n","sampled-threads-ah-delta-context3/1167_ah_t1_ctstiwz.json\n","sampled-threads-ah-delta-context3/985_delta_t1_cbntita.json\n","sampled-threads-ah-delta-context3/87_delta_t1_d5a6jau.json\n","sampled-threads-ah-delta-context3/1122_delta_t1_dl1900q.json\n","sampled-threads-ah-delta-context3/715_ah_t1_cqilgn2.json\n","sampled-threads-ah-delta-context3/10_delta_t1_d7bri2j.json\n","sampled-threads-ah-delta-context3/1251_ah_t1_cudx59t.json\n","sampled-threads-ah-delta-context3/553_delta_t1_cr7kewe.json\n","sampled-threads-ah-delta-context3/272_ah_t1_dbhvs9l.json\n","sampled-threads-ah-delta-context3/360_ah_t1_cko2rap.json\n","sampled-threads-ah-delta-context3/282_ah_t1_d2tumxz.json\n","sampled-threads-ah-delta-context3/153_ah_t1_d1iftra.json\n","sampled-threads-ah-delta-context3/481_delta_t1_dlhd0d6.json\n","sampled-threads-ah-delta-context3/831_delta_t1_d5788ry.json\n","sampled-threads-ah-delta-context3/582_delta_t1_dktidgr.json\n","sampled-threads-ah-delta-context3/1017_delta_t1_dknevpj.json\n","sampled-threads-ah-delta-context3/1236_delta_t1_d7ep510.json\n","sampled-threads-ah-delta-context3/513_delta_t1_d6b6ac1.json\n","sampled-threads-ah-delta-context3/225_ah_t1_cjb237g.json\n","sampled-threads-ah-delta-context3/1243_delta_t1_czcqeg4.json\n","sampled-threads-ah-delta-context3/1254_delta_t1_cm8ci0k.json\n","sampled-threads-ah-delta-context3/689_ah_t1_dalad5i.json\n","sampled-threads-ah-delta-context3/416_delta_t1_dl10i4m.json\n","sampled-threads-ah-delta-context3/889_ah_t1_dmyzej8.json\n","sampled-threads-ah-delta-context3/695_delta_t1_d8fminr.json\n","sampled-threads-ah-delta-context3/561_ah_t1_dmx3ish.json\n","sampled-threads-ah-delta-context3/672_delta_t1_dd30jt9.json\n","sampled-threads-ah-delta-context3/67_ah_t1_cs8o8ha.json\n","sampled-threads-ah-delta-context3/47_ah_t1_czk17z0.json\n","sampled-threads-ah-delta-context3/32_ah_t1_d1xkpga.json\n","sampled-threads-ah-delta-context3/1127_delta_t1_dc4exwz.json\n","sampled-threads-ah-delta-context3/1112_ah_t1_dc67xdu.json\n","sampled-threads-ah-delta-context3/873_delta_t1_cwtnig2.json\n","sampled-threads-ah-delta-context3/1239_delta_t1_cbq6t3d.json\n","sampled-threads-ah-delta-context3/606_delta_t1_cv7c1hi.json\n","sampled-threads-ah-delta-context3/1226_delta_t1_d9svs3h.json\n","sampled-threads-ah-delta-context3/847_ah_t1_dedzlyx.json\n","sampled-threads-ah-delta-context3/146_delta_t1_df93m3o.json\n","sampled-threads-ah-delta-context3/1170_ah_t1_djfrzji.json\n","sampled-threads-ah-delta-context3/652_delta_t1_cgeihei.json\n","sampled-threads-ah-delta-context3/199_delta_t1_cjns0ro.json\n","sampled-threads-ah-delta-context3/1134_ah_t1_czca8bd.json\n","sampled-threads-ah-delta-context3/111_delta_t1_ddxaia4.json\n","sampled-threads-ah-delta-context3/456_ah_t1_dmzb869.json\n","sampled-threads-ah-delta-context3/329_delta_t1_dmzb329.json\n","sampled-threads-ah-delta-context3/682_delta_t1_dkt2si1.json\n","sampled-threads-ah-delta-context3/1137_delta_t1_djccl03.json\n","sampled-threads-ah-delta-context3/1134_delta_t1_dlun684.json\n","sampled-threads-ah-delta-context3/378_delta_t1_cjo1nlv.json\n","sampled-threads-ah-delta-context3/1288_ah_t1_d282n88.json\n","sampled-threads-ah-delta-context3/1239_ah_t1_dahlerj.json\n","sampled-threads-ah-delta-context3/179_delta_t1_dchjf1d.json\n","sampled-threads-ah-delta-context3/1259_ah_t1_dezgggz.json\n","sampled-threads-ah-delta-context3/1053_delta_t1_cgjc1b8.json\n","sampled-threads-ah-delta-context3/633_ah_t1_dfxd5ns.json\n","sampled-threads-ah-delta-context3/1141_ah_t1_d972jcf.json\n","sampled-threads-ah-delta-context3/74_delta_t1_chox9ib.json\n","sampled-threads-ah-delta-context3/109_ah_t1_cuu8gko.json\n","sampled-threads-ah-delta-context3/818_delta_t1_dbnmlk8.json\n","sampled-threads-ah-delta-context3/1196_ah_t1_ckkkg55.json\n","sampled-threads-ah-delta-context3/1090_delta_t1_cqylilv.json\n","sampled-threads-ah-delta-context3/864_delta_t1_dezkh0w.json\n","sampled-threads-ah-delta-context3/1131_ah_t1_de2oo4s.json\n","sampled-threads-ah-delta-context3/496_ah_t1_d9cthnk.json\n","sampled-threads-ah-delta-context3/443_delta_t1_cgj7e5r.json\n","sampled-threads-ah-delta-context3/1189_ah_t1_dd4ri5e.json\n","sampled-threads-ah-delta-context3/894_ah_t1_cv225q9.json\n","sampled-threads-ah-delta-context3/1003_delta_t1_cllvewo.json\n","sampled-threads-ah-delta-context3/776_ah_t1_dl10nkv.json\n","sampled-threads-ah-delta-context3/214_delta_t1_d5l6t3j.json\n","sampled-threads-ah-delta-context3/2_delta_t1_cfkhpja.json\n","sampled-threads-ah-delta-context3/937_ah_t1_dhj3y95.json\n","sampled-threads-ah-delta-context3/1242_delta_t1_dh87prv.json\n","sampled-threads-ah-delta-context3/1068_ah_t1_cssbcnq.json\n","sampled-threads-ah-delta-context3/318_delta_t1_dhph8vs.json\n","sampled-threads-ah-delta-context3/1071_ah_t1_d33y7uq.json\n","sampled-threads-ah-delta-context3/625_ah_t1_dkprrtp.json\n","sampled-threads-ah-delta-context3/820_delta_t1_ct5zwlk.json\n","sampled-threads-ah-delta-context3/1177_delta_t1_dmdl8cd.json\n","sampled-threads-ah-delta-context3/628_delta_t1_cx8asci.json\n","sampled-threads-ah-delta-context3/642_delta_t1_d2ntti6.json\n","sampled-threads-ah-delta-context3/559_ah_t1_d78iv4p.json\n","sampled-threads-ah-delta-context3/1151_ah_t1_ded3ydy.json\n","sampled-threads-ah-delta-context3/761_ah_t1_dhfmmob.json\n","sampled-threads-ah-delta-context3/843_ah_t1_dc6bhb5.json\n","sampled-threads-ah-delta-context3/739_ah_t1_cox4a7v.json\n","sampled-threads-ah-delta-context3/908_delta_t1_cut49p7.json\n","sampled-threads-ah-delta-context3/761_delta_t1_d08qu7k.json\n","sampled-threads-ah-delta-context3/594_ah_t1_cv5wbgy.json\n","sampled-threads-ah-delta-context3/73_delta_t1_d6l2bte.json\n","sampled-threads-ah-delta-context3/751_ah_t1_cpc6n6a.json\n","sampled-threads-ah-delta-context3/1061_ah_t1_cu49own.json\n","sampled-threads-ah-delta-context3/984_ah_t1_dc22p56.json\n","sampled-threads-ah-delta-context3/973_ah_t1_d0pnsyw.json\n","sampled-threads-ah-delta-context3/494_delta_t1_dgadbar.json\n","sampled-threads-ah-delta-context3/68_ah_t1_d06s211.json\n","sampled-threads-ah-delta-context3/279_ah_t1_djphsvx.json\n","sampled-threads-ah-delta-context3/269_delta_t1_defuxyu.json\n","sampled-threads-ah-delta-context3/784_delta_t1_dletgg3.json\n","sampled-threads-ah-delta-context3/337_delta_t1_dgavjhi.json\n","sampled-threads-ah-delta-context3/1176_ah_t1_cwnyat4.json\n","sampled-threads-ah-delta-context3/870_ah_t1_d6h0y1p.json\n","sampled-threads-ah-delta-context3/1020_ah_t1_dm3z991.json\n","sampled-threads-ah-delta-context3/276_delta_t1_cj5cyca.json\n","sampled-threads-ah-delta-context3/361_delta_t1_coepap8.json\n","sampled-threads-ah-delta-context3/974_ah_t1_dmsnlm2.json\n","sampled-threads-ah-delta-context3/664_delta_t1_d9go4nn.json\n","sampled-threads-ah-delta-context3/181_ah_t1_dg0dm4w.json\n","sampled-threads-ah-delta-context3/1032_ah_t1_dgkwzg3.json\n","sampled-threads-ah-delta-context3/58_delta_t1_cil7xng.json\n","sampled-threads-ah-delta-context3/291_delta_t1_cm0dz5u.json\n","sampled-threads-ah-delta-context3/1002_delta_t1_dfj7u7x.json\n","sampled-threads-ah-delta-context3/888_ah_t1_de2en4h.json\n","sampled-threads-ah-delta-context3/927_delta_t1_dhif5ab.json\n","sampled-threads-ah-delta-context3/317_delta_t1_cbzy6y9.json\n","sampled-threads-ah-delta-context3/599_ah_t1_ckbowcs.json\n","sampled-threads-ah-delta-context3/1072_ah_t1_dfjz9m9.json\n","sampled-threads-ah-delta-context3/532_ah_t1_d0h9t92.json\n","sampled-threads-ah-delta-context3/394_ah_t1_csfhjqa.json\n","sampled-threads-ah-delta-context3/303_delta_t1_co3nb98.json\n","sampled-threads-ah-delta-context3/232_delta_t1_dj5pc6o.json\n","sampled-threads-ah-delta-context3/586_delta_t1_cu42h5q.json\n","sampled-threads-ah-delta-context3/513_ah_t1_cm1lv5u.json\n","sampled-threads-ah-delta-context3/1262_delta_t1_di1p64g.json\n","sampled-threads-ah-delta-context3/995_ah_t1_cpx5o2s.json\n","sampled-threads-ah-delta-context3/585_delta_t1_cfkcra3.json\n","sampled-threads-ah-delta-context3/1238_delta_t1_dkfqmuv.json\n","sampled-threads-ah-delta-context3/1188_delta_t1_de6mt3g.json\n","sampled-threads-ah-delta-context3/934_delta_t1_db6yp23.json\n","sampled-threads-ah-delta-context3/115_delta_t1_djff4cp.json\n","sampled-threads-ah-delta-context3/28_ah_t1_cpf7p28.json\n","sampled-threads-ah-delta-context3/1235_delta_t1_dfvxnin.json\n","sampled-threads-ah-delta-context3/1113_delta_t1_cyp689t.json\n","sampled-threads-ah-delta-context3/184_ah_t1_cy0wmb8.json\n","sampled-threads-ah-delta-context3/348_delta_t1_cu13vwx.json\n","sampled-threads-ah-delta-context3/805_ah_t1_dgywa17.json\n","sampled-threads-ah-delta-context3/1029_ah_t1_dmxrbsc.json\n","sampled-threads-ah-delta-context3/866_ah_t1_cj56s40.json\n","sampled-threads-ah-delta-context3/278_ah_t1_dn9ohdw.json\n","sampled-threads-ah-delta-context3/338_ah_t1_d12c6kb.json\n","sampled-threads-ah-delta-context3/335_ah_t1_dkmun3n.json\n","sampled-threads-ah-delta-context3/15_delta_t1_dbavp9f.json\n","sampled-threads-ah-delta-context3/1194_ah_t1_d8fdroy.json\n","sampled-threads-ah-delta-context3/542_ah_t1_dl9k00j.json\n","sampled-threads-ah-delta-context3/33_ah_t1_dlcts7m.json\n","sampled-threads-ah-delta-context3/899_ah_t1_czk0ma2.json\n","sampled-threads-ah-delta-context3/1006_delta_t1_dg81i6d.json\n","sampled-threads-ah-delta-context3/1184_ah_t1_cixoyhg.json\n","sampled-threads-ah-delta-context3/528_delta_t1_dfvr7bb.json\n","sampled-threads-ah-delta-context3/697_ah_t1_ddjx7f1.json\n","sampled-threads-ah-delta-context3/395_delta_t1_cbreueo.json\n","sampled-threads-ah-delta-context3/987_delta_t1_cttt61p.json\n","sampled-threads-ah-delta-context3/506_delta_t1_cwd3s32.json\n","sampled-threads-ah-delta-context3/219_ah_t1_dixke3a.json\n","sampled-threads-ah-delta-context3/924_delta_t1_dgc6qb0.json\n","sampled-threads-ah-delta-context3/540_ah_t1_djwxvqx.json\n","sampled-threads-ah-delta-context3/470_delta_t1_ciqsjf5.json\n","sampled-threads-ah-delta-context3/1043_delta_t1_cdib3vv.json\n","sampled-threads-ah-delta-context3/994_delta_t1_cedn4m3.json\n","sampled-threads-ah-delta-context3/535_ah_t1_cmw8lci.json\n","sampled-threads-ah-delta-context3/411_ah_t1_d8a7rr6.json\n","sampled-threads-ah-delta-context3/179_ah_t1_cx93sy5.json\n","sampled-threads-ah-delta-context3/168_ah_t1_dk943l3.json\n","sampled-threads-ah-delta-context3/1029_delta_t1_dgxnzin.json\n","sampled-threads-ah-delta-context3/8_delta_t1_d7bv9tt.json\n","sampled-threads-ah-delta-context3/36_ah_t1_cy8rtpa.json\n","sampled-threads-ah-delta-context3/568_delta_t1_d6qjtyh.json\n","sampled-threads-ah-delta-context3/117_delta_t1_d6y1dfc.json\n","sampled-threads-ah-delta-context3/1154_delta_t1_dlnjq9e.json\n","sampled-threads-ah-delta-context3/123_delta_t1_cga72lg.json\n","sampled-threads-ah-delta-context3/352_delta_t1_d21i9e7.json\n","sampled-threads-ah-delta-context3/620_delta_t1_d85s41h.json\n","sampled-threads-ah-delta-context3/898_ah_t1_da2ptfr.json\n","sampled-threads-ah-delta-context3/379_delta_t1_d8rti5x.json\n","sampled-threads-ah-delta-context3/933_delta_t1_crg3dwf.json\n","sampled-threads-ah-delta-context3/1115_delta_t1_dlkpmr5.json\n","sampled-threads-ah-delta-context3/1028_ah_t1_co8rssj.json\n","sampled-threads-ah-delta-context3/1136_ah_t1_ctms47u.json\n","sampled-threads-ah-delta-context3/1091_ah_t1_d5yjo56.json\n","sampled-threads-ah-delta-context3/767_delta_t1_cu41hav.json\n","sampled-threads-ah-delta-context3/58_ah_t1_cjic6hz.json\n","sampled-threads-ah-delta-context3/571_ah_t1_dfrciys.json\n","sampled-threads-ah-delta-context3/193_ah_t1_d20a3by.json\n","sampled-threads-ah-delta-context3/597_delta_t1_djelo7h.json\n","sampled-threads-ah-delta-context3/897_ah_t1_cwzgki4.json\n","sampled-threads-ah-delta-context3/326_ah_t1_cvek3qg.json\n","sampled-threads-ah-delta-context3/1129_ah_t1_dgsq4cw.json\n","sampled-threads-ah-delta-context3/1120_delta_t1_d26d7iy.json\n","sampled-threads-ah-delta-context3/118_ah_t1_dd2aife.json\n","sampled-threads-ah-delta-context3/261_delta_t1_dbsj3ij.json\n","sampled-threads-ah-delta-context3/823_ah_t1_cle91a2.json\n","sampled-threads-ah-delta-context3/111_ah_t1_dmz4lt4.json\n","sampled-threads-ah-delta-context3/132_ah_t1_csrkmor.json\n","sampled-threads-ah-delta-context3/798_delta_t1_cetkblp.json\n","sampled-threads-ah-delta-context3/699_delta_t1_dddtej8.json\n","sampled-threads-ah-delta-context3/498_ah_t1_d7ppinf.json\n","sampled-threads-ah-delta-context3/451_ah_t1_d1l7obw.json\n","sampled-threads-ah-delta-context3/169_ah_t1_dmxmzcs.json\n","sampled-threads-ah-delta-context3/683_ah_t1_cqfpyn7.json\n","sampled-threads-ah-delta-context3/990_delta_t1_cu162ky.json\n","sampled-threads-ah-delta-context3/1127_ah_t1_dicxjf5.json\n","sampled-threads-ah-delta-context3/580_ah_t1_d6ubpjw.json\n","sampled-threads-ah-delta-context3/512_delta_t1_ddkqlv0.json\n","sampled-threads-ah-delta-context3/952_delta_t1_dibuq8k.json\n","sampled-threads-ah-delta-context3/250_ah_t1_cm5plrh.json\n","sampled-threads-ah-delta-context3/837_ah_t1_dloi8qz.json\n","sampled-threads-ah-delta-context3/1276_delta_t1_dftmcvb.json\n","sampled-threads-ah-delta-context3/70_delta_t1_dctegi4.json\n","sampled-threads-ah-delta-context3/957_delta_t1_dhj133k.json\n","sampled-threads-ah-delta-context3/1279_ah_t1_dm89eyx.json\n","sampled-threads-ah-delta-context3/1135_delta_t1_cgnbcfn.json\n","sampled-threads-ah-delta-context3/324_ah_t1_ddszug6.json\n","sampled-threads-ah-delta-context3/1205_delta_t1_d97atzw.json\n","sampled-threads-ah-delta-context3/1228_ah_t1_d5tfwpu.json\n","sampled-threads-ah-delta-context3/964_ah_t1_d2gj2ly.json\n","sampled-threads-ah-delta-context3/1275_delta_t1_dez6tte.json\n","sampled-threads-ah-delta-context3/155_delta_t1_dludhte.json\n","sampled-threads-ah-delta-context3/1094_ah_t1_daqp1tl.json\n","sampled-threads-ah-delta-context3/918_ah_t1_cvq7fbd.json\n","sampled-threads-ah-delta-context3/1279_delta_t1_dgiowsc.json\n","sampled-threads-ah-delta-context3/858_ah_t1_d0ud32b.json\n","sampled-threads-ah-delta-context3/1028_delta_t1_dg9lgvr.json\n","sampled-threads-ah-delta-context3/547_ah_t1_d4oqjkc.json\n","sampled-threads-ah-delta-context3/488_ah_t1_dkw45ez.json\n","sampled-threads-ah-delta-context3/1074_ah_t1_dfi6ggs.json\n","sampled-threads-ah-delta-context3/770_delta_t1_dkeyemo.json\n","sampled-threads-ah-delta-context3/969_ah_t1_ckymx9s.json\n","sampled-threads-ah-delta-context3/1118_ah_t1_dn9tvt9.json\n","sampled-threads-ah-delta-context3/1026_ah_t1_cwmekk1.json\n","sampled-threads-ah-delta-context3/726_ah_t1_djru4x6.json\n","sampled-threads-ah-delta-context3/1140_delta_t1_cp5olkr.json\n","sampled-threads-ah-delta-context3/617_ah_t1_dldohui.json\n","sampled-threads-ah-delta-context3/1128_ah_t1_cln26m5.json\n","sampled-threads-ah-delta-context3/386_delta_t1_dfctcvt.json\n","sampled-threads-ah-delta-context3/84_delta_t1_cj1p7t8.json\n","sampled-threads-ah-delta-context3/255_ah_t1_djrfjcn.json\n","sampled-threads-ah-delta-context3/1216_ah_t1_dde8g9h.json\n","sampled-threads-ah-delta-context3/1252_delta_t1_dlnsmk9.json\n","sampled-threads-ah-delta-context3/429_delta_t1_dmapzsk.json\n","sampled-threads-ah-delta-context3/54_ah_t1_daetigw.json\n","sampled-threads-ah-delta-context3/966_delta_t1_dlo4y0s.json\n","sampled-threads-ah-delta-context3/1268_ah_t1_dmpg415.json\n","sampled-threads-ah-delta-context3/972_delta_t1_ck4c6rd.json\n","sampled-threads-ah-delta-context3/44_ah_t1_d2vpyf8.json\n","sampled-threads-ah-delta-context3/205_delta_t1_d9fyhpd.json\n","sampled-threads-ah-delta-context3/736_delta_t1_coqxswz.json\n","sampled-threads-ah-delta-context3/247_ah_t1_csbik6f.json\n","sampled-threads-ah-delta-context3/1170_delta_t1_dmb6h33.json\n","sampled-threads-ah-delta-context3/916_ah_t1_ddx388z.json\n","sampled-threads-ah-delta-context3/66_delta_t1_cgo8sob.json\n","sampled-threads-ah-delta-context3/3_ah_t1_cqxdw1j.json\n","sampled-threads-ah-delta-context3/1235_ah_t1_cp4i9gl.json\n","sampled-threads-ah-delta-context3/110_delta_t1_d9vh3qv.json\n","sampled-threads-ah-delta-context3/791_ah_t1_db1j8uz.json\n","sampled-threads-ah-delta-context3/671_ah_t1_d3wcyg7.json\n","sampled-threads-ah-delta-context3/1183_delta_t1_cb98xd8.json\n","sampled-threads-ah-delta-context3/797_delta_t1_dicam2w.json\n","sampled-threads-ah-delta-context3/153_delta_t1_datp9ks.json\n","sampled-threads-ah-delta-context3/438_delta_t1_d5ysdpw.json\n","sampled-threads-ah-delta-context3/493_delta_t1_cn4cvhm.json\n","sampled-threads-ah-delta-context3/951_ah_t1_cm5fzjj.json\n","sampled-threads-ah-delta-context3/791_delta_t1_dd2ityp.json\n","sampled-threads-ah-delta-context3/351_ah_t1_de59vhg.json\n","sampled-threads-ah-delta-context3/363_delta_t1_cjh4mzp.json\n","sampled-threads-ah-delta-context3/931_delta_t1_cclty2a.json\n","sampled-threads-ah-delta-context3/1200_ah_t1_cjz0coi.json\n","sampled-threads-ah-delta-context3/1123_ah_t1_cux0ggf.json\n","sampled-threads-ah-delta-context3/113_ah_t1_cxt1te8.json\n","sampled-threads-ah-delta-context3/1169_ah_t1_crgtooi.json\n","sampled-threads-ah-delta-context3/298_ah_t1_cwegrvf.json\n","sampled-threads-ah-delta-context3/347_ah_t1_cle1fhu.json\n","sampled-threads-ah-delta-context3/576_delta_t1_dfnwxy0.json\n","sampled-threads-ah-delta-context3/102_ah_t1_dikfhc8.json\n","sampled-threads-ah-delta-context3/511_ah_t1_ddbag88.json\n","sampled-threads-ah-delta-context3/172_delta_t1_cj2rblk.json\n","sampled-threads-ah-delta-context3/537_delta_t1_ct2cxmw.json\n","sampled-threads-ah-delta-context3/1093_ah_t1_corefkj.json\n","sampled-threads-ah-delta-context3/520_ah_t1_cpy74en.json\n","sampled-threads-ah-delta-context3/189_delta_t1_cpsqw8m.json\n","sampled-threads-ah-delta-context3/148_ah_t1_daowz8t.json\n","sampled-threads-ah-delta-context3/165_delta_t1_ci5gu70.json\n","sampled-threads-ah-delta-context3/1222_delta_t1_d2b2e8e.json\n","sampled-threads-ah-delta-context3/409_delta_t1_d2h10gd.json\n","sampled-threads-ah-delta-context3/218_delta_t1_dn03yms.json\n","sampled-threads-ah-delta-context3/1052_delta_t1_deta2cp.json\n","sampled-threads-ah-delta-context3/841_ah_t1_d1ctjxl.json\n","sampled-threads-ah-delta-context3/184_delta_t1_dbdw12o.json\n","sampled-threads-ah-delta-context3/642_ah_t1_d982f79.json\n","sampled-threads-ah-delta-context3/1039_ah_t1_d4kssen.json\n","sampled-threads-ah-delta-context3/286_delta_t1_dm6fz6d.json\n","sampled-threads-ah-delta-context3/208_delta_t1_dcffg0z.json\n","sampled-threads-ah-delta-context3/439_delta_t1_dj2b1a2.json\n","sampled-threads-ah-delta-context3/502_ah_t1_cjbesvp.json\n","sampled-threads-ah-delta-context3/691_delta_t1_cav9rph.json\n","sampled-threads-ah-delta-context3/419_delta_t1_d67fyx7.json\n","sampled-threads-ah-delta-context3/780_ah_t1_d794pgn.json\n","sampled-threads-ah-delta-context3/773_delta_t1_cnconu7.json\n","sampled-threads-ah-delta-context3/297_delta_t1_dfupnxw.json\n","sampled-threads-ah-delta-context3/327_delta_t1_ck0dzl8.json\n","sampled-threads-ah-delta-context3/656_delta_t1_d9y1p83.json\n","sampled-threads-ah-delta-context3/277_delta_t1_cnw8yu6.json\n","sampled-threads-ah-delta-context3/198_ah_t1_cxf24ou.json\n","sampled-threads-ah-delta-context3/358_ah_t1_d1i0p29.json\n","sampled-threads-ah-delta-context3/670_ah_t1_diod6u1.json\n","sampled-threads-ah-delta-context3/932_ah_t1_cx4gn74.json\n","sampled-threads-ah-delta-context3/1257_ah_t1_dith3ia.json\n","sampled-threads-ah-delta-context3/884_ah_t1_dmydka7.json\n","sampled-threads-ah-delta-context3/628_ah_t1_dl7unr7.json\n","sampled-threads-ah-delta-context3/838_delta_t1_cl6zbs8.json\n","sampled-threads-ah-delta-context3/1037_ah_t1_d8zqaqu.json\n","sampled-threads-ah-delta-context3/981_ah_t1_divrjj9.json\n","sampled-threads-ah-delta-context3/583_delta_t1_ci4u323.json\n","sampled-threads-ah-delta-context3/937_delta_t1_dmpm1ps.json\n","sampled-threads-ah-delta-context3/609_ah_t1_d8is5qy.json\n","sampled-threads-ah-delta-context3/1018_delta_t1_d5mzqrx.json\n","sampled-threads-ah-delta-context3/259_delta_t1_djfg2n7.json\n","sampled-threads-ah-delta-context3/819_ah_t1_d9q0q82.json\n","sampled-threads-ah-delta-context3/1109_ah_t1_dff7ot7.json\n","sampled-threads-ah-delta-context3/502_delta_t1_cwii76r.json\n","sampled-threads-ah-delta-context3/374_delta_t1_cf37u4w.json\n","sampled-threads-ah-delta-context3/595_delta_t1_cqbnf5c.json\n","sampled-threads-ah-delta-context3/1082_delta_t1_cdhy9nr.json\n","sampled-threads-ah-delta-context3/393_ah_t1_ctuzcru.json\n","sampled-threads-ah-delta-context3/930_delta_t1_cyjz9ia.json\n","sampled-threads-ah-delta-context3/305_ah_t1_d3uys5a.json\n","sampled-threads-ah-delta-context3/886_ah_t1_de976m1.json\n","sampled-threads-ah-delta-context3/1067_ah_t1_d3ms657.json\n","sampled-threads-ah-delta-context3/75_ah_t1_dlofn5f.json\n","sampled-threads-ah-delta-context3/782_ah_t1_dfack4x.json\n","sampled-threads-ah-delta-context3/1085_ah_t1_d79yn6z.json\n","sampled-threads-ah-delta-context3/224_ah_t1_cvqtzq2.json\n","sampled-threads-ah-delta-context3/810_delta_t1_cro6ha5.json\n","sampled-threads-ah-delta-context3/151_delta_t1_cbwv18x.json\n","sampled-threads-ah-delta-context3/901_ah_t1_d4a1gax.json\n","sampled-threads-ah-delta-context3/379_ah_t1_dmylxgx.json\n","sampled-threads-ah-delta-context3/928_ah_t1_d4dc8wb.json\n","sampled-threads-ah-delta-context3/1110_delta_t1_dlfmxhk.json\n","sampled-threads-ah-delta-context3/630_ah_t1_d389i9y.json\n","sampled-threads-ah-delta-context3/266_delta_t1_cr101vd.json\n","sampled-threads-ah-delta-context3/983_delta_t1_ci2d63x.json\n","sampled-threads-ah-delta-context3/187_delta_t1_cl5xluk.json\n","sampled-threads-ah-delta-context3/542_delta_t1_ddqlu68.json\n","sampled-threads-ah-delta-context3/976_delta_t1_ddj7pno.json\n","sampled-threads-ah-delta-context3/813_ah_t1_dd0ughj.json\n","sampled-threads-ah-delta-context3/991_ah_t1_cjtsbnn.json\n","sampled-threads-ah-delta-context3/1064_ah_t1_d4cyzp7.json\n","sampled-threads-ah-delta-context3/371_delta_t1_czoirwn.json\n","sampled-threads-ah-delta-context3/268_ah_t1_dmcndf0.json\n","sampled-threads-ah-delta-context3/1025_ah_t1_dgc11xf.json\n","sampled-threads-ah-delta-context3/1062_ah_t1_d770bg4.json\n","sampled-threads-ah-delta-context3/644_ah_t1_dgax5dq.json\n","sampled-threads-ah-delta-context3/34_ah_t1_d7phadg.json\n","sampled-threads-ah-delta-context3/583_ah_t1_dlus0kr.json\n","sampled-threads-ah-delta-context3/1205_ah_t1_d7uajzs.json\n","sampled-threads-ah-delta-context3/23_ah_t1_cueh6ho.json\n","sampled-threads-ah-delta-context3/992_ah_t1_d0mw6ev.json\n","sampled-threads-ah-delta-context3/262_ah_t1_da1r78m.json\n","sampled-threads-ah-delta-context3/688_delta_t1_dfhe8cx.json\n","sampled-threads-ah-delta-context3/917_ah_t1_dj5hy4o.json\n","sampled-threads-ah-delta-context3/18_delta_t1_d3ksz4j.json\n","sampled-threads-ah-delta-context3/406_delta_t1_cqcl3qp.json\n","sampled-threads-ah-delta-context3/311_ah_t1_cv3wo2m.json\n","sampled-threads-ah-delta-context3/687_ah_t1_dchw3kn.json\n","sampled-threads-ah-delta-context3/561_delta_t1_cbjtznc.json\n","sampled-threads-ah-delta-context3/923_ah_t1_cys1ffy.json\n","sampled-threads-ah-delta-context3/725_ah_t1_dl0tdwo.json\n","sampled-threads-ah-delta-context3/485_delta_t1_dgewga4.json\n","sampled-threads-ah-delta-context3/718_ah_t1_djka87l.json\n","sampled-threads-ah-delta-context3/81_delta_t1_cre2rtw.json\n","sampled-threads-ah-delta-context3/1118_delta_t1_d6g7uww.json\n","sampled-threads-ah-delta-context3/544_ah_t1_da18ock.json\n","sampled-threads-ah-delta-context3/611_delta_t1_dk5cf8k.json\n","sampled-threads-ah-delta-context3/1149_delta_t1_ctta7bh.json\n","sampled-threads-ah-delta-context3/1145_delta_t1_dlh8xjo.json\n","sampled-threads-ah-delta-context3/196_delta_t1_cwbley3.json\n","sampled-threads-ah-delta-context3/885_delta_t1_dgxd5lh.json\n","sampled-threads-ah-delta-context3/468_ah_t1_cmf3730.json\n","sampled-threads-ah-delta-context3/294_ah_t1_dk0cl8s.json\n","sampled-threads-ah-delta-context3/1152_ah_t1_cry7c9x.json\n","sampled-threads-ah-delta-context3/185_ah_t1_dlpm06v.json\n","sampled-threads-ah-delta-context3/835_ah_t1_de1nmso.json\n","sampled-threads-ah-delta-context3/970_ah_t1_clxpmbh.json\n","sampled-threads-ah-delta-context3/31_delta_t1_cp6jlf1.json\n","sampled-threads-ah-delta-context3/202_delta_t1_d17rsmo.json\n","sampled-threads-ah-delta-context3/296_delta_t1_dgkbde7.json\n","sampled-threads-ah-delta-context3/382_delta_t1_czpjhy4.json\n","sampled-threads-ah-delta-context3/1092_ah_t1_dcr4rr6.json\n","sampled-threads-ah-delta-context3/1054_ah_t1_ddoje0w.json\n","sampled-threads-ah-delta-context3/15_ah_t1_cmd3fnu.json\n","sampled-threads-ah-delta-context3/1083_delta_t1_d5c7sdc.json\n","sampled-threads-ah-delta-context3/1195_delta_t1_cjs2syv.json\n","sampled-threads-ah-delta-context3/1273_delta_t1_cty2j1b.json\n","sampled-threads-ah-delta-context3/279_delta_t1_cmamie1.json\n","sampled-threads-ah-delta-context3/4_ah_t1_cqlbxg5.json\n","sampled-threads-ah-delta-context3/226_delta_t1_cmqn770.json\n","sampled-threads-ah-delta-context3/995_delta_t1_cp67itd.json\n","sampled-threads-ah-delta-context3/453_delta_t1_dm2h0al.json\n","sampled-threads-ah-delta-context3/1054_delta_t1_d87wi5s.json\n","sampled-threads-ah-delta-context3/685_ah_t1_d5tkxnk.json\n","sampled-threads-ah-delta-context3/613_delta_t1_d8hpd1x.json\n","sampled-threads-ah-delta-context3/216_delta_t1_d47t3cr.json\n","sampled-threads-ah-delta-context3/57_ah_t1_dgtrtf1.json\n","sampled-threads-ah-delta-context3/740_ah_t1_dh203k3.json\n","sampled-threads-ah-delta-context3/830_ah_t1_cso844j.json\n","sampled-threads-ah-delta-context3/357_delta_t1_cb8ie7q.json\n","sampled-threads-ah-delta-context3/284_delta_t1_diulrcz.json\n","sampled-threads-ah-delta-context3/1167_delta_t1_caob4os.json\n","sampled-threads-ah-delta-context3/1101_delta_t1_cc69zel.json\n","sampled-threads-ah-delta-context3/817_ah_t1_cs94l8c.json\n","sampled-threads-ah-delta-context3/1283_delta_t1_cq9dznx.json\n","sampled-threads-ah-delta-context3/1013_ah_t1_dduzmbu.json\n","sampled-threads-ah-delta-context3/902_delta_t1_d7u61am.json\n","sampled-threads-ah-delta-context3/392_delta_t1_cvoopqv.json\n","sampled-threads-ah-delta-context3/786_delta_t1_dek2z3l.json\n","sampled-threads-ah-delta-context3/57_delta_t1_dbjhodt.json\n","sampled-threads-ah-delta-context3/1006_ah_t1_dhuslbl.json\n","sampled-threads-ah-delta-context3/833_ah_t1_d0s2ak2.json\n","sampled-threads-ah-delta-context3/1034_delta_t1_d06h7x8.json\n","sampled-threads-ah-delta-context3/845_delta_t1_dfp5c88.json\n","sampled-threads-ah-delta-context3/107_delta_t1_cehzrti.json\n","sampled-threads-ah-delta-context3/1092_delta_t1_djb7a2d.json\n","sampled-threads-ah-delta-context3/142_delta_t1_dec81pi.json\n","sampled-threads-ah-delta-context3/204_ah_t1_d0hap7t.json\n","sampled-threads-ah-delta-context3/619_delta_t1_dlej1g7.json\n","sampled-threads-ah-delta-context3/330_delta_t1_ctvctui.json\n","sampled-threads-ah-delta-context3/804_delta_t1_cxc90y8.json\n","sampled-threads-ah-delta-context3/92_delta_t1_cfrctgl.json\n","sampled-threads-ah-delta-context3/434_delta_t1_daxwj61.json\n","sampled-threads-ah-delta-context3/1162_delta_t1_dkr9j1d.json\n","sampled-threads-ah-delta-context3/381_ah_t1_dfw16mv.json\n","sampled-threads-ah-delta-context3/1267_ah_t1_d4pv4np.json\n","sampled-threads-ah-delta-context3/360_delta_t1_cyesjlm.json\n","sampled-threads-ah-delta-context3/661_delta_t1_cdztdn3.json\n","sampled-threads-ah-delta-context3/89_delta_t1_dka3cot.json\n","sampled-threads-ah-delta-context3/100_ah_t1_d6f1qdf.json\n","sampled-threads-ah-delta-context3/163_delta_t1_dln141x.json\n","sampled-threads-ah-delta-context3/872_ah_t1_dbzdk74.json\n","sampled-threads-ah-delta-context3/641_delta_t1_cdxmt8j.json\n","sampled-threads-ah-delta-context3/301_ah_t1_dft9fvl.json\n","sampled-threads-ah-delta-context3/321_ah_t1_dl1aamw.json\n","sampled-threads-ah-delta-context3/842_delta_t1_cgkrdkk.json\n","sampled-threads-ah-delta-context3/29_delta_t1_djy6kni.json\n","sampled-threads-ah-delta-context3/1207_delta_t1_d73nin0.json\n","sampled-threads-ah-delta-context3/95_delta_t1_d8mc4jy.json\n","sampled-threads-ah-delta-context3/375_ah_t1_d0zpwzz.json\n","sampled-threads-ah-delta-context3/1160_ah_t1_dlpu8ih.json\n","sampled-threads-ah-delta-context3/1058_ah_t1_daruhhf.json\n","sampled-threads-ah-delta-context3/495_ah_t1_cjcjx7d.json\n","sampled-threads-ah-delta-context3/230_ah_t1_d03ctwq.json\n","sampled-threads-ah-delta-context3/638_ah_t1_dh2wuy7.json\n","sampled-threads-ah-delta-context3/85_ah_t1_d1iw4qk.json\n","sampled-threads-ah-delta-context3/730_delta_t1_dgdputo.json\n","sampled-threads-ah-delta-context3/407_ah_t1_ddx95dk.json\n","sampled-threads-ah-delta-context3/848_delta_t1_cvirhcl.json\n","sampled-threads-ah-delta-context3/921_ah_t1_d0aho3t.json\n","sampled-threads-ah-delta-context3/323_ah_t1_dksys08.json\n","sampled-threads-ah-delta-context3/0_delta_t1_dk3zd9h.json\n","sampled-threads-ah-delta-context3/321_delta_t1_d31zvkc.json\n","sampled-threads-ah-delta-context3/237_ah_t1_cpu3y8b.json\n","sampled-threads-ah-delta-context3/1165_ah_t1_dbc097o.json\n","sampled-threads-ah-delta-context3/14_ah_t1_cnb980x.json\n","sampled-threads-ah-delta-context3/1225_ah_t1_dmz16fc.json\n","sampled-threads-ah-delta-context3/277_ah_t1_d2e1czy.json\n","sampled-threads-ah-delta-context3/1186_delta_t1_df2bjzr.json\n","sampled-threads-ah-delta-context3/538_delta_t1_d99fvo8.json\n","sampled-threads-ah-delta-context3/61_delta_t1_den3t84.json\n","sampled-threads-ah-delta-context3/267_ah_t1_depw64x.json\n","sampled-threads-ah-delta-context3/669_delta_t1_dmafxzr.json\n","sampled-threads-ah-delta-context3/1146_delta_t1_dfupzab.json\n","sampled-threads-ah-delta-context3/1281_delta_t1_df86znr.json\n","sampled-threads-ah-delta-context3/116_delta_t1_dl278i9.json\n","sampled-threads-ah-delta-context3/156_delta_t1_de8k0c8.json\n","sampled-threads-ah-delta-context3/608_ah_t1_cmn2znu.json\n","sampled-threads-ah-delta-context3/479_delta_t1_cc75sb7.json\n","sampled-threads-ah-delta-context3/308_delta_t1_ddtsnth.json\n","sampled-threads-ah-delta-context3/867_delta_t1_d7qgjmd.json\n","sampled-threads-ah-delta-context3/911_delta_t1_dknpjmc.json\n","sampled-threads-ah-delta-context3/620_ah_t1_d21mwza.json\n","sampled-threads-ah-delta-context3/521_ah_t1_d05clyk.json\n","sampled-threads-ah-delta-context3/567_delta_t1_dminunh.json\n","sampled-threads-ah-delta-context3/350_ah_t1_d1yfw4i.json\n","sampled-threads-ah-delta-context3/139_ah_t1_cmckspi.json\n","sampled-threads-ah-delta-context3/1240_delta_t1_d5bdf0e.json\n","sampled-threads-ah-delta-context3/681_ah_t1_d93u9kw.json\n","sampled-threads-ah-delta-context3/426_ah_t1_cyrz5da.json\n","sampled-threads-ah-delta-context3/965_delta_t1_ddphykd.json\n","sampled-threads-ah-delta-context3/710_delta_t1_d2v90lz.json\n","sampled-threads-ah-delta-context3/230_delta_t1_d6z1l3o.json\n","sampled-threads-ah-delta-context3/204_delta_t1_cneruuv.json\n","sampled-threads-ah-delta-context3/302_delta_t1_dk57ugv.json\n","sampled-threads-ah-delta-context3/463_delta_t1_d36efbd.json\n","sampled-threads-ah-delta-context3/764_delta_t1_dhqwy01.json\n","sampled-threads-ah-delta-context3/1206_delta_t1_defnley.json\n","sampled-threads-ah-delta-context3/1240_ah_t1_d0r1157.json\n","sampled-threads-ah-delta-context3/1078_ah_t1_d1kqy96.json\n","sampled-threads-ah-delta-context3/639_ah_t1_d2eqs89.json\n","sampled-threads-ah-delta-context3/82_delta_t1_cfn6fka.json\n","sampled-threads-ah-delta-context3/874_ah_t1_d8z2fgx.json\n","sampled-threads-ah-delta-context3/455_delta_t1_d8fjzbb.json\n","sampled-threads-ah-delta-context3/182_delta_t1_d6lm6uh.json\n","sampled-threads-ah-delta-context3/1086_ah_t1_djilj72.json\n","sampled-threads-ah-delta-context3/389_delta_t1_cx74eip.json\n","sampled-threads-ah-delta-context3/811_delta_t1_dhwdph1.json\n","sampled-threads-ah-delta-context3/245_ah_t1_dln0j75.json\n","sampled-threads-ah-delta-context3/198_delta_t1_chxu2ly.json\n","sampled-threads-ah-delta-context3/36_delta_t1_ci9dfu3.json\n","sampled-threads-ah-delta-context3/905_delta_t1_cpje18r.json\n","sampled-threads-ah-delta-context3/538_ah_t1_d5qtk6v.json\n","sampled-threads-ah-delta-context3/882_delta_t1_chtd179.json\n","sampled-threads-ah-delta-context3/453_ah_t1_dc5zk07.json\n","sampled-threads-ah-delta-context3/526_delta_t1_cfthbvs.json\n","sampled-threads-ah-delta-context3/27_delta_t1_cf2yzfh.json\n","sampled-threads-ah-delta-context3/18_ah_t1_dcib8j9.json\n","sampled-threads-ah-delta-context3/1066_delta_t1_cl53j7s.json\n","sampled-threads-ah-delta-context3/395_ah_t1_dmflkkr.json\n","sampled-threads-ah-delta-context3/25_delta_t1_csexkhd.json\n","sampled-threads-ah-delta-context3/790_ah_t1_cjut30h.json\n","sampled-threads-ah-delta-context3/748_delta_t1_clzic7j.json\n","sampled-threads-ah-delta-context3/767_ah_t1_cvjh1ix.json\n","sampled-threads-ah-delta-context3/961_ah_t1_d8tasj0.json\n","sampled-threads-ah-delta-context3/916_delta_t1_cxdbb86.json\n","sampled-threads-ah-delta-context3/1231_delta_t1_d3o1iw7.json\n","sampled-threads-ah-delta-context3/1014_delta_t1_dfrvoys.json\n","sampled-threads-ah-delta-context3/783_delta_t1_d1immdd.json\n","sampled-threads-ah-delta-context3/33_delta_t1_cimgtdv.json\n","sampled-threads-ah-delta-context3/1174_delta_t1_dbk2r5x.json\n","sampled-threads-ah-delta-context3/966_ah_t1_dmm4f1v.json\n","sampled-threads-ah-delta-context3/491_ah_t1_cu1m56p.json\n","sampled-threads-ah-delta-context3/603_delta_t1_cgj6xtq.json\n","sampled-threads-ah-delta-context3/747_delta_t1_coxhy3u.json\n","sampled-threads-ah-delta-context3/226_ah_t1_dlpeztr.json\n","sampled-threads-ah-delta-context3/325_ah_t1_dk02fj2.json\n","sampled-threads-ah-delta-context3/182_ah_t1_dl5bau7.json\n","sampled-threads-ah-delta-context3/1178_delta_t1_chsicpu.json\n","sampled-threads-ah-delta-context3/717_delta_t1_dibi4cc.json\n","sampled-threads-ah-delta-context3/572_ah_t1_cpctoio.json\n","sampled-threads-ah-delta-context3/229_ah_t1_dh3kj2f.json\n","sampled-threads-ah-delta-context3/650_delta_t1_cbylgdi.json\n","sampled-threads-ah-delta-context3/334_delta_t1_cgneaye.json\n","sampled-threads-ah-delta-context3/959_delta_t1_cftw8r2.json\n","sampled-threads-ah-delta-context3/133_ah_t1_d13oh2a.json\n","sampled-threads-ah-delta-context3/91_delta_t1_dg6m8ye.json\n","sampled-threads-ah-delta-context3/727_ah_t1_d2ptbtr.json\n","sampled-threads-ah-delta-context3/383_ah_t1_dfwn5ka.json\n","sampled-threads-ah-delta-context3/863_ah_t1_d162g2p.json\n","sampled-threads-ah-delta-context3/120_delta_t1_d9t05bv.json\n","sampled-threads-ah-delta-context3/34_delta_t1_cghplp8.json\n","sampled-threads-ah-delta-context3/364_delta_t1_chea97b.json\n","sampled-threads-ah-delta-context3/693_ah_t1_dht4d8v.json\n","sampled-threads-ah-delta-context3/385_ah_t1_dmifd8n.json\n","sampled-threads-ah-delta-context3/646_delta_t1_dbw86ji.json\n","sampled-threads-ah-delta-context3/815_delta_t1_coj5fan.json\n","sampled-threads-ah-delta-context3/549_delta_t1_clf4ztm.json\n","sampled-threads-ah-delta-context3/245_delta_t1_cug4crz.json\n","sampled-threads-ah-delta-context3/740_delta_t1_dcsjk59.json\n","sampled-threads-ah-delta-context3/298_delta_t1_cyw0xr0.json\n","sampled-threads-ah-delta-context3/522_delta_t1_dmcnrpi.json\n","sampled-threads-ah-delta-context3/833_delta_t1_cxsvi7r.json\n","sampled-threads-ah-delta-context3/452_delta_t1_dlrow8c.json\n","sampled-threads-ah-delta-context3/271_delta_t1_crgs4wu.json\n","sampled-threads-ah-delta-context3/921_delta_t1_djc0fz3.json\n","sampled-threads-ah-delta-context3/503_ah_t1_d05lwku.json\n","sampled-threads-ah-delta-context3/356_delta_t1_cf8s39d.json\n","sampled-threads-ah-delta-context3/758_delta_t1_c9s17ah.json\n","sampled-threads-ah-delta-context3/584_delta_t1_d9xf92p.json\n","sampled-threads-ah-delta-context3/260_ah_t1_dmvgsig.json\n","sampled-threads-ah-delta-context3/728_ah_t1_deu33nd.json\n","sampled-threads-ah-delta-context3/1062_delta_t1_cwd3r4z.json\n","sampled-threads-ah-delta-context3/1023_ah_t1_cnhtuvm.json\n","sampled-threads-ah-delta-context3/584_ah_t1_dk0d017.json\n","sampled-threads-ah-delta-context3/483_delta_t1_d93n6bl.json\n","sampled-threads-ah-delta-context3/424_ah_t1_clr7qpi.json\n","sampled-threads-ah-delta-context3/1209_ah_t1_d7qzwbk.json\n","sampled-threads-ah-delta-context3/524_delta_t1_cr3urij.json\n","sampled-threads-ah-delta-context3/234_delta_t1_chl2dfb.json\n","sampled-threads-ah-delta-context3/97_ah_t1_d1uefqp.json\n","sampled-threads-ah-delta-context3/711_ah_t1_dd1k4g6.json\n","sampled-threads-ah-delta-context3/39_delta_t1_cda52l4.json\n","sampled-threads-ah-delta-context3/518_ah_t1_dm0w6tf.json\n","sampled-threads-ah-delta-context3/28_delta_t1_cflc1dv.json\n","sampled-threads-ah-delta-context3/706_ah_t1_d0h55nb.json\n","sampled-threads-ah-delta-context3/329_ah_t1_df7z5uc.json\n","sampled-threads-ah-delta-context3/841_delta_t1_ctlycgt.json\n","sampled-threads-ah-delta-context3/933_ah_t1_d2hd4fx.json\n","sampled-threads-ah-delta-context3/407_delta_t1_d9i57rm.json\n","sampled-threads-ah-delta-context3/1193_delta_t1_cd21ove.json\n","sampled-threads-ah-delta-context3/698_ah_t1_dlhisq5.json\n","sampled-threads-ah-delta-context3/352_ah_t1_cvg8i7p.json\n","sampled-threads-ah-delta-context3/1227_delta_t1_cyokq66.json\n","sampled-threads-ah-delta-context3/856_ah_t1_csq6gq7.json\n","sampled-threads-ah-delta-context3/1150_ah_t1_d1v872a.json\n","sampled-threads-ah-delta-context3/472_ah_t1_cjmnc11.json\n","sampled-threads-ah-delta-context3/1113_ah_t1_cw06d0t.json\n","sampled-threads-ah-delta-context3/709_delta_t1_crtmi2e.json\n","sampled-threads-ah-delta-context3/589_delta_t1_capr5lx.json\n","sampled-threads-ah-delta-context3/497_ah_t1_dc4wffa.json\n","sampled-threads-ah-delta-context3/1204_ah_t1_d3oon5x.json\n","sampled-threads-ah-delta-context3/687_delta_t1_czc261o.json\n","sampled-threads-ah-delta-context3/305_delta_t1_cu6rgck.json\n","sampled-threads-ah-delta-context3/150_delta_t1_dkul1lo.json\n","sampled-threads-ah-delta-context3/1087_ah_t1_d6kd6sy.json\n","sampled-threads-ah-delta-context3/53_delta_t1_crbz7gy.json\n","sampled-threads-ah-delta-context3/541_delta_t1_dk838kj.json\n","sampled-threads-ah-delta-context3/1236_ah_t1_d37j47w.json\n","sampled-threads-ah-delta-context3/778_delta_t1_dm9fzqj.json\n","sampled-threads-ah-delta-context3/40_delta_t1_d7wn0pr.json\n","sampled-threads-ah-delta-context3/477_ah_t1_d6cl8oj.json\n","sampled-threads-ah-delta-context3/285_ah_t1_dccmvar.json\n","sampled-threads-ah-delta-context3/702_delta_t1_cbslt59.json\n","sampled-threads-ah-delta-context3/587_ah_t1_cm7djx3.json\n","sampled-threads-ah-delta-context3/608_delta_t1_cc4gwbr.json\n","sampled-threads-ah-delta-context3/557_ah_t1_d3s3i1q.json\n","sampled-threads-ah-delta-context3/149_delta_t1_cl6t100.json\n","sampled-threads-ah-delta-context3/243_delta_t1_daugyu2.json\n","sampled-threads-ah-delta-context3/1130_delta_t1_dnbb1uu.json\n","sampled-threads-ah-delta-context3/177_delta_t1_dmdjt44.json\n","sampled-threads-ah-delta-context3/342_delta_t1_dnbbnd4.json\n","sampled-threads-ah-delta-context3/484_delta_t1_dhhlqvf.json\n","sampled-threads-ah-delta-context3/1072_delta_t1_cuzent7.json\n","sampled-threads-ah-delta-context3/1197_ah_t1_dk8e0w1.json\n","sampled-threads-ah-delta-context3/112_ah_t1_cslcchd.json\n","sampled-threads-ah-delta-context3/356_ah_t1_d37yiz7.json\n","sampled-threads-ah-delta-context3/529_ah_t1_clmcmmm.json\n","sampled-threads-ah-delta-context3/897_delta_t1_cqqpczg.json\n","sampled-threads-ah-delta-context3/850_ah_t1_dl7nacm.json\n","sampled-threads-ah-delta-context3/997_ah_t1_dldof1s.json\n","sampled-threads-ah-delta-context3/737_ah_t1_cxlaac6.json\n","sampled-threads-ah-delta-context3/225_delta_t1_cms66ua.json\n","sampled-threads-ah-delta-context3/108_delta_t1_d2h3hjp.json\n","sampled-threads-ah-delta-context3/525_ah_t1_djr9f3s.json\n","sampled-threads-ah-delta-context3/639_delta_t1_cvf2uil.json\n","sampled-threads-ah-delta-context3/638_delta_t1_dh0yxza.json\n","sampled-threads-ah-delta-context3/551_ah_t1_cyryr8e.json\n","sampled-threads-ah-delta-context3/218_ah_t1_dbl2mef.json\n","sampled-threads-ah-delta-context3/1000_delta_t1_cpzy2ya.json\n","sampled-threads-ah-delta-context3/738_delta_t1_d48i3bs.json\n","sampled-threads-ah-delta-context3/51_ah_t1_dcrnxzj.json\n","sampled-threads-ah-delta-context3/83_ah_t1_dc7he8r.json\n","sampled-threads-ah-delta-context3/1156_ah_t1_d3licda.json\n","sampled-threads-ah-delta-context3/10_ah_t1_dmrezmr.json\n","sampled-threads-ah-delta-context3/917_delta_t1_clcb390.json\n","sampled-threads-ah-delta-context3/1158_delta_t1_dn1g9b6.json\n","sampled-threads-ah-delta-context3/114_delta_t1_dhilwsp.json\n","sampled-threads-ah-delta-context3/328_delta_t1_cd7jxrv.json\n","sampled-threads-ah-delta-context3/119_delta_t1_d967f8v.json\n","sampled-threads-ah-delta-context3/122_delta_t1_cn77m9w.json\n","sampled-threads-ah-delta-context3/386_ah_t1_d9ughmy.json\n","sampled-threads-ah-delta-context3/1214_delta_t1_d64npey.json\n","sampled-threads-ah-delta-context3/236_delta_t1_dgmi7wb.json\n","sampled-threads-ah-delta-context3/66_ah_t1_d05mvk7.json\n","sampled-threads-ah-delta-context3/733_delta_t1_cuvlqi2.json\n","sampled-threads-ah-delta-context3/433_delta_t1_dbeotyy.json\n","sampled-threads-ah-delta-context3/763_ah_t1_dco1rsd.json\n","sampled-threads-ah-delta-context3/1031_delta_t1_dmin7ai.json\n","sampled-threads-ah-delta-context3/380_ah_t1_cu8cx9g.json\n","sampled-threads-ah-delta-context3/295_ah_t1_dk47mlo.json\n","sampled-threads-ah-delta-context3/1241_delta_t1_cip5iuo.json\n","sampled-threads-ah-delta-context3/285_delta_t1_dlus2v3.json\n","sampled-threads-ah-delta-context3/52_delta_t1_dia9opy.json\n","sampled-threads-ah-delta-context3/800_delta_t1_dj7v7y6.json\n","sampled-threads-ah-delta-context3/1202_delta_t1_ci6ndjo.json\n","sampled-threads-ah-delta-context3/342_ah_t1_de9sgl9.json\n","sampled-threads-ah-delta-context3/968_delta_t1_dkn94uw.json\n","sampled-threads-ah-delta-context3/442_ah_t1_dkusqfh.json\n","sampled-threads-ah-delta-context3/574_delta_t1_cktiou9.json\n","sampled-threads-ah-delta-context3/114_ah_t1_dal2goz.json\n","sampled-threads-ah-delta-context3/1096_delta_t1_cpd04jv.json\n","sampled-threads-ah-delta-context3/1258_ah_t1_d5msv3w.json\n","sampled-threads-ah-delta-context3/849_delta_t1_dfdmlq4.json\n","sampled-threads-ah-delta-context3/975_ah_t1_d1g3g90.json\n","sampled-threads-ah-delta-context3/257_ah_t1_dlayvn6.json\n","sampled-threads-ah-delta-context3/750_delta_t1_d6u6r2x.json\n","sampled-threads-ah-delta-context3/1011_delta_t1_diuxzey.json\n","sampled-threads-ah-delta-context3/388_ah_t1_cpdxmjj.json\n","sampled-threads-ah-delta-context3/42_delta_t1_ckus2ys.json\n","sampled-threads-ah-delta-context3/361_ah_t1_d13vf0t.json\n","sampled-threads-ah-delta-context3/650_ah_t1_d1qbf8p.json\n","sampled-threads-ah-delta-context3/217_delta_t1_cs8s4g1.json\n","sampled-threads-ah-delta-context3/482_delta_t1_cyt1ufo.json\n","sampled-threads-ah-delta-context3/760_delta_t1_cbf50ig.json\n","sampled-threads-ah-delta-context3/235_ah_t1_cqqpapu.json\n","sampled-threads-ah-delta-context3/550_delta_t1_dfsloqu.json\n","sampled-threads-ah-delta-context3/533_ah_t1_cvbsu3r.json\n","sampled-threads-ah-delta-context3/554_delta_t1_dftmoa0.json\n","sampled-threads-ah-delta-context3/863_delta_t1_df4o89e.json\n","sampled-threads-ah-delta-context3/456_delta_t1_cdj5vts.json\n","sampled-threads-ah-delta-context3/345_ah_t1_d8wv7ch.json\n","sampled-threads-ah-delta-context3/1097_ah_t1_d1td1z8.json\n","sampled-threads-ah-delta-context3/534_ah_t1_dm8s0jf.json\n","sampled-threads-ah-delta-context3/1233_delta_t1_cemusvf.json\n","sampled-threads-ah-delta-context3/1151_delta_t1_dd13ht8.json\n","sampled-threads-ah-delta-context3/596_ah_t1_dbuuu0a.json\n","sampled-threads-ah-delta-context3/476_delta_t1_cizpp5l.json\n","sampled-threads-ah-delta-context3/504_ah_t1_dmev5zo.json\n","sampled-threads-ah-delta-context3/381_delta_t1_cjqns9h.json\n","sampled-threads-ah-delta-context3/320_delta_t1_cigeyam.json\n","sampled-threads-ah-delta-context3/988_delta_t1_dhmoqnd.json\n","sampled-threads-ah-delta-context3/278_delta_t1_cj665qd.json\n","sampled-threads-ah-delta-context3/601_delta_t1_dj1h9c7.json\n","sampled-threads-ah-delta-context3/401_ah_t1_ck9nug9.json\n","sampled-threads-ah-delta-context3/270_delta_t1_cdxkd2p.json\n","sampled-threads-ah-delta-context3/519_delta_t1_crhpt1o.json\n","sampled-threads-ah-delta-context3/99_delta_t1_d6dk9zd.json\n","sampled-threads-ah-delta-context3/426_delta_t1_dh9md8x.json\n","sampled-threads-ah-delta-context3/1142_delta_t1_cst7976.json\n","sampled-threads-ah-delta-context3/1108_delta_t1_cnbkx62.json\n","sampled-threads-ah-delta-context3/1285_delta_t1_ch64ina.json\n","sampled-threads-ah-delta-context3/8_ah_t1_daser9z.json\n","sampled-threads-ah-delta-context3/223_ah_t1_daq5sr7.json\n","sampled-threads-ah-delta-context3/358_delta_t1_d6h0wwa.json\n","sampled-threads-ah-delta-context3/768_ah_t1_cvg88x9.json\n","sampled-threads-ah-delta-context3/808_ah_t1_denzw80.json\n","sampled-threads-ah-delta-context3/1179_delta_t1_dmyyl0b.json\n","sampled-threads-ah-delta-context3/67_delta_t1_cm1iwtg.json\n","sampled-threads-ah-delta-context3/996_delta_t1_cu2bhdp.json\n","sampled-threads-ah-delta-context3/677_delta_t1_dg9gokd.json\n","sampled-threads-ah-delta-context3/827_delta_t1_d9ul5l1.json\n","sampled-threads-ah-delta-context3/292_delta_t1_dn0qhhd.json\n","sampled-threads-ah-delta-context3/879_ah_t1_cxg7n98.json\n","sampled-threads-ah-delta-context3/481_ah_t1_cldp5l1.json\n","sampled-threads-ah-delta-context3/189_ah_t1_cqoqoum.json\n","sampled-threads-ah-delta-context3/449_delta_t1_d4rn8gy.json\n","sampled-threads-ah-delta-context3/492_ah_t1_crvt7qc.json\n","sampled-threads-ah-delta-context3/295_delta_t1_dbz9tu8.json\n","sampled-threads-ah-delta-context3/480_delta_t1_dmaem1q.json\n","sampled-threads-ah-delta-context3/766_delta_t1_cupfjet.json\n","sampled-threads-ah-delta-context3/1191_delta_t1_dg06xl6.json\n","sampled-threads-ah-delta-context3/249_ah_t1_dfhkj8e.json\n","sampled-threads-ah-delta-context3/1245_ah_t1_dikxv50.json\n","sampled-threads-ah-delta-context3/851_delta_t1_d726jzb.json\n","sampled-threads-ah-delta-context3/1061_delta_t1_d95wbfg.json\n","sampled-threads-ah-delta-context3/1050_ah_t1_cpzoyaz.json\n","sampled-threads-ah-delta-context3/772_delta_t1_cdd57zm.json\n","sampled-threads-ah-delta-context3/622_ah_t1_d6y0p28.json\n","sampled-threads-ah-delta-context3/1008_delta_t1_dgab9es.json\n","sampled-threads-ah-delta-context3/1089_ah_t1_ddo379h.json\n","sampled-threads-ah-delta-context3/853_ah_t1_de3c4qj.json\n","sampled-threads-ah-delta-context3/807_ah_t1_cj28ab0.json\n","sampled-threads-ah-delta-context3/37_delta_t1_dh59en0.json\n","sampled-threads-ah-delta-context3/887_ah_t1_dla1m2c.json\n","sampled-threads-ah-delta-context3/35_ah_t1_d2cm0r6.json\n","sampled-threads-ah-delta-context3/1146_ah_t1_cs8nx3q.json\n","sampled-threads-ah-delta-context3/534_delta_t1_dk58k9w.json\n","sampled-threads-ah-delta-context3/1121_ah_t1_dmkvzpe.json\n","sampled-threads-ah-delta-context3/1001_delta_t1_cimh75z.json\n","sampled-threads-ah-delta-context3/1218_ah_t1_db4kksx.json\n","sampled-threads-ah-delta-context3/428_ah_t1_cs2rqjk.json\n","sampled-threads-ah-delta-context3/310_ah_t1_dlr8ydh.json\n","sampled-threads-ah-delta-context3/832_ah_t1_d123eqp.json\n","sampled-threads-ah-delta-context3/108_ah_t1_d6rmfcz.json\n","sampled-threads-ah-delta-context3/781_delta_t1_d9ab09h.json\n","sampled-threads-ah-delta-context3/167_ah_t1_d08lx8w.json\n","sampled-threads-ah-delta-context3/1217_ah_t1_ddvuqd6.json\n","sampled-threads-ah-delta-context3/50_delta_t1_djt9kr3.json\n","sampled-threads-ah-delta-context3/692_delta_t1_cibvhly.json\n","sampled-threads-ah-delta-context3/399_delta_t1_cgcry0e.json\n","sampled-threads-ah-delta-context3/167_delta_t1_cg57ue3.json\n","sampled-threads-ah-delta-context3/159_ah_t1_d4oaeqj.json\n","sampled-threads-ah-delta-context3/215_delta_t1_ceejza8.json\n","sampled-threads-ah-delta-context3/1011_ah_t1_cvbdpri.json\n","sampled-threads-ah-delta-context3/1280_delta_t1_dbp0egp.json\n","sampled-threads-ah-delta-context3/499_delta_t1_dfpjzg9.json\n","sampled-threads-ah-delta-context3/172_ah_t1_ctdmlx4.json\n","sampled-threads-ah-delta-context3/1019_delta_t1_d9lxxdw.json\n","sampled-threads-ah-delta-context3/123_ah_t1_ckq5g2v.json\n","sampled-threads-ah-delta-context3/911_ah_t1_ckieiry.json\n","sampled-threads-ah-delta-context3/953_ah_t1_d6cg4bx.json\n","sampled-threads-ah-delta-context3/414_delta_t1_dlcrqbd.json\n","sampled-threads-ah-delta-context3/460_ah_t1_dm3nvla.json\n","sampled-threads-ah-delta-context3/315_delta_t1_ddx3elt.json\n","sampled-threads-ah-delta-context3/317_ah_t1_cjnvdr1.json\n","sampled-threads-ah-delta-context3/675_ah_t1_d55382o.json\n","sampled-threads-ah-delta-context3/968_ah_t1_ckwyp15.json\n","sampled-threads-ah-delta-context3/978_delta_t1_dfnpl4r.json\n","sampled-threads-ah-delta-context3/413_ah_t1_d7dsyp4.json\n","sampled-threads-ah-delta-context3/1209_delta_t1_d8ycffo.json\n","sampled-threads-ah-delta-context3/1012_ah_t1_cw6qhhv.json\n","sampled-threads-ah-delta-context3/1070_delta_t1_cyv3d0g.json\n","sampled-threads-ah-delta-context3/1158_ah_t1_cpeolbx.json\n","sampled-threads-ah-delta-context3/340_delta_t1_de314bs.json\n","sampled-threads-ah-delta-context3/609_delta_t1_dalpv0c.json\n","sampled-threads-ah-delta-context3/1183_ah_t1_dbz6ycy.json\n","sampled-threads-ah-delta-context3/579_ah_t1_dildg66.json\n","sampled-threads-ah-delta-context3/1198_delta_t1_cio82mr.json\n","sampled-threads-ah-delta-context3/939_ah_t1_csvcbvq.json\n","sampled-threads-ah-delta-context3/969_delta_t1_da0xfef.json\n","sampled-threads-ah-delta-context3/273_delta_t1_dg541t5.json\n","sampled-threads-ah-delta-context3/465_ah_t1_cw3bydk.json\n","sampled-threads-ah-delta-context3/918_delta_t1_coglswy.json\n","sampled-threads-ah-delta-context3/600_delta_t1_dln7e9g.json\n","sampled-threads-ah-delta-context3/477_delta_t1_combm1t.json\n","sampled-threads-ah-delta-context3/749_ah_t1_czbjtff.json\n","sampled-threads-ah-delta-context3/1243_ah_t1_dir5ib6.json\n","sampled-threads-ah-delta-context3/533_delta_t1_dlhihzj.json\n","sampled-threads-ah-delta-context3/461_delta_t1_cpbkneg.json\n","sampled-threads-ah-delta-context3/206_delta_t1_cu362c4.json\n","sampled-threads-ah-delta-context3/401_delta_t1_cslt0e9.json\n","sampled-threads-ah-delta-context3/1047_ah_t1_czmxg5e.json\n","sampled-threads-ah-delta-context3/393_delta_t1_caxokck.json\n","sampled-threads-ah-delta-context3/462_ah_t1_dbakmt0.json\n","sampled-threads-ah-delta-context3/159_delta_t1_dd5x4xo.json\n","sampled-threads-ah-delta-context3/1021_ah_t1_csjqj5o.json\n","sampled-threads-ah-delta-context3/910_delta_t1_chxaxgs.json\n","sampled-threads-ah-delta-context3/941_delta_t1_d4ensb6.json\n","sampled-threads-ah-delta-context3/166_ah_t1_dmybmbt.json\n","sampled-threads-ah-delta-context3/984_delta_t1_cbnhcwv.json\n","sampled-threads-ah-delta-context3/701_delta_t1_cfdtnzu.json\n","sampled-threads-ah-delta-context3/1108_ah_t1_clxlhw6.json\n","sampled-threads-ah-delta-context3/530_delta_t1_ck6prv4.json\n","sampled-threads-ah-delta-context3/705_ah_t1_cw71gyr.json\n","sampled-threads-ah-delta-context3/627_delta_t1_d70zev5.json\n","sampled-threads-ah-delta-context3/384_delta_t1_ch73p4g.json\n","sampled-threads-ah-delta-context3/931_ah_t1_d0mtmjm.json\n","sampled-threads-ah-delta-context3/1186_ah_t1_dh4rxr8.json\n","sampled-threads-ah-delta-context3/623_ah_t1_df84ndn.json\n","sampled-threads-ah-delta-context3/1245_delta_t1_dd39t3r.json\n","sampled-threads-ah-delta-context3/4_delta_t1_d2fzilg.json\n","sampled-threads-ah-delta-context3/808_delta_t1_coztjh8.json\n","sampled-threads-ah-delta-context3/424_delta_t1_ccsx1nx.json\n","sampled-threads-ah-delta-context3/746_delta_t1_dgg84ib.json\n","sampled-threads-ah-delta-context3/436_ah_t1_cv70b2x.json\n","sampled-threads-ah-delta-context3/1085_delta_t1_de63pxm.json\n","sampled-threads-ah-delta-context3/818_ah_t1_dcx85h6.json\n","sampled-threads-ah-delta-context3/1273_ah_t1_d97dq3p.json\n","sampled-threads-ah-delta-context3/1206_ah_t1_dikx31s.json\n","sampled-threads-ah-delta-context3/1163_ah_t1_d89znz1.json\n","sampled-threads-ah-delta-context3/435_delta_t1_cfu6l1j.json\n","sampled-threads-ah-delta-context3/558_ah_t1_cj4gnfg.json\n","sampled-threads-ah-delta-context3/24_ah_t1_cn3mn54.json\n","sampled-threads-ah-delta-context3/765_delta_t1_df2ez6o.json\n","sampled-threads-ah-delta-context3/811_ah_t1_d9bda5d.json\n","sampled-threads-ah-delta-context3/871_ah_t1_cjyu5bm.json\n","sampled-threads-ah-delta-context3/2_ah_t1_d579xvu.json\n","sampled-threads-ah-delta-context3/690_ah_t1_dimg2ug.json\n","sampled-threads-ah-delta-context3/708_delta_t1_ch7503g.json\n","sampled-threads-ah-delta-context3/17_ah_t1_crugu4f.json\n","sampled-threads-ah-delta-context3/945_delta_t1_cfkd2dg.json\n","sampled-threads-ah-delta-context3/464_ah_t1_dlt66lv.json\n","sampled-threads-ah-delta-context3/70_ah_t1_dipwvtv.json\n","sampled-threads-ah-delta-context3/434_ah_t1_dkc40r9.json\n","sampled-threads-ah-delta-context3/1181_ah_t1_dji4x99.json\n","sampled-threads-ah-delta-context3/465_delta_t1_cibclm6.json\n","sampled-threads-ah-delta-context3/726_delta_t1_dgbxoci.json\n","sampled-threads-ah-delta-context3/756_ah_t1_dkuj3w1.json\n","sampled-threads-ah-delta-context3/13_delta_t1_dedozze.json\n","sampled-threads-ah-delta-context3/140_delta_t1_dg5dnk5.json\n","sampled-threads-ah-delta-context3/478_delta_t1_ctxj7fe.json\n","sampled-threads-ah-delta-context3/82_ah_t1_dgue183.json\n","sampled-threads-ah-delta-context3/703_delta_t1_djb8nb4.json\n","sampled-threads-ah-delta-context3/762_ah_t1_disj997.json\n","sampled-threads-ah-delta-context3/895_delta_t1_dhmbp2k.json\n","sampled-threads-ah-delta-context3/896_ah_t1_cxucmou.json\n","sampled-threads-ah-delta-context3/894_delta_t1_cb74h8i.json\n","sampled-threads-ah-delta-context3/425_ah_t1_d1vs4hu.json\n","sampled-threads-ah-delta-context3/855_delta_t1_d2tee00.json\n","sampled-threads-ah-delta-context3/16_delta_t1_d8dy9kk.json\n","sampled-threads-ah-delta-context3/1081_delta_t1_clm7cnb.json\n","sampled-threads-ah-delta-context3/607_delta_t1_ci59um5.json\n","sampled-threads-ah-delta-context3/462_delta_t1_d9sxqkx.json\n","sampled-threads-ah-delta-context3/1010_ah_t1_cmks972.json\n","sampled-threads-ah-delta-context3/270_ah_t1_d83yjz5.json\n","sampled-threads-ah-delta-context3/799_ah_t1_d4rcy6k.json\n","sampled-threads-ah-delta-context3/770_ah_t1_czgkjn4.json\n","sampled-threads-ah-delta-context3/616_ah_t1_dij52it.json\n","sampled-threads-ah-delta-context3/196_ah_t1_d4m57qm.json\n","sampled-threads-ah-delta-context3/59_ah_t1_dbk0qq5.json\n","sampled-threads-ah-delta-context3/1030_ah_t1_d12mhds.json\n","sampled-threads-ah-delta-context3/644_delta_t1_dec97pu.json\n","sampled-threads-ah-delta-context3/1176_delta_t1_da50dp2.json\n","sampled-threads-ah-delta-context3/605_ah_t1_d12hv3d.json\n","sampled-threads-ah-delta-context3/864_ah_t1_dkc8t2v.json\n","sampled-threads-ah-delta-context3/5_delta_t1_chrabzv.json\n","sampled-threads-ah-delta-context3/680_delta_t1_ddy7jm0.json\n","sampled-threads-ah-delta-context3/1064_delta_t1_cc9nnp8.json\n","sampled-threads-ah-delta-context3/588_ah_t1_d6bb884.json\n","sampled-threads-ah-delta-context3/851_ah_t1_dl2o1ob.json\n","sampled-threads-ah-delta-context3/45_delta_t1_d0d0z82.json\n","sampled-threads-ah-delta-context3/363_ah_t1_dmxsyfg.json\n","sampled-threads-ah-delta-context3/170_ah_t1_crcea3j.json\n","sampled-threads-ah-delta-context3/845_ah_t1_dgosvd4.json\n","sampled-threads-ah-delta-context3/1229_ah_t1_cpx61hr.json\n","sampled-threads-ah-delta-context3/1203_delta_t1_d5ffs3u.json\n","sampled-threads-ah-delta-context3/581_ah_t1_dbadho7.json\n","sampled-threads-ah-delta-context3/307_delta_t1_dfcfv0e.json\n","sampled-threads-ah-delta-context3/369_ah_t1_ctgr16w.json\n","sampled-threads-ah-delta-context3/1258_delta_t1_cosc9at.json\n","sampled-threads-ah-delta-context3/1164_ah_t1_copkqkl.json\n","sampled-threads-ah-delta-context3/993_ah_t1_ct7yuzc.json\n","sampled-threads-ah-delta-context3/1025_delta_t1_ddy9g6p.json\n","sampled-threads-ah-delta-context3/587_delta_t1_ckdch4k.json\n","sampled-threads-ah-delta-context3/275_ah_t1_d972v37.json\n","sampled-threads-ah-delta-context3/960_ah_t1_d6cla13.json\n","sampled-threads-ah-delta-context3/209_delta_t1_d6llrlk.json\n","sampled-threads-ah-delta-context3/883_ah_t1_dhrdezo.json\n","sampled-threads-ah-delta-context3/548_delta_t1_cbbkgxp.json\n","sampled-threads-ah-delta-context3/480_ah_t1_cznfv93.json\n","sampled-threads-ah-delta-context3/107_ah_t1_ddk3c6r.json\n","sampled-threads-ah-delta-context3/787_delta_t1_cxw91rm.json\n","sampled-threads-ah-delta-context3/221_ah_t1_d3xg73f.json\n","sampled-threads-ah-delta-context3/1123_delta_t1_dhg0j8i.json\n","sampled-threads-ah-delta-context3/431_ah_t1_dic3ma0.json\n","sampled-threads-ah-delta-context3/840_delta_t1_clxxawe.json\n","sampled-threads-ah-delta-context3/1063_ah_t1_cjw36nj.json\n","sampled-threads-ah-delta-context3/69_ah_t1_djwmu30.json\n","sampled-threads-ah-delta-context3/704_delta_t1_devf7es.json\n","sampled-threads-ah-delta-context3/806_delta_t1_djvjw6p.json\n","sampled-threads-ah-delta-context3/741_delta_t1_d5iha3x.json\n","sampled-threads-ah-delta-context3/548_ah_t1_d3yq4vb.json\n","sampled-threads-ah-delta-context3/899_delta_t1_dn0zqxr.json\n","sampled-threads-ah-delta-context3/572_delta_t1_djfkcqu.json\n","sampled-threads-ah-delta-context3/902_ah_t1_d6bax7o.json\n","sampled-threads-ah-delta-context3/1133_delta_t1_df9d1op.json\n","sampled-threads-ah-delta-context3/705_delta_t1_dij9bi3.json\n","sampled-threads-ah-delta-context3/260_delta_t1_dh7d5h7.json\n","sampled-threads-ah-delta-context3/1264_delta_t1_di8fggy.json\n","sampled-threads-ah-delta-context3/842_ah_t1_dbjzrkw.json\n","sampled-threads-ah-delta-context3/1244_ah_t1_cjhyuhq.json\n","sampled-threads-ah-delta-context3/487_ah_t1_dav4sxn.json\n","sampled-threads-ah-delta-context3/717_ah_t1_cp9hlx2.json\n","sampled-threads-ah-delta-context3/804_ah_t1_dcc6ges.json\n","sampled-threads-ah-delta-context3/1187_delta_t1_djj8blo.json\n","sampled-threads-ah-delta-context3/948_ah_t1_dl87de8.json\n","sampled-threads-ah-delta-context3/1135_ah_t1_czu6vck.json\n","sampled-threads-ah-delta-context3/219_delta_t1_dionl47.json\n","sampled-threads-ah-delta-context3/254_ah_t1_dm56m7y.json\n","sampled-threads-ah-delta-context3/193_delta_t1_chbagpd.json\n","sampled-threads-ah-delta-context3/181_delta_t1_d057ojh.json\n","sampled-threads-ah-delta-context3/21_ah_t1_diawf6r.json\n","sampled-threads-ah-delta-context3/589_ah_t1_ckj4c02.json\n","sampled-threads-ah-delta-context3/440_delta_t1_dj99hql.json\n","sampled-threads-ah-delta-context3/771_delta_t1_cjaq2ge.json\n","sampled-threads-ah-delta-context3/935_delta_t1_d18ncya.json\n","sampled-threads-ah-delta-context3/54_delta_t1_ciy5j47.json\n","sampled-threads-ah-delta-context3/611_ah_t1_cqy3rpx.json\n","sampled-threads-ah-delta-context3/422_delta_t1_co674r6.json\n","sampled-threads-ah-delta-context3/877_delta_t1_dfmh6s9.json\n","sampled-threads-ah-delta-context3/746_ah_t1_cw1gso3.json\n","sampled-threads-ah-delta-context3/667_ah_t1_cq8826i.json\n","sampled-threads-ah-delta-context3/1269_delta_t1_dg9orsv.json\n","sampled-threads-ah-delta-context3/160_ah_t1_dd3125t.json\n","sampled-threads-ah-delta-context3/207_ah_t1_cj6kqsj.json\n","sampled-threads-ah-delta-context3/372_delta_t1_d0abuao.json\n","sampled-threads-ah-delta-context3/651_delta_t1_cc2nay8.json\n","sampled-threads-ah-delta-context3/178_ah_t1_cnrjs60.json\n","sampled-threads-ah-delta-context3/1140_ah_t1_d2ubej0.json\n","sampled-threads-ah-delta-context3/567_ah_t1_cy7m3uh.json\n","sampled-threads-ah-delta-context3/227_ah_t1_cx0hyfv.json\n","sampled-threads-ah-delta-context3/1230_delta_t1_cjiinyj.json\n","sampled-threads-ah-delta-context3/706_delta_t1_dhpd72l.json\n","sampled-threads-ah-delta-context3/1229_delta_t1_df9pco1.json\n","sampled-threads-ah-delta-context3/421_delta_t1_dca6wbd.json\n","sampled-threads-ah-delta-context3/676_ah_t1_dhn8jw6.json\n","sampled-threads-ah-delta-context3/1230_ah_t1_ctk2mup.json\n","sampled-threads-ah-delta-context3/135_delta_t1_dd1a9os.json\n","sampled-threads-ah-delta-context3/1090_ah_t1_de76v25.json\n","sampled-threads-ah-delta-context3/876_delta_t1_cpi27eq.json\n","sampled-threads-ah-delta-context3/566_delta_t1_cu6lk6m.json\n","sampled-threads-ah-delta-context3/463_ah_t1_cmuivmr.json\n","sampled-threads-ah-delta-context3/345_delta_t1_cju1iur.json\n","sampled-threads-ah-delta-context3/78_ah_t1_cje26fi.json\n","sampled-threads-ah-delta-context3/986_ah_t1_dkt86r7.json\n","sampled-threads-ah-delta-context3/121_delta_t1_dbolgmu.json\n","sampled-threads-ah-delta-context3/1274_ah_t1_cjhwtfk.json\n","sampled-threads-ah-delta-context3/569_ah_t1_clvy67k.json\n","sampled-threads-ah-delta-context3/565_ah_t1_cylpujj.json\n","sampled-threads-ah-delta-context3/127_ah_t1_dauw2dj.json\n","sampled-threads-ah-delta-context3/891_delta_t1_czam97r.json\n","sampled-threads-ah-delta-context3/985_ah_t1_d6xxic1.json\n","sampled-threads-ah-delta-context3/385_delta_t1_dmhkdqg.json\n","sampled-threads-ah-delta-context3/286_ah_t1_da0a3ve.json\n","sampled-threads-ah-delta-context3/1100_ah_t1_cju4pk0.json\n","sampled-threads-ah-delta-context3/242_delta_t1_d4d8vp1.json\n","sampled-threads-ah-delta-context3/654_ah_t1_diaeaas.json\n","sampled-threads-ah-delta-context3/45_ah_t1_d00cx15.json\n","sampled-threads-ah-delta-context3/679_ah_t1_ddb3oyh.json\n","sampled-threads-ah-delta-context3/432_ah_t1_d54qfh8.json\n","sampled-threads-ah-delta-context3/273_ah_t1_cr22iqg.json\n","sampled-threads-ah-delta-context3/593_ah_t1_dmthgcm.json\n","sampled-threads-ah-delta-context3/249_delta_t1_dkjh77r.json\n","sampled-threads-ah-delta-context3/370_delta_t1_ckx7slq.json\n","sampled-threads-ah-delta-context3/540_delta_t1_d5tkvju.json\n","sampled-threads-ah-delta-context3/389_ah_t1_dkrvbwm.json\n","sampled-threads-ah-delta-context3/655_delta_t1_dcg50qp.json\n","sampled-threads-ah-delta-context3/1199_delta_t1_dhdo5qi.json\n","sampled-threads-ah-delta-context3/327_ah_t1_cwbnqn5.json\n","sampled-threads-ah-delta-context3/164_ah_t1_csp2rym.json\n","sampled-threads-ah-delta-context3/1210_ah_t1_czvdx2u.json\n","sampled-threads-ah-delta-context3/239_delta_t1_cblit9u.json\n","sampled-threads-ah-delta-context3/176_delta_t1_csmi0a1.json\n","sampled-threads-ah-delta-context3/467_delta_t1_di08adp.json\n","sampled-threads-ah-delta-context3/12_delta_t1_ddd3gih.json\n","sampled-threads-ah-delta-context3/549_ah_t1_d452ta2.json\n","sampled-threads-ah-delta-context3/1076_ah_t1_dafw2fy.json\n","sampled-threads-ah-delta-context3/1254_ah_t1_dkvzmy8.json\n","sampled-threads-ah-delta-context3/274_ah_t1_djcri1h.json\n","sampled-threads-ah-delta-context3/154_ah_t1_dbygnpx.json\n","sampled-threads-ah-delta-context3/1101_ah_t1_d4oc5fq.json\n","sampled-threads-ah-delta-context3/519_ah_t1_dgtuw05.json\n","sampled-threads-ah-delta-context3/964_delta_t1_d579qh4.json\n","sampled-threads-ah-delta-context3/1218_delta_t1_de3hn61.json\n","sampled-threads-ah-delta-context3/591_ah_t1_d3xi3rt.json\n","sampled-threads-ah-delta-context3/497_delta_t1_cu1yldc.json\n","sampled-threads-ah-delta-context3/596_delta_t1_dknjk3k.json\n","sampled-threads-ah-delta-context3/422_ah_t1_cpo1mr9.json\n","sampled-threads-ah-delta-context3/1289_delta_t1_d9nf719.json\n","sampled-threads-ah-delta-context3/410_ah_t1_d8lkguh.json\n","sampled-threads-ah-delta-context3/709_ah_t1_denmvjy.json\n","sampled-threads-ah-delta-context3/1190_ah_t1_dfnjm0y.json\n","sampled-threads-ah-delta-context3/1088_ah_t1_dguc70f.json\n","sampled-threads-ah-delta-context3/1144_ah_t1_cqbiua4.json\n","sampled-threads-ah-delta-context3/532_delta_t1_cki4q8y.json\n","sampled-threads-ah-delta-context3/281_ah_t1_cwt041s.json\n","sampled-threads-ah-delta-context3/723_ah_t1_d6kard3.json\n","sampled-threads-ah-delta-context3/777_ah_t1_dcv6a5o.json\n","sampled-threads-ah-delta-context3/632_delta_t1_d4bgpso.json\n","sampled-threads-ah-delta-context3/475_ah_t1_dkmucgu.json\n","sampled-threads-ah-delta-context3/659_ah_t1_d1s8wl4.json\n","sampled-threads-ah-delta-context3/836_ah_t1_d16xy59.json\n","sampled-threads-ah-delta-context3/974_delta_t1_cda7tch.json\n","sampled-threads-ah-delta-context3/758_ah_t1_d2k238y.json\n","sampled-threads-ah-delta-context3/241_ah_t1_dbzjt6a.json\n","sampled-threads-ah-delta-context3/775_delta_t1_dkp9idd.json\n","sampled-threads-ah-delta-context3/896_delta_t1_cvkzqnl.json\n","sampled-threads-ah-delta-context3/405_delta_t1_dg9cee9.json\n","sampled-threads-ah-delta-context3/858_delta_t1_cym2vfs.json\n","sampled-threads-ah-delta-context3/240_ah_t1_cjm6xgm.json\n","sampled-threads-ah-delta-context3/953_delta_t1_djh8b8w.json\n","sampled-threads-ah-delta-context3/1157_ah_t1_cvk5t54.json\n","sampled-threads-ah-delta-context3/148_delta_t1_cj12pi3.json\n","sampled-threads-ah-delta-context3/37_ah_t1_dn75ts0.json\n","sampled-threads-ah-delta-context3/11_delta_t1_ddy8p0o.json\n","sampled-threads-ah-delta-context3/772_ah_t1_ddqmjz9.json\n","sampled-threads-ah-delta-context3/59_delta_t1_dia7f3o.json\n","sampled-threads-ah-delta-context3/598_ah_t1_cjbmfpg.json\n","sampled-threads-ah-delta-context3/370_ah_t1_dfx7ep8.json\n","sampled-threads-ah-delta-context3/634_ah_t1_cpn6z7s.json\n","sampled-threads-ah-delta-context3/926_ah_t1_csu91um.json\n","sampled-threads-ah-delta-context3/368_ah_t1_crfqrgg.json\n","sampled-threads-ah-delta-context3/319_ah_t1_d4hfgfb.json\n","sampled-threads-ah-delta-context3/1268_delta_t1_d2ddshf.json\n","sampled-threads-ah-delta-context3/753_ah_t1_dh8twn9.json\n","sampled-threads-ah-delta-context3/24_delta_t1_d7kx4q0.json\n","sampled-threads-ah-delta-context3/824_delta_t1_cpcigu7.json\n","sampled-threads-ah-delta-context3/351_delta_t1_djb8qpy.json\n","sampled-threads-ah-delta-context3/700_ah_t1_dihcq6v.json\n","sampled-threads-ah-delta-context3/367_delta_t1_ceaosh0.json\n","sampled-threads-ah-delta-context3/1124_delta_t1_dg4yk65.json\n","sampled-threads-ah-delta-context3/397_ah_t1_dlbe5ws.json\n","sampled-threads-ah-delta-context3/14_delta_t1_d5a5olv.json\n","sampled-threads-ah-delta-context3/314_ah_t1_d2jn7z5.json\n","sampled-threads-ah-delta-context3/940_delta_t1_czrprrw.json\n","sampled-threads-ah-delta-context3/905_ah_t1_dfnfhvf.json\n","sampled-threads-ah-delta-context3/522_ah_t1_dlvwpye.json\n","sampled-threads-ah-delta-context3/876_ah_t1_cljnig3.json\n","sampled-threads-ah-delta-context3/825_delta_t1_dhdub9z.json\n","sampled-threads-ah-delta-context3/87_ah_t1_dk0gsr6.json\n","sampled-threads-ah-delta-context3/938_delta_t1_cokdle5.json\n","sampled-threads-ah-delta-context3/599_delta_t1_ctklalj.json\n","sampled-threads-ah-delta-context3/1065_delta_t1_dhc8tdh.json\n","sampled-threads-ah-delta-context3/0_ah_t1_dggp3q9.json\n","sampled-threads-ah-delta-context3/72_ah_t1_ct15lzz.json\n","sampled-threads-ah-delta-context3/573_delta_t1_cau0x1e.json\n","sampled-threads-ah-delta-context3/1097_delta_t1_detddrf.json\n","sampled-threads-ah-delta-context3/5_ah_t1_crsf842.json\n","sampled-threads-ah-delta-context3/65_delta_t1_cv043en.json\n","sampled-threads-ah-delta-context3/423_delta_t1_co7ixr4.json\n","sampled-threads-ah-delta-context3/1009_ah_t1_d3n7a8h.json\n","sampled-threads-ah-delta-context3/621_delta_t1_cb1fr9p.json\n","sampled-threads-ah-delta-context3/640_delta_t1_cosook2.json\n","sampled-threads-ah-delta-context3/1007_ah_t1_ddkinbd.json\n","sampled-threads-ah-delta-context3/714_delta_t1_cuwfuyo.json\n","sampled-threads-ah-delta-context3/22_ah_t1_cwc89n1.json\n","sampled-threads-ah-delta-context3/780_delta_t1_d03hshv.json\n","sampled-threads-ah-delta-context3/1265_delta_t1_cjfopji.json\n","sampled-threads-ah-delta-context3/154_delta_t1_cnhdajd.json\n","sampled-threads-ah-delta-context3/1016_delta_t1_ctca5ls.json\n","sampled-threads-ah-delta-context3/353_delta_t1_dn1srtn.json\n","sampled-threads-ah-delta-context3/1103_ah_t1_dmzww1e.json\n","sampled-threads-ah-delta-context3/987_ah_t1_df9ssz5.json\n","sampled-threads-ah-delta-context3/556_ah_t1_cj881af.json\n","sampled-threads-ah-delta-context3/213_delta_t1_cn5bcc3.json\n","sampled-threads-ah-delta-context3/1248_ah_t1_d0ashoc.json\n","sampled-threads-ah-delta-context3/1128_delta_t1_dbt76aq.json\n","sampled-threads-ah-delta-context3/1107_delta_t1_djyyp1m.json\n","sampled-threads-ah-delta-context3/570_ah_t1_d6vgbqc.json\n","sampled-threads-ah-delta-context3/517_ah_t1_dbzfydb.json\n","sampled-threads-ah-delta-context3/900_delta_t1_del86af.json\n","sampled-threads-ah-delta-context3/1099_delta_t1_d6xwxy7.json\n","sampled-threads-ah-delta-context3/714_ah_t1_codklzb.json\n","sampled-threads-ah-delta-context3/505_delta_t1_cbvz9zj.json\n","sampled-threads-ah-delta-context3/915_ah_t1_cj45glm.json\n","sampled-threads-ah-delta-context3/17_delta_t1_cdlaxg9.json\n","sampled-threads-ah-delta-context3/290_ah_t1_dms0ztg.json\n","sampled-threads-ah-delta-context3/1056_ah_t1_cphp1gf.json\n","sampled-threads-ah-delta-context3/771_ah_t1_d6jr7z0.json\n","sampled-threads-ah-delta-context3/647_delta_t1_ckep6wg.json\n","sampled-threads-ah-delta-context3/232_ah_t1_cs3z1vl.json\n","sampled-threads-ah-delta-context3/1163_delta_t1_dax3a1w.json\n","sampled-threads-ah-delta-context3/564_ah_t1_d8ybpbm.json\n","sampled-threads-ah-delta-context3/1159_ah_t1_cjyuaky.json\n","sampled-threads-ah-delta-context3/685_delta_t1_dmx484p.json\n","sampled-threads-ah-delta-context3/1036_ah_t1_d914dvv.json\n","sampled-threads-ah-delta-context3/288_ah_t1_dliz6lc.json\n","sampled-threads-ah-delta-context3/71_delta_t1_cmt8fwl.json\n","sampled-threads-ah-delta-context3/651_ah_t1_dhklkiw.json\n","sampled-threads-ah-delta-context3/898_delta_t1_cj7qcp7.json\n","sampled-threads-ah-delta-context3/322_delta_t1_cylv8uz.json\n","sampled-threads-ah-delta-context3/376_ah_t1_dijl9d1.json\n","sampled-threads-ah-delta-context3/762_delta_t1_cqxffpz.json\n","sampled-threads-ah-delta-context3/886_delta_t1_cd219n8.json\n","sampled-threads-ah-delta-context3/745_ah_t1_d0e6v20.json\n","sampled-threads-ah-delta-context3/191_delta_t1_deqxixn.json\n","sampled-threads-ah-delta-context3/339_ah_t1_czqdmnk.json\n","sampled-threads-ah-delta-context3/431_delta_t1_cntw67i.json\n","sampled-threads-ah-delta-context3/53_ah_t1_cl9hi36.json\n","sampled-threads-ah-delta-context3/614_ah_t1_dgevqza.json\n","sampled-threads-ah-delta-context3/1238_ah_t1_d38js3t.json\n","sampled-threads-ah-delta-context3/834_delta_t1_cgrtlhy.json\n","sampled-threads-ah-delta-context3/683_delta_t1_cmaec3g.json\n","sampled-threads-ah-delta-context3/13_ah_t1_coyee58.json\n","sampled-threads-ah-delta-context3/168_delta_t1_d06szll.json\n","sampled-threads-ah-delta-context3/926_delta_t1_clmqbnw.json\n","sampled-threads-ah-delta-context3/211_delta_t1_csv08sb.json\n","sampled-threads-ah-delta-context3/173_ah_t1_deiseva.json\n","sampled-threads-ah-delta-context3/26_ah_t1_dl8jxvg.json\n","sampled-threads-ah-delta-context3/135_ah_t1_clk932q.json\n","sampled-threads-ah-delta-context3/199_ah_t1_cknae5s.json\n","sampled-threads-ah-delta-context3/52_ah_t1_di0954d.json\n","sampled-threads-ah-delta-context3/889_delta_t1_cs8taw9.json\n","sampled-threads-ah-delta-context3/960_delta_t1_cr7800q.json\n","sampled-threads-ah-delta-context3/40_ah_t1_db75jjn.json\n","sampled-threads-ah-delta-context3/486_delta_t1_d077gr0.json\n","sampled-threads-ah-delta-context3/503_delta_t1_daqhne4.json\n","sampled-threads-ah-delta-context3/1173_ah_t1_cjnrvn5.json\n","sampled-threads-ah-delta-context3/920_ah_t1_decfvdy.json\n","sampled-threads-ah-delta-context3/627_ah_t1_d4e39ob.json\n","sampled-threads-ah-delta-context3/304_delta_t1_d4jxg7w.json\n","sampled-threads-ah-delta-context3/98_ah_t1_dgm2a0w.json\n","sampled-threads-ah-delta-context3/248_delta_t1_dfweicz.json\n","sampled-threads-ah-delta-context3/417_ah_t1_cqm0562.json\n","sampled-threads-ah-delta-context3/1255_ah_t1_d62il8t.json\n","sampled-threads-ah-delta-context3/1250_ah_t1_ckl51nb.json\n","sampled-threads-ah-delta-context3/822_delta_t1_d0v1qd4.json\n","sampled-threads-ah-delta-context3/130_delta_t1_ct3p0b7.json\n","sampled-threads-ah-delta-context3/1024_ah_t1_df858yu.json\n","sampled-threads-ah-delta-context3/612_ah_t1_dfykg7x.json\n","sampled-threads-ah-delta-context3/1126_ah_t1_d7a60j1.json\n","sampled-threads-ah-delta-context3/615_ah_t1_cyxfbig.json\n","sampled-threads-ah-delta-context3/362_delta_t1_dajstuj.json\n","sampled-threads-ah-delta-context3/518_delta_t1_df9dl0y.json\n","sampled-threads-ah-delta-context3/223_delta_t1_deo9c24.json\n","sampled-threads-ah-delta-context3/387_delta_t1_d17gze6.json\n","sampled-threads-ah-delta-context3/470_ah_t1_cuapz90.json\n","sampled-threads-ah-delta-context3/922_ah_t1_djsar7t.json\n","sampled-threads-ah-delta-context3/248_ah_t1_d50wgma.json\n","sampled-threads-ah-delta-context3/377_delta_t1_dh2nr5w.json\n","sampled-threads-ah-delta-context3/280_delta_t1_dhcga0r.json\n","sampled-threads-ah-delta-context3/458_ah_t1_dfmfwva.json\n","sampled-threads-ah-delta-context3/197_ah_t1_cxs98gy.json\n","sampled-threads-ah-delta-context3/743_delta_t1_dezss12.json\n","sampled-threads-ah-delta-context3/757_delta_t1_djchtlc.json\n","sampled-threads-ah-delta-context3/1180_ah_t1_cvpexlo.json\n","sampled-threads-ah-delta-context3/826_ah_t1_cyae07d.json\n","sampled-threads-ah-delta-context3/520_delta_t1_dk6t94l.json\n","sampled-threads-ah-delta-context3/972_ah_t1_dagw5jb.json\n","sampled-threads-ah-delta-context3/1172_ah_t1_cxjuktv.json\n","sampled-threads-ah-delta-context3/830_delta_t1_d7iiool.json\n","sampled-threads-ah-delta-context3/418_delta_t1_dhx355y.json\n","sampled-threads-ah-delta-context3/256_delta_t1_dm1jx6j.json\n","sampled-threads-ah-delta-context3/593_delta_t1_dfv5qy0.json\n","sampled-threads-ah-delta-context3/79_delta_t1_ck0edto.json\n","sampled-threads-ah-delta-context3/1035_delta_t1_dg1yhew.json\n","sampled-threads-ah-delta-context3/190_ah_t1_d2u4v3s.json\n","sampled-threads-ah-delta-context3/663_delta_t1_d128nh9.json\n","sampled-threads-ah-delta-context3/65_ah_t1_cn5ndu1.json\n","sampled-threads-ah-delta-context3/1190_delta_t1_cxrzt7b.json\n","sampled-threads-ah-delta-context3/787_ah_t1_cuv4bfs.json\n","sampled-threads-ah-delta-context3/1145_ah_t1_d2gcz3m.json\n","sampled-threads-ah-delta-context3/854_delta_t1_cx9ycpb.json\n","sampled-threads-ah-delta-context3/340_ah_t1_d9ce55h.json\n","sampled-threads-ah-delta-context3/1_ah_t1_dk29ix7.json\n","sampled-threads-ah-delta-context3/109_delta_t1_dc4gokk.json\n","sampled-threads-ah-delta-context3/874_delta_t1_cncxxk2.json\n","sampled-threads-ah-delta-context3/816_delta_t1_cssb5w4.json\n","sampled-threads-ah-delta-context3/48_ah_t1_d20z0sc.json\n","sampled-threads-ah-delta-context3/1004_ah_t1_dayiaie.json\n","sampled-threads-ah-delta-context3/785_ah_t1_ddve37i.json\n","sampled-threads-ah-delta-context3/884_delta_t1_dj480x6.json\n","sampled-threads-ah-delta-context3/1132_ah_t1_dfnetbu.json\n","sampled-threads-ah-delta-context3/376_delta_t1_dgfgfyw.json\n","sampled-threads-ah-delta-context3/1241_ah_t1_ctxp2ia.json\n","sampled-threads-ah-delta-context3/62_ah_t1_dgw769x.json\n","sampled-threads-ah-delta-context3/1164_delta_t1_dkjagf8.json\n","sampled-threads-ah-delta-context3/681_delta_t1_cepgeeh.json\n","sampled-threads-ah-delta-context3/1100_delta_t1_d5cz8is.json\n","sampled-threads-ah-delta-context3/976_ah_t1_dm8qw3k.json\n","sampled-threads-ah-delta-context3/334_ah_t1_d1vj0cf.json\n","sampled-threads-ah-delta-context3/527_delta_t1_cciojhb.json\n","sampled-threads-ah-delta-context3/860_ah_t1_crtr0q6.json\n","sampled-threads-ah-delta-context3/297_ah_t1_ckzb2i2.json\n","sampled-threads-ah-delta-context3/1071_delta_t1_db1k6rr.json\n","sampled-threads-ah-delta-context3/669_ah_t1_dea3ab7.json\n","sampled-threads-ah-delta-context3/865_delta_t1_d6vl4jo.json\n","sampled-threads-ah-delta-context3/999_delta_t1_cw9oveu.json\n","sampled-threads-ah-delta-context3/1106_ah_t1_dlme35y.json\n","sampled-threads-ah-delta-context3/748_ah_t1_clyvg6f.json\n","sampled-threads-ah-delta-context3/514_delta_t1_cn2zbxm.json\n","sampled-threads-ah-delta-context3/925_delta_t1_cf1pzku.json\n","sampled-threads-ah-delta-context3/491_delta_t1_dkcmg5p.json\n","sampled-threads-ah-delta-context3/436_delta_t1_cy0pcys.json\n","sampled-threads-ah-delta-context3/413_delta_t1_dg52xse.json\n","sampled-threads-ah-delta-context3/847_delta_t1_czasw98.json\n","sampled-threads-ah-delta-context3/951_delta_t1_dd9cek6.json\n","sampled-threads-ah-delta-context3/1005_ah_t1_d8isikf.json\n","sampled-threads-ah-delta-context3/476_ah_t1_d3whv9m.json\n","sampled-threads-ah-delta-context3/500_ah_t1_cjin90a.json\n","sampled-threads-ah-delta-context3/577_delta_t1_cpkkv7x.json\n","sampled-threads-ah-delta-context3/875_delta_t1_da98xxp.json\n","sampled-threads-ah-delta-context3/680_ah_t1_cvt1xmu.json\n","sampled-threads-ah-delta-context3/600_ah_t1_cxl9545.json\n","sampled-threads-ah-delta-context3/1015_ah_t1_dmzd2ww.json\n","sampled-threads-ah-delta-context3/958_ah_t1_cnxnsjo.json\n","sampled-threads-ah-delta-context3/788_ah_t1_cq3vzot.json\n","sampled-threads-ah-delta-context3/975_delta_t1_djv71l3.json\n","sampled-threads-ah-delta-context3/1201_delta_t1_d5k7zo3.json\n","sampled-threads-ah-delta-context3/875_ah_t1_cj792jz.json\n","sampled-threads-ah-delta-context3/1080_delta_t1_d2e5d8i.json\n","sampled-threads-ah-delta-context3/869_ah_t1_cqqlpzs.json\n","sampled-threads-ah-delta-context3/998_ah_t1_d0ynkz7.json\n","sampled-threads-ah-delta-context3/634_delta_t1_dmzvvdb.json\n","sampled-threads-ah-delta-context3/331_ah_t1_csmc4im.json\n","sampled-threads-ah-delta-context3/1083_ah_t1_ctl7xmk.json\n","sampled-threads-ah-delta-context3/252_delta_t1_cwgyc9l.json\n","sampled-threads-ah-delta-context3/769_ah_t1_d3s7bm7.json\n","sampled-threads-ah-delta-context3/326_delta_t1_ddzyixj.json\n","sampled-threads-ah-delta-context3/310_delta_t1_dgadb0u.json\n","sampled-threads-ah-delta-context3/613_ah_t1_d75d60w.json\n","sampled-threads-ah-delta-context3/730_ah_t1_d62wvxe.json\n","sampled-threads-ah-delta-context3/765_ah_t1_cqwxy95.json\n","sampled-threads-ah-delta-context3/857_delta_t1_cw4xg5g.json\n","sampled-threads-ah-delta-context3/484_ah_t1_dla1h1v.json\n","sampled-threads-ah-delta-context3/49_ah_t1_ctqa7mc.json\n","sampled-threads-ah-delta-context3/333_delta_t1_ch0mocw.json\n","sampled-threads-ah-delta-context3/562_ah_t1_djqpb5k.json\n","sampled-threads-ah-delta-context3/860_delta_t1_de1wv1n.json\n","sampled-threads-ah-delta-context3/447_ah_t1_dg4616t.json\n","sampled-threads-ah-delta-context3/20_delta_t1_czg6ga5.json\n","sampled-threads-ah-delta-context3/55_delta_t1_dl43cn8.json\n","sampled-threads-ah-delta-context3/423_ah_t1_dmy386n.json\n","sampled-threads-ah-delta-context3/939_delta_t1_ck3ap7e.json\n","sampled-threads-ah-delta-context3/446_ah_t1_dh0me94.json\n","sampled-threads-ah-delta-context3/127_delta_t1_cjzlv7i.json\n","sampled-threads-ah-delta-context3/264_ah_t1_dliafp1.json\n","sampled-threads-ah-delta-context3/530_ah_t1_d1f6i1u.json\n","sampled-threads-ah-delta-context3/789_ah_t1_coqipr6.json\n","sampled-threads-ah-delta-context3/508_ah_t1_d3uz6ws.json\n","sampled-threads-ah-delta-context3/388_delta_t1_cse4a93.json\n","sampled-threads-ah-delta-context3/578_delta_t1_dg4a3na.json\n","sampled-threads-ah-delta-context3/657_ah_t1_diursdw.json\n","sampled-threads-ah-delta-context3/49_delta_t1_del1sw3.json\n","sampled-threads-ah-delta-context3/367_ah_t1_d92smgs.json\n","sampled-threads-ah-delta-context3/588_delta_t1_cda8j4f.json\n","sampled-threads-ah-delta-context3/501_ah_t1_d9kyjre.json\n","sampled-threads-ah-delta-context3/369_delta_t1_cf6l6sd.json\n","sampled-threads-ah-delta-context3/602_delta_t1_dfgpskn.json\n","sampled-threads-ah-delta-context3/980_delta_t1_dbpjsgu.json\n","sampled-threads-ah-delta-context3/610_delta_t1_d9wwbl0.json\n","sampled-threads-ah-delta-context3/836_delta_t1_cid7j41.json\n","sampled-threads-ah-delta-context3/919_delta_t1_dabvzf2.json\n","sampled-threads-ah-delta-context3/835_delta_t1_djd6m97.json\n","sampled-threads-ah-delta-context3/1263_ah_t1_dduor6z.json\n","sampled-threads-ah-delta-context3/448_ah_t1_clex0kg.json\n","sampled-threads-ah-delta-context3/1138_delta_t1_cs74zf4.json\n","sampled-threads-ah-delta-context3/147_delta_t1_defef69.json\n","sampled-threads-ah-delta-context3/88_delta_t1_dl3l2da.json\n","sampled-threads-ah-delta-context3/140_ah_t1_dg49lpf.json\n","sampled-threads-ah-delta-context3/1104_ah_t1_d4sndks.json\n","sampled-threads-ah-delta-context3/1171_ah_t1_ctlv9b8.json\n","sampled-threads-ah-delta-context3/1057_delta_t1_d9dm8zn.json\n","sampled-threads-ah-delta-context3/112_delta_t1_d8i3owz.json\n","sampled-threads-ah-delta-context3/175_delta_t1_d1763kl.json\n","sampled-threads-ah-delta-context3/610_ah_t1_djumvdd.json\n","sampled-threads-ah-delta-context3/101_delta_t1_df1pkhb.json\n","sampled-threads-ah-delta-context3/162_delta_t1_del9e7l.json\n","sampled-threads-ah-delta-context3/90_ah_t1_cztbr6y.json\n","sampled-threads-ah-delta-context3/187_ah_t1_dm27mpc.json\n","sampled-threads-ah-delta-context3/234_ah_t1_cuaa9ex.json\n","sampled-threads-ah-delta-context3/980_ah_t1_diapclz.json\n","sampled-threads-ah-delta-context3/319_delta_t1_dguougt.json\n","sampled-threads-ah-delta-context3/77_ah_t1_dbt1dhw.json\n","sampled-threads-ah-delta-context3/1052_ah_t1_dl3s4y5.json\n","sampled-threads-ah-delta-context3/535_delta_t1_dlziaef.json\n","sampled-threads-ah-delta-context3/1281_ah_t1_dezkfxb.json\n","sampled-threads-ah-delta-context3/1126_delta_t1_dhz7mxy.json\n","sampled-threads-ah-delta-context3/624_ah_t1_dmz7t8d.json\n","sampled-threads-ah-delta-context3/77_delta_t1_dg6cpw0.json\n","sampled-threads-ah-delta-context3/467_ah_t1_d4jlfwc.json\n","sampled-threads-ah-delta-context3/752_ah_t1_cj7kmfk.json\n","sampled-threads-ah-delta-context3/938_ah_t1_de9zpll.json\n","sampled-threads-ah-delta-context3/1175_ah_t1_d044ahx.json\n","sampled-threads-ah-delta-context3/1129_delta_t1_dfnowet.json\n","sampled-threads-ah-delta-context3/547_delta_t1_d6lytnc.json\n","sampled-threads-ah-delta-context3/907_delta_t1_ctsydm4.json\n","sampled-threads-ah-delta-context3/563_delta_t1_df83d21.json\n","sampled-threads-ah-delta-context3/668_delta_t1_dh4qvz8.json\n","sampled-threads-ah-delta-context3/1053_ah_t1_cxbovdl.json\n","sampled-threads-ah-delta-context3/982_delta_t1_dgyekjd.json\n","sampled-threads-ah-delta-context3/142_ah_t1_d67o6tc.json\n","sampled-threads-ah-delta-context3/137_ah_t1_cx41b1m.json\n","sampled-threads-ah-delta-context3/466_delta_t1_cbgje0n.json\n","sampled-threads-ah-delta-context3/459_ah_t1_cqbw7bo.json\n","sampled-threads-ah-delta-context3/208_ah_t1_cz281en.json\n","sampled-threads-ah-delta-context3/536_delta_t1_cre3hyj.json\n","sampled-threads-ah-delta-context3/891_ah_t1_d78tv0y.json\n","sampled-threads-ah-delta-context3/78_delta_t1_ckctr11.json\n","sampled-threads-ah-delta-context3/733_ah_t1_dfl8nmb.json\n","sampled-threads-ah-delta-context3/1003_ah_t1_csfaej3.json\n","sampled-threads-ah-delta-context3/188_ah_t1_dfk4ok8.json\n","sampled-threads-ah-delta-context3/755_ah_t1_d3yuszq.json\n","sampled-threads-ah-delta-context3/96_delta_t1_ccj91x1.json\n","sampled-threads-ah-delta-context3/1079_ah_t1_d50z1un.json\n","sampled-threads-ah-delta-context3/509_delta_t1_dm1o9jd.json\n","sampled-threads-ah-delta-context3/653_ah_t1_d1dlru6.json\n","sampled-threads-ah-delta-context3/1081_ah_t1_dgu3zjy.json\n","sampled-threads-ah-delta-context3/332_ah_t1_dghd89h.json\n","sampled-threads-ah-delta-context3/192_ah_t1_d6kbbdw.json\n","sampled-threads-ah-delta-context3/439_ah_t1_dlnah5w.json\n","sampled-threads-ah-delta-context3/643_ah_t1_ddaedmo.json\n","sampled-threads-ah-delta-context3/1024_delta_t1_dadzjjj.json\n","sampled-threads-ah-delta-context3/962_ah_t1_dmzby49.json\n","sampled-threads-ah-delta-context3/732_delta_t1_cpmyb0w.json\n","sampled-threads-ah-delta-context3/792_delta_t1_dlnbpta.json\n","sampled-threads-ah-delta-context3/525_delta_t1_d05h7f3.json\n","sampled-threads-ah-delta-context3/287_delta_t1_caoq47a.json\n","sampled-threads-ah-delta-context3/1223_delta_t1_dcypf25.json\n","sampled-threads-ah-delta-context3/1157_delta_t1_cxpa0v3.json\n","sampled-threads-ah-delta-context3/19_delta_t1_cl9uzuy.json\n","sampled-threads-ah-delta-context3/652_ah_t1_dmxb7my.json\n","sampled-threads-ah-delta-context3/403_delta_t1_cuc3s61.json\n","sampled-threads-ah-delta-context3/798_ah_t1_d10arr0.json\n","sampled-threads-ah-delta-context3/556_delta_t1_dfufcy4.json\n","sampled-threads-ah-delta-context3/471_ah_t1_cuueg7y.json\n","sampled-threads-ah-delta-context3/444_ah_t1_d1iupas.json\n","sampled-threads-ah-delta-context3/739_delta_t1_dhvaar7.json\n","sampled-threads-ah-delta-context3/932_delta_t1_ctffm8g.json\n","sampled-threads-ah-delta-context3/743_ah_t1_dd60nxu.json\n","sampled-threads-ah-delta-context3/170_delta_t1_dbfp93f.json\n","sampled-threads-ah-delta-context3/766_ah_t1_dkw4m70.json\n","sampled-threads-ah-delta-context3/200_delta_t1_ck5b38n.json\n","sampled-threads-ah-delta-context3/96_ah_t1_cqs0sw9.json\n","sampled-threads-ah-delta-context3/136_delta_t1_dlglrrf.json\n","sampled-threads-ah-delta-context3/1124_ah_t1_dhbutoz.json\n","sampled-threads-ah-delta-context3/1231_ah_t1_dak8jte.json\n","sampled-threads-ah-delta-context3/1256_delta_t1_d8rfkwf.json\n","sampled-threads-ah-delta-context3/786_ah_t1_dloheid.json\n","sampled-threads-ah-delta-context3/183_ah_t1_dk19220.json\n","sampled-threads-ah-delta-context3/98_delta_t1_cb9mqr2.json\n","sampled-threads-ah-delta-context3/1142_ah_t1_d0cgtbs.json\n","sampled-threads-ah-delta-context3/1232_ah_t1_ddqme0v.json\n","sampled-threads-ah-delta-context3/1091_delta_t1_cgaprci.json\n","sampled-threads-ah-delta-context3/1178_ah_t1_d49fidg.json\n","sampled-threads-ah-delta-context3/126_ah_t1_dg2bq1l.json\n","sampled-threads-ah-delta-context3/821_delta_t1_d9izimu.json\n","sampled-threads-ah-delta-context3/800_ah_t1_cwuryv6.json\n","sampled-threads-ah-delta-context3/19_ah_t1_dausqlz.json\n","sampled-threads-ah-delta-context3/1115_ah_t1_dkar2j5.json\n","sampled-threads-ah-delta-context3/129_delta_t1_dfc8cj1.json\n","sampled-threads-ah-delta-context3/471_delta_t1_cgqk0w8.json\n","sampled-threads-ah-delta-context3/27_ah_t1_cvbosci.json\n","sampled-threads-ah-delta-context3/415_ah_t1_d7ymzmu.json\n","sampled-threads-ah-delta-context3/161_delta_t1_d2lhqzc.json\n","sampled-threads-ah-delta-context3/1289_ah_t1_cj8zgdl.json\n","sampled-threads-ah-delta-context3/161_ah_t1_dk96xca.json\n","sampled-threads-ah-delta-context3/300_ah_t1_cvv4d0v.json\n","sampled-threads-ah-delta-context3/774_ah_t1_d2hedzv.json\n","sampled-threads-ah-delta-context3/31_ah_t1_dknr6i2.json\n","sampled-threads-ah-delta-context3/633_delta_t1_d8ah3ql.json\n","sampled-threads-ah-delta-context3/1068_delta_t1_d8zj0w7.json\n","sampled-threads-ah-delta-context3/210_ah_t1_cyihrlz.json\n","sampled-threads-ah-delta-context3/1266_ah_t1_d676yqv.json\n","sampled-threads-ah-delta-context3/869_delta_t1_ch71onc.json\n","sampled-threads-ah-delta-context3/942_delta_t1_dh2y3f3.json\n","sampled-threads-ah-delta-context3/827_ah_t1_dlhd6du.json\n","sampled-threads-ah-delta-context3/1264_ah_t1_dh01fbg.json\n","sampled-threads-ah-delta-context3/1168_ah_t1_dlvvjm2.json\n","sampled-threads-ah-delta-context3/720_delta_t1_ce5s1ev.json\n","sampled-threads-ah-delta-context3/474_ah_t1_dbw46w0.json\n","sampled-threads-ah-delta-context3/817_delta_t1_dklw5zj.json\n","sampled-threads-ah-delta-context3/1282_ah_t1_czq5tlo.json\n","sampled-threads-ah-delta-context3/523_delta_t1_cgytso9.json\n","sampled-threads-ah-delta-context3/1200_delta_t1_db19dxc.json\n","sampled-threads-ah-delta-context3/1271_ah_t1_d5d07k3.json\n","sampled-threads-ah-delta-context3/626_delta_t1_cuz28uz.json\n","sampled-threads-ah-delta-context3/102_delta_t1_cw0w62s.json\n","sampled-threads-ah-delta-context3/629_delta_t1_dgbjvea.json\n","sampled-threads-ah-delta-context3/592_delta_t1_dlgahil.json\n","sampled-threads-ah-delta-context3/590_ah_t1_crsjqpu.json\n","sampled-threads-ah-delta-context3/913_delta_t1_d6rf3pl.json\n","sampled-threads-ah-delta-context3/826_delta_t1_dbjcn04.json\n","sampled-threads-ah-delta-context3/1171_delta_t1_d2ci2fw.json\n","sampled-threads-ah-delta-context3/1266_delta_t1_cxcllki.json\n","sampled-threads-ah-delta-context3/1224_ah_t1_djbwhme.json\n","sampled-threads-ah-delta-context3/459_delta_t1_df5jgfv.json\n","sampled-threads-ah-delta-context3/228_delta_t1_d97x3jj.json\n","sampled-threads-ah-delta-context3/200_ah_t1_djxtqpk.json\n","sampled-threads-ah-delta-context3/267_delta_t1_cl37cox.json\n","sampled-threads-ah-delta-context3/390_ah_t1_cq9ov97.json\n","sampled-threads-ah-delta-context3/461_ah_t1_csdzj3p.json\n","sampled-threads-ah-delta-context3/1122_ah_t1_d0iy1nh.json\n","sampled-threads-ah-delta-context3/665_delta_t1_czld8nb.json\n","sampled-threads-ah-delta-context3/1067_delta_t1_dgvu1ne.json\n","sampled-threads-ah-delta-context3/314_delta_t1_dk9i0uu.json\n","sampled-threads-ah-delta-context3/1000_ah_t1_d86bsqs.json\n","sampled-threads-ah-delta-context3/914_ah_t1_cv2jl3t.json\n","sampled-threads-ah-delta-context3/437_delta_t1_cgxru69.json\n","sampled-threads-ah-delta-context3/878_delta_t1_ct94j11.json\n","sampled-threads-ah-delta-context3/257_delta_t1_covtude.json\n","sampled-threads-ah-delta-context3/866_delta_t1_cfe0jv3.json\n","sampled-threads-ah-delta-context3/559_delta_t1_dlg6hhj.json\n","sampled-threads-ah-delta-context3/141_delta_t1_ddxk8oh.json\n","sampled-threads-ah-delta-context3/735_delta_t1_dgu38tg.json\n","sampled-threads-ah-delta-context3/364_ah_t1_djrw4mp.json\n","sampled-threads-ah-delta-context3/427_ah_t1_d98ouv3.json\n","sampled-threads-ah-delta-context3/129_ah_t1_dmfcyjr.json\n","sampled-threads-ah-delta-context3/742_delta_t1_dez83ma.json\n","sampled-threads-ah-delta-context3/602_ah_t1_cn5x37n.json\n","sampled-threads-ah-delta-context3/3_delta_t1_djg3vuf.json\n","sampled-threads-ah-delta-context3/445_delta_t1_dcc1qwk.json\n","sampled-threads-ah-delta-context3/155_ah_t1_contgqn.json\n","sampled-threads-ah-delta-context3/558_delta_t1_d662z4c.json\n","sampled-threads-ah-delta-context3/1046_delta_t1_daf2mah.json\n","sampled-threads-ah-delta-context3/550_ah_t1_dkel1pj.json\n","sampled-threads-ah-delta-context3/1196_delta_t1_cl8qbbd.json\n","sampled-threads-ah-delta-context3/169_delta_t1_cc4twgy.json\n","sampled-threads-ah-delta-context3/1160_delta_t1_d4blehs.json\n","sampled-threads-ah-delta-context3/992_delta_t1_d0inaml.json\n","sampled-threads-ah-delta-context3/258_delta_t1_ck96vg6.json\n","sampled-threads-ah-delta-context3/887_delta_t1_cm8katd.json\n","sampled-threads-ah-delta-context3/110_ah_t1_d3yweqv.json\n","sampled-threads-ah-delta-context3/433_ah_t1_cnwkw1l.json\n","sampled-threads-ah-delta-context3/971_delta_t1_cus3s73.json\n","sampled-threads-ah-delta-context3/607_ah_t1_cumk860.json\n","sampled-threads-ah-delta-context3/1212_ah_t1_dbatw5b.json\n","sampled-threads-ah-delta-context3/731_delta_t1_dn7ntmv.json\n","sampled-threads-ah-delta-context3/1147_delta_t1_db3mlns.json\n","sampled-threads-ah-delta-context3/825_ah_t1_cnu1fi5.json\n","sampled-threads-ah-delta-context3/665_ah_t1_da4k70x.json\n","sampled-threads-ah-delta-context3/723_delta_t1_ciudetm.json\n","sampled-threads-ah-delta-context3/517_delta_t1_d1c6e50.json\n","sampled-threads-ah-delta-context3/1031_ah_t1_dkur88o.json\n","sampled-threads-ah-delta-context3/399_ah_t1_ctped5j.json\n","sampled-threads-ah-delta-context3/936_delta_t1_cb2ka7q.json\n","sampled-threads-ah-delta-context3/814_delta_t1_cxfef52.json\n","sampled-threads-ah-delta-context3/26_delta_t1_diu0jne.json\n","sampled-threads-ah-delta-context3/105_ah_t1_dl96h6s.json\n","sampled-threads-ah-delta-context3/1242_ah_t1_d06pjrq.json\n","sampled-threads-ah-delta-context3/615_delta_t1_dkycmhu.json\n","sampled-threads-ah-delta-context3/820_ah_t1_d2gr6zj.json\n","sampled-threads-ah-delta-context3/1260_delta_t1_dhunexo.json\n","sampled-threads-ah-delta-context3/958_delta_t1_dknk89r.json\n","sampled-threads-ah-delta-context3/206_ah_t1_d71mgq9.json\n","sampled-threads-ah-delta-context3/56_delta_t1_d9v09vn.json\n","sampled-threads-ah-delta-context3/397_delta_t1_ch51k5g.json\n","sampled-threads-ah-delta-context3/250_delta_t1_d6d763v.json\n","sampled-threads-ah-delta-context3/247_delta_t1_cbprlaq.json\n","sampled-threads-ah-delta-context3/537_ah_t1_cox6ez5.json\n","sampled-threads-ah-delta-context3/1102_ah_t1_cji42rq.json\n","sampled-threads-ah-delta-context3/955_ah_t1_cu174y2.json\n","sampled-threads-ah-delta-context3/574_ah_t1_csh5ffl.json\n","sampled-threads-ah-delta-context3/120_ah_t1_d3s18kc.json\n","sampled-threads-ah-delta-context3/862_ah_t1_dlaipub.json\n","sampled-threads-ah-delta-context3/679_delta_t1_d7c4kz7.json\n","sampled-threads-ah-delta-context3/1175_delta_t1_d0q00rx.json\n","sampled-threads-ah-delta-context3/773_ah_t1_dgslqtq.json\n","sampled-threads-ah-delta-context3/684_ah_t1_cjf9u0z.json\n","sampled-threads-ah-delta-context3/729_ah_t1_cwleev4.json\n","sampled-threads-ah-delta-context3/1150_delta_t1_d7a7wfk.json\n","sampled-threads-ah-delta-context3/134_ah_t1_cnq6atw.json\n","sampled-threads-ah-delta-context3/1078_delta_t1_cvlvrd3.json\n","sampled-threads-ah-delta-context3/514_ah_t1_cro228x.json\n","sampled-threads-ah-delta-context3/1019_ah_t1_cnav6o5.json\n","sampled-threads-ah-delta-context3/774_delta_t1_dlph2pt.json\n","sampled-threads-ah-delta-context3/631_delta_t1_dlofv7h.json\n","sampled-threads-ah-delta-context3/653_delta_t1_ck5tk52.json\n","sampled-threads-ah-delta-context3/366_ah_t1_d0k8owh.json\n","sampled-threads-ah-delta-context3/666_delta_t1_d8hqep1.json\n","sampled-threads-ah-delta-context3/893_delta_t1_dffs9qm.json\n","sampled-threads-ah-delta-context3/752_delta_t1_cu6op07.json\n","sampled-threads-ah-delta-context3/191_ah_t1_cycx5fe.json\n","sampled-threads-ah-delta-context3/954_ah_t1_dgofdz0.json\n","sampled-threads-ah-delta-context3/302_ah_t1_d4x6ll9.json\n","sampled-threads-ah-delta-context3/43_delta_t1_dj2cz85.json\n","sampled-threads-ah-delta-context3/301_delta_t1_cgk6xkw.json\n","sampled-threads-ah-delta-context3/374_ah_t1_de5jif9.json\n","sampled-threads-ah-delta-context3/158_delta_t1_d4kpm05.json\n","sampled-threads-ah-delta-context3/1191_ah_t1_da1pdpk.json\n","sampled-threads-ah-delta-context3/450_ah_t1_d1ly2mf.json\n","sampled-threads-ah-delta-context3/390_delta_t1_cw4x93h.json\n","sampled-threads-ah-delta-context3/122_ah_t1_de1p2la.json\n","sampled-threads-ah-delta-context3/283_delta_t1_dkaw50i.json\n","sampled-threads-ah-delta-context3/927_ah_t1_djhzokh.json\n","sampled-threads-ah-delta-context3/143_delta_t1_coc2h7i.json\n","sampled-threads-ah-delta-context3/973_delta_t1_cm8fw8c.json\n","sampled-threads-ah-delta-context3/674_ah_t1_cynqky0.json\n","sampled-threads-ah-delta-context3/566_ah_t1_cmq1iea.json\n","sampled-threads-ah-delta-context3/703_ah_t1_djek7c3.json\n","sampled-threads-ah-delta-context3/1026_delta_t1_d2fdrly.json\n","sampled-threads-ah-delta-context3/754_ah_t1_dkn16ne.json\n","sampled-threads-ah-delta-context3/637_delta_t1_cbcw3sl.json\n","sampled-threads-ah-delta-context3/441_ah_t1_dfmk6cf.json\n","sampled-threads-ah-delta-context3/143_ah_t1_dn02bcy.json\n","sampled-threads-ah-delta-context3/238_ah_t1_ctbgeci.json\n","sampled-threads-ah-delta-context3/1099_ah_t1_cpux4m2.json\n","sampled-threads-ah-delta-context3/485_ah_t1_djphsnf.json\n","sampled-threads-ah-delta-context3/1143_ah_t1_dmxha6q.json\n","sampled-threads-ah-delta-context3/1173_delta_t1_d8fiuir.json\n","sampled-threads-ah-delta-context3/378_ah_t1_cw626w8.json\n","sampled-threads-ah-delta-context3/604_ah_t1_cyx3r8b.json\n","sampled-threads-ah-delta-context3/412_delta_t1_cjho8so.json\n","sampled-threads-ah-delta-context3/856_delta_t1_dghhlo6.json\n","sampled-threads-ah-delta-context3/812_delta_t1_cch94dr.json\n","sampled-threads-ah-delta-context3/1060_delta_t1_cezve5m.json\n","sampled-threads-ah-delta-context3/309_ah_t1_dgghaah.json\n","sampled-threads-ah-delta-context3/806_ah_t1_cjivf4n.json\n","sampled-threads-ah-delta-context3/299_delta_t1_czhvx43.json\n","sampled-threads-ah-delta-context3/1185_delta_t1_dh8yyg0.json\n","sampled-threads-ah-delta-context3/1013_delta_t1_cnogyyn.json\n","sampled-threads-ah-delta-context3/282_delta_t1_dgcyrjd.json\n","sampled-threads-ah-delta-context3/941_ah_t1_dmacgk3.json\n","sampled-threads-ah-delta-context3/1227_ah_t1_d9ym8mu.json\n","sampled-threads-ah-delta-context3/988_ah_t1_dealh7i.json\n","sampled-threads-ah-delta-context3/1034_ah_t1_difttgy.json\n","sampled-threads-ah-delta-context3/949_ah_t1_crb3q1p.json\n","sampled-threads-ah-delta-context3/764_ah_t1_deaxcdk.json\n","sampled-threads-ah-delta-context3/177_ah_t1_cspann3.json\n","sampled-threads-ah-delta-context3/264_delta_t1_cgq73lr.json\n","sampled-threads-ah-delta-context3/380_delta_t1_d0u49tm.json\n","sampled-threads-ah-delta-context3/231_ah_t1_clufbd1.json\n","sampled-threads-ah-delta-context3/763_delta_t1_djckzig.json\n","sampled-threads-ah-delta-context3/734_delta_t1_de3l1ch.json\n","sampled-threads-ah-delta-context3/881_ah_t1_dlpsy51.json\n","sampled-threads-ah-delta-context3/829_ah_t1_did5k4x.json\n","sampled-threads-ah-delta-context3/131_ah_t1_cudl33r.json\n","sampled-threads-ah-delta-context3/655_ah_t1_cjo9u97.json\n","sampled-threads-ah-delta-context3/500_delta_t1_d5k6c89.json\n","sampled-threads-ah-delta-context3/100_delta_t1_cle5h0h.json\n","sampled-threads-ah-delta-context3/1211_delta_t1_dh1jvyg.json\n","sampled-threads-ah-delta-context3/785_delta_t1_cdid3gl.json\n","sampled-threads-ah-delta-context3/1112_delta_t1_ddg2wmr.json\n","sampled-threads-ah-delta-context3/371_ah_t1_ckfhycb.json\n","sampled-threads-ah-delta-context3/881_delta_t1_dhfwq1c.json\n","sampled-threads-ah-delta-context3/815_ah_t1_d20aatq.json\n","sampled-threads-ah-delta-context3/1057_ah_t1_d5mqiy1.json\n","sampled-threads-ah-delta-context3/233_ah_t1_cvqjoff.json\n","sampled-threads-ah-delta-context3/1050_delta_t1_ciz3xia.json\n","sampled-threads-ah-delta-context3/930_ah_t1_cqmckqm.json\n","sampled-threads-ah-delta-context3/446_delta_t1_ck54ote.json\n","sampled-threads-ah-delta-context3/1139_ah_t1_cxxiubv.json\n","sampled-threads-ah-delta-context3/176_ah_t1_d4315on.json\n","sampled-threads-ah-delta-context3/1044_ah_t1_dfdmdr2.json\n","sampled-threads-ah-delta-context3/697_delta_t1_crcwrlr.json\n","sampled-threads-ah-delta-context3/162_ah_t1_dcmlbkl.json\n","sampled-threads-ah-delta-context3/738_ah_t1_dh8dw6y.json\n","sampled-threads-ah-delta-context3/555_delta_t1_d9q7l0c.json\n","sampled-threads-ah-delta-context3/861_ah_t1_dn8gow1.json\n","sampled-threads-ah-delta-context3/212_delta_t1_cc33sey.json\n","sampled-threads-ah-delta-context3/1063_delta_t1_cvumwfv.json\n","sampled-threads-ah-delta-context3/852_ah_t1_ddrenoo.json\n","sampled-threads-ah-delta-context3/425_delta_t1_chg2y74.json\n","sampled-threads-ah-delta-context3/996_ah_t1_ctt05db.json\n","sampled-threads-ah-delta-context3/274_delta_t1_cgppayd.json\n","sampled-threads-ah-delta-context3/788_delta_t1_cc2bava.json\n","sampled-threads-ah-delta-context3/903_ah_t1_cybd1sg.json\n","sampled-threads-ah-delta-context3/859_delta_t1_cj1mzga.json\n","sampled-threads-ah-delta-context3/194_ah_t1_cnjqoug.json\n","sampled-threads-ah-delta-context3/982_ah_t1_dktbgf0.json\n","sampled-threads-ah-delta-context3/1286_ah_t1_d2xj9qy.json\n","sampled-threads-ah-delta-context3/1039_delta_t1_cdkpzce.json\n","sampled-threads-ah-delta-context3/993_delta_t1_cjt21v5.json\n","sampled-threads-ah-delta-context3/662_ah_t1_df9c8fx.json\n","sampled-threads-ah-delta-context3/1232_delta_t1_dgguz02.json\n","sampled-threads-ah-delta-context3/1215_ah_t1_dme4aa0.json\n","sampled-threads-ah-delta-context3/1272_ah_t1_de8lh2y.json\n","sampled-threads-ah-delta-context3/868_delta_t1_cm5frmf.json\n","sampled-threads-ah-delta-context3/1107_ah_t1_d7by5ph.json\n","sampled-threads-ah-delta-context3/104_ah_t1_da05pcr.json\n","sampled-threads-ah-delta-context3/1212_delta_t1_dbvm8oj.json\n","sampled-threads-ah-delta-context3/1246_delta_t1_dj0zojl.json\n","sampled-threads-ah-delta-context3/695_ah_t1_de3ksaa.json\n","sampled-threads-ah-delta-context3/324_delta_t1_ctc5rpf.json\n","sampled-threads-ah-delta-context3/383_delta_t1_d936e84.json\n","sampled-threads-ah-delta-context3/796_delta_t1_d764dim.json\n","sampled-threads-ah-delta-context3/1197_delta_t1_cy2yuas.json\n","sampled-threads-ah-delta-context3/1037_delta_t1_d5mixfa.json\n","sampled-threads-ah-delta-context3/1121_delta_t1_cascor2.json\n","sampled-threads-ah-delta-context3/1247_delta_t1_ctrdsm2.json\n","sampled-threads-ah-delta-context3/416_ah_t1_d7zkcl3.json\n","sampled-threads-ah-delta-context3/814_ah_t1_dkoivia.json\n","sampled-threads-ah-delta-context3/756_delta_t1_d6sybg9.json\n","sampled-threads-ah-delta-context3/292_ah_t1_d2v4t3t.json\n","sampled-threads-ah-delta-context3/1141_delta_t1_dav4zxx.json\n","sampled-threads-ah-delta-context3/750_ah_t1_dg9r00a.json\n","sampled-threads-ah-delta-context3/850_delta_t1_ce1peo6.json\n","sampled-threads-ah-delta-context3/1016_ah_t1_cyrlfqa.json\n","sampled-threads-ah-delta-context3/402_ah_t1_cks66gx.json\n","sampled-threads-ah-delta-context3/643_delta_t1_dee91w4.json\n","sampled-threads-ah-delta-context3/415_delta_t1_dlhresz.json\n","sampled-threads-ah-delta-context3/950_ah_t1_cyp1uug.json\n","sampled-threads-ah-delta-context3/1010_delta_t1_d9cvim0.json\n","sampled-threads-ah-delta-context3/213_ah_t1_crf2xli.json\n","sampled-threads-ah-delta-context3/499_ah_t1_cynj4rh.json\n","sampled-threads-ah-delta-context3/1287_delta_t1_dchl6vp.json\n","sampled-threads-ah-delta-context3/457_delta_t1_djfdqw4.json\n","sampled-threads-ah-delta-context3/861_delta_t1_d3275o8.json\n","sampled-threads-ah-delta-context3/1184_delta_t1_cwvg1gm.json\n","sampled-threads-ah-delta-context3/136_ah_t1_czcux3g.json\n","sampled-threads-ah-delta-context3/489_delta_t1_dchlhjk.json\n","sampled-threads-ah-delta-context3/60_delta_t1_dfx9pno.json\n","sampled-threads-ah-delta-context3/145_delta_t1_cg5kzla.json\n","sampled-threads-ah-delta-context3/885_ah_t1_csw8yim.json\n","sampled-threads-ah-delta-context3/646_ah_t1_dfmh987.json\n","sampled-threads-ah-delta-context3/1166_ah_t1_dcgnag7.json\n","sampled-threads-ah-delta-context3/275_delta_t1_d4abcjw.json\n","sampled-threads-ah-delta-context3/859_ah_t1_czk753b.json\n","sampled-threads-ah-delta-context3/1087_delta_t1_cxos0mk.json\n","sampled-threads-ah-delta-context3/1035_ah_t1_dmi2cjt.json\n","sampled-threads-ah-delta-context3/1065_ah_t1_dfkkayi.json\n","sampled-threads-ah-delta-context3/867_ah_t1_cxaffhk.json\n","sampled-threads-ah-delta-context3/719_delta_t1_crbszo1.json\n","sampled-threads-ah-delta-context3/113_delta_t1_cq7bcsf.json\n","sampled-threads-ah-delta-context3/1202_ah_t1_dfqmlm1.json\n","sampled-threads-ah-delta-context3/394_delta_t1_cia16vu.json\n","sampled-threads-ah-delta-context3/934_ah_t1_cjylm1k.json\n","sampled-threads-ah-delta-context3/619_ah_t1_d7prvks.json\n","sampled-threads-ah-delta-context3/1007_delta_t1_cd1p548.json\n","sampled-threads-ah-delta-context3/294_delta_t1_ctu7kuu.json\n","sampled-threads-ah-delta-context3/716_ah_t1_crf29br.json\n","sampled-threads-ah-delta-context3/1233_ah_t1_de17sq0.json\n","sampled-threads-ah-delta-context3/106_delta_t1_dbbykq5.json\n","sampled-threads-ah-delta-context3/303_ah_t1_ddvcwtl.json\n","sampled-threads-ah-delta-context3/678_ah_t1_cqj5q8o.json\n","sampled-threads-ah-delta-context3/44_delta_t1_dh3hqdz.json\n","sampled-threads-ah-delta-context3/141_ah_t1_ddanwky.json\n","sampled-threads-ah-delta-context3/438_ah_t1_d3clsw8.json\n","sampled-threads-ah-delta-context3/287_ah_t1_d9zg075.json\n","sampled-threads-ah-delta-context3/694_delta_t1_dmxhsg5.json\n","sampled-threads-ah-delta-context3/755_delta_t1_cihul28.json\n","sampled-threads-ah-delta-context3/789_delta_t1_d8ih1z3.json\n","sampled-threads-ah-delta-context3/1073_ah_t1_cj8i5k9.json\n","sampled-threads-ah-delta-context3/673_delta_t1_ctgrw25.json\n","sampled-threads-ah-delta-context3/344_ah_t1_cu49wxv.json\n","sampled-threads-ah-delta-context3/263_delta_t1_cbu1dr7.json\n","sampled-threads-ah-delta-context3/1022_ah_t1_cs4k6wr.json\n","sampled-threads-ah-delta-context3/954_delta_t1_cw9rq5q.json\n","sampled-threads-ah-delta-context3/956_delta_t1_ct4o1w1.json\n","sampled-threads-ah-delta-context3/753_delta_t1_cii4t52.json\n","sampled-threads-ah-delta-context3/689_delta_t1_canmveo.json\n","sampled-threads-ah-delta-context3/229_delta_t1_cgmz58w.json\n","sampled-threads-ah-delta-context3/694_ah_t1_dcv2jj2.json\n","sampled-threads-ah-delta-context3/429_ah_t1_dh4fdvv.json\n","sampled-threads-ah-delta-context3/552_ah_t1_dmnjo82.json\n","sampled-threads-ah-delta-context3/749_delta_t1_dac5u0n.json\n","sampled-threads-ah-delta-context3/130_ah_t1_dk0cpui.json\n","sampled-threads-ah-delta-context3/1104_delta_t1_ddr7nrr.json\n","sampled-threads-ah-delta-context3/1198_ah_t1_di7rg34.json\n","sampled-threads-ah-delta-context3/712_ah_t1_cvt22sf.json\n","sampled-threads-ah-delta-context3/658_delta_t1_cggzxoh.json\n","sampled-threads-ah-delta-context3/668_ah_t1_dcuvlzg.json\n","sampled-threads-ah-delta-context3/217_ah_t1_cjjwcfx.json\n","sampled-threads-ah-delta-context3/1018_ah_t1_d1ijo9u.json\n","sampled-threads-ah-delta-context3/1046_ah_t1_d6h5l13.json\n","sampled-threads-ah-delta-context3/202_ah_t1_dn5ovec.json\n","sampled-threads-ah-delta-context3/1274_delta_t1_cb5b4ut.json\n","sampled-threads-ah-delta-context3/1269_ah_t1_dkr11dp.json\n","sampled-threads-ah-delta-context3/454_ah_t1_dlcamzx.json\n","sampled-threads-ah-delta-context3/12_ah_t1_dlnti02.json\n","sampled-threads-ah-delta-context3/91_ah_t1_d7joy4q.json\n","sampled-threads-ah-delta-context3/998_delta_t1_cvhovbw.json\n","sampled-threads-ah-delta-context3/79_ah_t1_cw18qa6.json\n","sampled-threads-ah-delta-context3/721_delta_t1_cfky7rz.json\n","sampled-threads-ah-delta-context3/1012_delta_t1_crhrjjv.json\n","sampled-threads-ah-delta-context3/810_ah_t1_dmlex3b.json\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QrHlig_p4oh","executionInfo":{"status":"ok","timestamp":1615642274923,"user_tz":-330,"elapsed":1099392,"user":{"displayName":"Utkarsh Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4WnjwP-2YGoFk8O-jMTl4jmo7YjKJ6PEf7WDUbw=s64","userId":"14292413845157007490"}},"outputId":"923c6a7a-2069-43c9-f9d1-1dbf2e0d8a09"},"source":["%%shell\n","cd /content/gdrive/'My Drive'/Ad-hominem-fallacies/experiments\n","pip install lda\n","python classification_experiments.py --model cnn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting lda\n","  Using cached https://files.pythonhosted.org/packages/d1/45/8bf6862a599649350280bf0020b0b23c4948304158702632f677dc967737/lda-2.0.0-cp37-cp37m-manylinux1_x86_64.whl\n","Requirement already satisfied: numpy<2.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from lda) (1.19.5)\n","Collecting pbr<4,>=0.6\n","  Using cached https://files.pythonhosted.org/packages/0c/5d/b077dbf309993d52c1d71e6bf6fe443a8029ea215135ebbe0b1b10e7aefc/pbr-3.1.1-py2.py3-none-any.whl\n","Installing collected packages: pbr, lda\n","Successfully installed lda-2.0.0 pbr-3.1.1\n","2021-03-13 13:13:00.977974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","WARNING:tensorflow:From classification_experiments.py:76: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n","2021-03-13 13:13:02.677776: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 13:13:02.678756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-03-13 13:13:02.739952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:02.740544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 13:13:02.740589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 13:13:02.839802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 13:13:02.839906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 13:13:03.012979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 13:13:03.062272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 13:13:03.319888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 13:13:03.351111: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 13:13:03.354741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 13:13:03.354885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:03.355557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:03.358182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 13:13:03.360062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 13:13:07.755779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-03-13 13:13:07.755829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-03-13 13:13:07.755843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-03-13 13:13:07.818660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.819388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.819985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.820498: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-03-13 13:13:07.820556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 13994 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2021-03-13 13:13:07.825704: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 13:13:07.825820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.826379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 13:13:07.826430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 13:13:07.826481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 13:13:07.826504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 13:13:07.826528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 13:13:07.826553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 13:13:07.826577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 13:13:07.826599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 13:13:07.826637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 13:13:07.826711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.827292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.827828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 13:13:07.828118: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 13:13:07.828224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.828754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 13:13:07.828795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 13:13:07.828831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 13:13:07.828856: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 13:13:07.828879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 13:13:07.828901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 13:13:07.828925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 13:13:07.828947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 13:13:07.828968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 13:13:07.829035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.829677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.830175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 13:13:07.830237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-03-13 13:13:07.830254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-03-13 13:13:07.830268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-03-13 13:13:07.830364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.830920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:13:07.831435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13994 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Using GPU\n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Running fold 1/10\n","Max length in training data:  406\n","Compiling model\n","/content/gdrive/My Drive/Ad-hominem-fallacies/experiments/nnclassifiers.py:380: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  result_x_numpy_array = numpy.array(result_x)\n","2021-03-13 13:13:14.757072: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_286\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2021-03-13 13:13:14.812572: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2021-03-13 13:13:14.814627: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n","Epoch 1/5\n","2021-03-13 13:13:17.683314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 13:13:20.201936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 13:13:20.290717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","204/204 [==============================] - 54s 91ms/step - loss: 1.4602\n","Epoch 2/5\n","204/204 [==============================] - 18s 90ms/step - loss: 0.6521\n","Epoch 3/5\n","204/204 [==============================] - 19s 91ms/step - loss: 0.4674\n","Epoch 4/5\n","204/204 [==============================] - 19s 92ms/step - loss: 0.3662\n","Epoch 5/5\n","204/204 [==============================] - 19s 93ms/step - loss: 0.2897\n","2021-03-13 13:15:23.657872: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_2418\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 2s 24ms/step\n","Evaluating after 1 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH       283        71       354\n","      None        84       287       371\n","     [sum]       367       358       725\n","Accuracy: 0.7862 (95ppCI: 0.0298)  Macro F1: 0.7865\n","AH: P=0.7711/R=0.7994/F1=0.7850 None: P=0.8017/R=0.7736/F1=0.7874\n","Running fold 2/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:15:26.393576: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_2918\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 22s 94ms/step - loss: 1.4350\n","Epoch 2/5\n","204/204 [==============================] - 19s 95ms/step - loss: 0.6886\n","Epoch 3/5\n","204/204 [==============================] - 19s 95ms/step - loss: 0.4915\n","Epoch 4/5\n","204/204 [==============================] - 20s 96ms/step - loss: 0.3548\n","Epoch 5/5\n","204/204 [==============================] - 20s 96ms/step - loss: 0.3212\n","2021-03-13 13:17:06.029776: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_5050\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 1s 25ms/step\n","Evaluating after 2 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH       556       164       720\n","      None       134       596       730\n","     [sum]       690       760      1450\n","Accuracy: 0.7945 (95ppCI: 0.0208)  Macro F1: 0.7947\n","AH: P=0.8058/R=0.7722/F1=0.7887 None: P=0.7842/R=0.8164/F1=0.8000\n","Running fold 3/10\n","Max length in training data:  404\n","Compiling model\n","2021-03-13 13:17:07.567263: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_5550\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 24s 100ms/step - loss: 1.4383\n","Epoch 2/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.6825\n","Epoch 3/5\n","204/204 [==============================] - 20s 99ms/step - loss: 0.4665\n","Epoch 4/5\n","204/204 [==============================] - 20s 99ms/step - loss: 0.3856\n","Epoch 5/5\n","204/204 [==============================] - 20s 100ms/step - loss: 0.3259\n","2021-03-13 13:18:52.092635: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_7682\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 2s 25ms/step\n","Evaluating after 3 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH       870       228      1098\n","      None       206       871      1077\n","     [sum]      1076      1099      2175\n","Accuracy: 0.8005 (95ppCI: 0.0168)  Macro F1: 0.8005\n","AH: P=0.8086/R=0.7923/F1=0.8004 None: P=0.7925/R=0.8087/F1=0.8006\n","Running fold 4/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:18:54.618494: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_8182\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 23s 98ms/step - loss: 1.4589\n","Epoch 2/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.7039\n","Epoch 3/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.4581\n","Epoch 4/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3704\n","Epoch 5/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3138\n","2021-03-13 13:20:37.384038: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_10314\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 2s 25ms/step\n","Evaluating after 4 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      1111       335      1446\n","      None       241      1213      1454\n","     [sum]      1352      1548      2900\n","Accuracy: 0.8014 (95ppCI: 0.0145)  Macro F1: 0.8020\n","AH: P=0.8217/R=0.7683/F1=0.7941 None: P=0.7836/R=0.8343/F1=0.8081\n","Running fold 5/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:20:39.917445: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_10814\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 23s 98ms/step - loss: 1.4278\n","Epoch 2/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.6879\n","Epoch 3/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.4775\n","Epoch 4/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3917\n","Epoch 5/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3151\n","2021-03-13 13:22:22.855888: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_12946\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 2s 25ms/step\n","Evaluating after 5 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      1363       444      1807\n","      None       281      1537      1818\n","     [sum]      1644      1981      3625\n","Accuracy: 0.8000 (95ppCI: 0.0130)  Macro F1: 0.8012\n","AH: P=0.8291/R=0.7543/F1=0.7899 None: P=0.7759/R=0.8454/F1=0.8092\n","Running fold 6/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:22:25.363458: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_13446\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 23s 98ms/step - loss: 1.3883\n","Epoch 2/5\n","204/204 [==============================] - 20s 99ms/step - loss: 0.6744\n","Epoch 3/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.4633\n","Epoch 4/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.4010\n","Epoch 5/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3086\n","2021-03-13 13:24:08.117026: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_15578\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 2s 25ms/step\n","Evaluating after 6 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      1635       541      2176\n","      None       316      1858      2174\n","     [sum]      1951      2399      4350\n","Accuracy: 0.8030 (95ppCI: 0.0118)  Macro F1: 0.8046\n","AH: P=0.8380/R=0.7514/F1=0.7923 None: P=0.7745/R=0.8546/F1=0.8126\n","Running fold 7/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:24:10.618067: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_16078\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 23s 98ms/step - loss: 1.4080\n","Epoch 2/5\n","204/204 [==============================] - 20s 99ms/step - loss: 0.6826\n","Epoch 3/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.4954\n","Epoch 4/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3898\n","Epoch 5/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3070\n","2021-03-13 13:25:53.662470: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_18210\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 2s 25ms/step\n","Evaluating after 7 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      1929       617      2546\n","      None       364      2165      2529\n","     [sum]      2293      2782      5075\n","Accuracy: 0.8067 (95ppCI: 0.0109)  Macro F1: 0.8083\n","AH: P=0.8413/R=0.7577/F1=0.7973 None: P=0.7782/R=0.8561/F1=0.8153\n","Running fold 8/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:25:56.189245: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_18710\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 23s 98ms/step - loss: 1.4206\n","Epoch 2/5\n","204/204 [==============================] - 20s 99ms/step - loss: 0.6774\n","Epoch 3/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.4507\n","Epoch 4/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3929\n","Epoch 5/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3009\n","2021-03-13 13:27:39.080184: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_20842\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 2s 25ms/step\n","Evaluating after 8 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      2227       682      2909\n","      None       430      2461      2891\n","     [sum]      2657      3143      5800\n","Accuracy: 0.8083 (95ppCI: 0.0101)  Macro F1: 0.8095\n","AH: P=0.8382/R=0.7656/F1=0.8002 None: P=0.7830/R=0.8513/F1=0.8157\n","Running fold 9/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:27:41.569779: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_21342\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 23s 99ms/step - loss: 1.4657\n","Epoch 2/5\n","204/204 [==============================] - 20s 99ms/step - loss: 0.6761\n","Epoch 3/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.4330\n","Epoch 4/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3566\n","Epoch 5/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3436\n","2021-03-13 13:29:24.642834: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_23474\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 1s 25ms/step\n","Evaluating after 9 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      2523       741      3264\n","      None       513      2748      3261\n","     [sum]      3036      3489      6525\n","Accuracy: 0.8078 (95ppCI: 0.0096)  Macro F1: 0.8086\n","AH: P=0.8310/R=0.7730/F1=0.8010 None: P=0.7876/R=0.8427/F1=0.8142\n","Running fold 10/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:29:26.152617: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_23974\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 23s 101ms/step - loss: 1.4207\n","Epoch 2/5\n","204/204 [==============================] - 20s 99ms/step - loss: 0.6649\n","Epoch 3/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.4814\n","Epoch 4/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3839\n","Epoch 5/5\n","204/204 [==============================] - 20s 98ms/step - loss: 0.3158\n","2021-03-13 13:31:09.816118: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_26106\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 2s 32ms/step\n","Evaluating after 10 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      2825       797      3622\n","      None       597      3023      3620\n","     [sum]      3422      3820      7242\n","Accuracy: 0.8075 (95ppCI: 0.0091)  Macro F1: 0.8080\n","AH: P=0.8255/R=0.7800/F1=0.8021 None: P=0.7914/R=0.8351/F1=0.8126\n","Final evaluation; reader.input_path_train was data/experiments/ah-classification1/exported-3621-sampled-positive-negative-ah-no-context.json\n","↓gold pr.→        AH      None     [sum]\n","        AH      2825       797      3622\n","      None       597      3023      3620\n","     [sum]      3422      3820      7242\n","Accuracy: 0.8075 (95ppCI: 0.0091)  Macro F1: 0.8080\n","AH: P=0.8255/R=0.7800/F1=0.8021 None: P=0.7914/R=0.8351/F1=0.8126\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzQ_M8vM3aen","executionInfo":{"status":"ok","timestamp":1615643235668,"user_tz":-330,"elapsed":881660,"user":{"displayName":"Utkarsh Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4WnjwP-2YGoFk8O-jMTl4jmo7YjKJ6PEf7WDUbw=s64","userId":"14292413845157007490"}},"outputId":"e3a5aee1-6ecd-49f6-ffe9-74c97bd7768f"},"source":["%%shell\n","cd /content/gdrive/'My Drive'/Ad-hominem-fallacies/experiments\n","pip install lda\n","python classification_experiments.py --model bilstm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: lda in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: numpy<2.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from lda) (1.19.5)\n","Requirement already satisfied: pbr<4,>=0.6 in /usr/local/lib/python3.7/dist-packages (from lda) (3.1.1)\n","2021-03-13 13:32:36.490056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","WARNING:tensorflow:From classification_experiments.py:76: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n","2021-03-13 13:32:38.079147: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 13:32:38.079934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-03-13 13:32:38.110810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.111365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 13:32:38.111408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 13:32:38.117491: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 13:32:38.117577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 13:32:38.122103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 13:32:38.122522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 13:32:38.124406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 13:32:38.125115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 13:32:38.125320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 13:32:38.125432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.126039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.126673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 13:32:38.126732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 13:32:38.629348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-03-13 13:32:38.629400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-03-13 13:32:38.629420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-03-13 13:32:38.629600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.630229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.630789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.631293: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-03-13 13:32:38.631344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 13994 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2021-03-13 13:32:38.631902: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 13:32:38.632006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.632531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 13:32:38.632578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 13:32:38.632633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 13:32:38.632657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 13:32:38.632677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 13:32:38.632695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 13:32:38.632724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 13:32:38.632743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 13:32:38.632762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 13:32:38.632824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.633362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.633854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 13:32:38.634103: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 13:32:38.634198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.634730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 13:32:38.634770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 13:32:38.634807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 13:32:38.634827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 13:32:38.634846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 13:32:38.634864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 13:32:38.634884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 13:32:38.634902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 13:32:38.634920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 13:32:38.634978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.635498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.635980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 13:32:38.636011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-03-13 13:32:38.636026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-03-13 13:32:38.636040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-03-13 13:32:38.636135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.636694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 13:32:38.637188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13994 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Using GPU\n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Warning: instance contains only a single token: \n","Running fold 1/10\n","Max length in training data:  406\n","Compiling model\n","/content/gdrive/My Drive/Ad-hominem-fallacies/experiments/nnclassifiers.py:380: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  result_x_numpy_array = numpy.array(result_x)\n","2021-03-13 13:32:47.359202: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_7062\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2021-03-13 13:32:47.364840: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2021-03-13 13:32:47.365195: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n","Epoch 1/5\n","2021-03-13 13:32:58.402763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 13:32:58.860113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 13:32:59.064576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","204/204 [==============================] - 27s 62ms/step - loss: 0.6834\n","Epoch 2/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.4503\n","Epoch 3/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.3019\n","Epoch 4/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.1850\n","Epoch 5/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.1283\n","2021-03-13 13:34:05.875032: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_28540\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 5s 23ms/step\n","Evaluating after 1 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH       289        65       354\n","      None       117       254       371\n","     [sum]       406       319       725\n","Accuracy: 0.7490 (95ppCI: 0.0316)  Macro F1: 0.7523\n","AH: P=0.7118/R=0.8164/F1=0.7605 None: P=0.7962/R=0.6846/F1=0.7362\n","Running fold 2/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:34:14.485038: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_42445\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 25s 64ms/step - loss: 0.6918\n","Epoch 2/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.4627\n","Epoch 3/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.3127\n","Epoch 4/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.1806\n","Epoch 5/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.1004\n","2021-03-13 13:35:31.526744: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_63923\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 5s 25ms/step\n","Evaluating after 2 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH       562       158       720\n","      None       192       538       730\n","     [sum]       754       696      1450\n","Accuracy: 0.7586 (95ppCI: 0.0220)  Macro F1: 0.7590\n","AH: P=0.7454/R=0.7806/F1=0.7626 None: P=0.7730/R=0.7370/F1=0.7546\n","Running fold 3/10\n","Max length in training data:  404\n","Compiling model\n","2021-03-13 13:35:40.723763: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_77828\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 25s 64ms/step - loss: 0.6750\n","Epoch 2/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.4890\n","Epoch 3/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.3240\n","Epoch 4/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.1890\n","Epoch 5/5\n","204/204 [==============================] - 13s 62ms/step - loss: 0.1038\n","2021-03-13 13:36:57.868518: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_99306\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 6s 25ms/step\n","Evaluating after 3 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH       859       239      1098\n","      None       258       819      1077\n","     [sum]      1117      1058      2175\n","Accuracy: 0.7715 (95ppCI: 0.0176)  Macro F1: 0.7715\n","AH: P=0.7690/R=0.7823/F1=0.7756 None: P=0.7741/R=0.7604/F1=0.7672\n","Running fold 4/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:37:06.852656: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_113211\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 25s 63ms/step - loss: 0.6902\n","Epoch 2/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.4619\n","Epoch 3/5\n","204/204 [==============================] - 13s 66ms/step - loss: 0.3091\n","Epoch 4/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.2040\n","Epoch 5/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.1158\n","2021-03-13 13:38:24.150978: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_134689\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 5s 24ms/step\n","Evaluating after 4 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      1157       289      1446\n","      None       370      1084      1454\n","     [sum]      1527      1373      2900\n","Accuracy: 0.7728 (95ppCI: 0.0153)  Macro F1: 0.7732\n","AH: P=0.7577/R=0.8001/F1=0.7783 None: P=0.7895/R=0.7455/F1=0.7669\n","Running fold 5/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:38:33.410457: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_148594\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 24s 64ms/step - loss: 0.6944\n","Epoch 2/5\n","204/204 [==============================] - 13s 62ms/step - loss: 0.4715\n","Epoch 3/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.3121\n","Epoch 4/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.2038\n","Epoch 5/5\n","204/204 [==============================] - 13s 65ms/step - loss: 0.1107\n","2021-03-13 13:39:49.651538: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_170072\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 5s 25ms/step\n","Evaluating after 5 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      1416       391      1807\n","      None       433      1385      1818\n","     [sum]      1849      1776      3625\n","Accuracy: 0.7727 (95ppCI: 0.0136)  Macro F1: 0.7728\n","AH: P=0.7658/R=0.7836/F1=0.7746 None: P=0.7798/R=0.7618/F1=0.7707\n","Running fold 6/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:39:58.605713: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_183977\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 25s 63ms/step - loss: 0.6744\n","Epoch 2/5\n","204/204 [==============================] - 13s 62ms/step - loss: 0.4501\n","Epoch 3/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.3041\n","Epoch 4/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.2129\n","Epoch 5/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.1077\n","2021-03-13 13:41:15.685762: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_205455\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 6s 25ms/step\n","Evaluating after 6 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      1704       472      2176\n","      None       489      1685      2174\n","     [sum]      2193      2157      4350\n","Accuracy: 0.7791 (95ppCI: 0.0123)  Macro F1: 0.7791\n","AH: P=0.7770/R=0.7831/F1=0.7800 None: P=0.7812/R=0.7751/F1=0.7781\n","Running fold 7/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:41:24.860656: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_219360\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 26s 64ms/step - loss: 0.6720\n","Epoch 2/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.4469\n","Epoch 3/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.3338\n","Epoch 4/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.1993\n","Epoch 5/5\n","204/204 [==============================] - 13s 65ms/step - loss: 0.1245\n","2021-03-13 13:42:42.875906: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_240838\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 6s 24ms/step\n","Evaluating after 7 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      1991       555      2546\n","      None       561      1968      2529\n","     [sum]      2552      2523      5075\n","Accuracy: 0.7801 (95ppCI: 0.0114)  Macro F1: 0.7801\n","AH: P=0.7802/R=0.7820/F1=0.7811 None: P=0.7800/R=0.7782/F1=0.7791\n","Running fold 8/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:42:52.363026: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_254743\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 25s 63ms/step - loss: 0.6869\n","Epoch 2/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.4655\n","Epoch 3/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.3253\n","Epoch 4/5\n","204/204 [==============================] - 13s 65ms/step - loss: 0.1865\n","Epoch 5/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.1056\n","2021-03-13 13:44:09.839480: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_276221\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 5s 27ms/step\n","Evaluating after 8 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      2280       629      2909\n","      None       642      2249      2891\n","     [sum]      2922      2878      5800\n","Accuracy: 0.7809 (95ppCI: 0.0106)  Macro F1: 0.7809\n","AH: P=0.7803/R=0.7838/F1=0.7820 None: P=0.7814/R=0.7779/F1=0.7797\n","Running fold 9/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:44:19.093169: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_290126\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 26s 64ms/step - loss: 0.6846\n","Epoch 2/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.4668\n","Epoch 3/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.3338\n","Epoch 4/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.2030\n","Epoch 5/5\n","204/204 [==============================] - 13s 63ms/step - loss: 0.1185\n","2021-03-13 13:45:36.536058: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_311604\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 6s 26ms/step\n","Evaluating after 9 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      2585       679      3264\n","      None       746      2515      3261\n","     [sum]      3331      3194      6525\n","Accuracy: 0.7816 (95ppCI: 0.0100)  Macro F1: 0.7817\n","AH: P=0.7760/R=0.7920/F1=0.7839 None: P=0.7874/R=0.7712/F1=0.7792\n","Running fold 10/10\n","Max length in training data:  406\n","Compiling model\n","2021-03-13 13:45:45.904797: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_325509\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","204/204 [==============================] - 26s 64ms/step - loss: 0.6813\n","Epoch 2/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.4763\n","Epoch 3/5\n","204/204 [==============================] - 13s 65ms/step - loss: 0.3034\n","Epoch 4/5\n","204/204 [==============================] - 13s 64ms/step - loss: 0.2040\n","Epoch 5/5\n","204/204 [==============================] - 13s 65ms/step - loss: 0.1074\n","2021-03-13 13:47:04.452667: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_346987\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","23/23 [==============================] - 5s 24ms/step\n","Evaluating after 10 folds\n","↓gold pr.→        AH      None     [sum]\n","        AH      2825       797      3622\n","      None       791      2829      3620\n","     [sum]      3616      3626      7242\n","Accuracy: 0.7807 (95ppCI: 0.0095)  Macro F1: 0.7807\n","AH: P=0.7812/R=0.7800/F1=0.7806 None: P=0.7802/R=0.7815/F1=0.7808\n","Final evaluation; reader.input_path_train was data/experiments/ah-classification1/exported-3621-sampled-positive-negative-ah-no-context.json\n","↓gold pr.→        AH      None     [sum]\n","        AH      2825       797      3622\n","      None       791      2829      3620\n","     [sum]      3616      3626      7242\n","Accuracy: 0.7807 (95ppCI: 0.0095)  Macro F1: 0.7807\n","AH: P=0.7812/R=0.7800/F1=0.7806 None: P=0.7802/R=0.7815/F1=0.7808\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"GahLy-de8W9c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615646572046,"user_tz":-330,"elapsed":856222,"user":{"displayName":"Utkarsh Patel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4WnjwP-2YGoFk8O-jMTl4jmo7YjKJ6PEf7WDUbw=s64","userId":"14292413845157007490"}},"outputId":"549aed1f-5837-47fe-c80f-107bbf476765"},"source":["%%shell\n","cd /content/gdrive/'My Drive'/Ad-hominem-fallacies/experiments\n","pip install lda\n","python classification_experiments.py --model ssase"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: lda in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: pbr<4,>=0.6 in /usr/local/lib/python3.7/dist-packages (from lda) (3.1.1)\n","Requirement already satisfied: numpy<2.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from lda) (1.19.5)\n","Collecting tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/dc/e8c5e7983866fa4ef3fd619faa35f660b95b01a2ab62b3884f038ccab542/tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n","\u001b[K     |████████████████████████████████| 394.3MB 39kB/s \n","\u001b[?25hCollecting tensorboard~=2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6MB)\n","\u001b[K     |████████████████████████████████| 10.6MB 53.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n","Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n","Collecting gast==0.3.3\n","  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n","Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n","Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n","Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Collecting tensorflow-estimator<2.5.0,>=2.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462kB)\n","\u001b[K     |████████████████████████████████| 471kB 51.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n","Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (54.0.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n","Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n","Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.1.1\n","    Uninstalling tensorboard-2.1.1:\n","      Successfully uninstalled tensorboard-2.1.1\n","  Found existing installation: gast 0.2.2\n","    Uninstalling gast-0.2.2:\n","      Successfully uninstalled gast-0.2.2\n","  Found existing installation: tensorflow-estimator 2.1.0\n","    Uninstalling tensorflow-estimator-2.1.0:\n","      Successfully uninstalled tensorflow-estimator-2.1.0\n","  Found existing installation: tensorflow 2.1.0\n","    Uninstalling tensorflow-2.1.0:\n","      Successfully uninstalled tensorflow-2.1.0\n","Successfully installed gast-0.3.3 tensorboard-2.4.1 tensorflow-2.4.1 tensorflow-estimator-2.4.0\n","Collecting keras\n","  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.3.1\n","    Uninstalling Keras-2.3.1:\n","      Successfully uninstalled Keras-2.3.1\n","Successfully installed keras-2.4.3\n","2021-03-13 14:29:43.220230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","WARNING:tensorflow:From classification_experiments.py:99: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n","2021-03-13 14:29:45.126366: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-03-13 14:29:45.126639: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 14:29:45.128666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-03-13 14:29:45.157995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.158563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 14:29:45.158616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 14:29:45.174456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 14:29:45.174529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 14:29:45.176391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 14:29:45.176778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 14:29:45.180848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 14:29:45.183198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 14:29:45.183921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 14:29:45.184032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.184626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.185132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 14:29:45.185255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 14:29:45.782806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-03-13 14:29:45.782853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-03-13 14:29:45.782865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-03-13 14:29:45.783119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.783733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.784278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.784775: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-03-13 14:29:45.784820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2021-03-13 14:29:45.785425: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 14:29:45.785534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.786079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 14:29:45.786123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 14:29:45.786165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 14:29:45.786185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 14:29:45.786203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 14:29:45.786221: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 14:29:45.786240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 14:29:45.786258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 14:29:45.786276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 14:29:45.786338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.786881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.787366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 14:29:45.787723: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-03-13 14:29:45.787819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.788349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-03-13 14:29:45.788388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-03-13 14:29:45.788424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 14:29:45.788445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 14:29:45.788461: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2021-03-13 14:29:45.788480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2021-03-13 14:29:45.788497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2021-03-13 14:29:45.788515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2021-03-13 14:29:45.788533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2021-03-13 14:29:45.788593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.789147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.789650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2021-03-13 14:29:45.789685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-03-13 14:29:45.789705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2021-03-13 14:29:45.789715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2021-03-13 14:29:45.789800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.790335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-13 14:29:45.790837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Using GPU\n","Running fold 1/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten[0][0]                    \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","/content/gdrive/My Drive/Ad-hominem-fallacies/experiments/nnclassifiers.py:380: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  result_x_numpy_array = numpy.array(result_x)\n","2021-03-13 14:29:58.428623: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_3741\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2021-03-13 14:29:58.435889: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2021-03-13 14:29:58.436395: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n","Epoch 1/5\n","2021-03-13 14:30:05.622500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2021-03-13 14:30:06.100804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2021-03-13 14:30:06.327100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","73/73 [==============================] - 26s 156ms/step - loss: 1.7576\n","Epoch 2/5\n","73/73 [==============================] - 11s 158ms/step - loss: 0.6780\n","Epoch 3/5\n","73/73 [==============================] - 11s 152ms/step - loss: 0.6260\n","Epoch 4/5\n","73/73 [==============================] - 11s 153ms/step - loss: 0.6066\n","Epoch 5/5\n","73/73 [==============================] - 11s 151ms/step - loss: 0.6362\n","2021-03-13 14:31:09.837126: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_15146\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 84ms/step\n","2021-03-13 14:31:13.545958: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_18796\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2021-03-13 14:31:17.203986: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 246205400 exceeds 10% of free system memory.\n","Collected words+weights saved to /tmp/visualization-context3/fold1.json\n","Evaluating after 1 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah        56        70       126\n","     delta        14       119       133\n","     [sum]        70       189       259\n","Accuracy: 0.6757 (95ppCI: 0.0570)  Macro F1: 0.6915\n","ah: P=0.8000/R=0.4444/F1=0.5714 delta: P=0.6296/R=0.8947/F1=0.7391\n","Running fold 2/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_1[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:31:20.754519: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_26131\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 20s 163ms/step - loss: 1.7027\n","Epoch 2/5\n","73/73 [==============================] - 12s 167ms/step - loss: 0.6550\n","Epoch 3/5\n","73/73 [==============================] - 12s 162ms/step - loss: 0.6154\n","Epoch 4/5\n","73/73 [==============================] - 12s 157ms/step - loss: 0.6005\n","Epoch 5/5\n","73/73 [==============================] - 12s 160ms/step - loss: 0.5629\n","2021-03-13 14:32:27.820878: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_37536\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 70ms/step\n","2021-03-13 14:32:31.979727: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_41186\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2021-03-13 14:32:35.416274: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 246205400 exceeds 10% of free system memory.\n","Collected words+weights saved to /tmp/visualization-context3/fold2.json\n","Evaluating after 2 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       170       105       275\n","     delta        49       194       243\n","     [sum]       219       299       518\n","Accuracy: 0.7027 (95ppCI: 0.0394)  Macro F1: 0.7104\n","ah: P=0.7763/R=0.6182/F1=0.6883 delta: P=0.6488/R=0.7984/F1=0.7159\n","Running fold 3/10\n","Max length in training data:  4514\n","Embeddings shape: (100004, 300)\n","Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_2[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:32:38.518897: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_48521\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 19s 154ms/step - loss: 2.0500\n","Epoch 2/5\n","73/73 [==============================] - 11s 153ms/step - loss: 0.6592\n","Epoch 3/5\n","73/73 [==============================] - 11s 152ms/step - loss: 0.6109\n","Epoch 4/5\n","73/73 [==============================] - 11s 154ms/step - loss: 0.6266\n","Epoch 5/5\n","73/73 [==============================] - 11s 155ms/step - loss: 0.5824\n","2021-03-13 14:33:42.830821: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_59926\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 100ms/step\n","2021-03-13 14:33:47.208105: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_63576\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2021-03-13 14:33:50.934746: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 233825200 exceeds 10% of free system memory.\n","Collected words+weights saved to /tmp/visualization-context3/fold3.json\n","Evaluating after 3 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       267       128       395\n","     delta        91       291       382\n","     [sum]       358       419       777\n","Accuracy: 0.7181 (95ppCI: 0.0316)  Macro F1: 0.7195\n","ah: P=0.7458/R=0.6759/F1=0.7092 delta: P=0.6945/R=0.7618/F1=0.7266\n","Running fold 4/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model_6\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_3[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:33:53.891242: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_70911\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 20s 161ms/step - loss: 1.6979\n","Epoch 2/5\n","73/73 [==============================] - 12s 159ms/step - loss: 0.6483\n","Epoch 3/5\n","73/73 [==============================] - 11s 157ms/step - loss: 0.6488\n","Epoch 4/5\n","73/73 [==============================] - 11s 151ms/step - loss: 0.5707\n","Epoch 5/5\n","73/73 [==============================] - 12s 163ms/step - loss: 0.6426\n","2021-03-13 14:34:59.514074: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_82316\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 85ms/step\n","2021-03-13 14:35:03.823721: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_85966\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2021-03-13 14:35:07.370160: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 246205400 exceeds 10% of free system memory.\n","Collected words+weights saved to /tmp/visualization-context3/fold4.json\n","Evaluating after 4 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       366       158       524\n","     delta       132       380       512\n","     [sum]       498       538      1036\n","Accuracy: 0.7201 (95ppCI: 0.0273)  Macro F1: 0.7205\n","ah: P=0.7349/R=0.6985/F1=0.7162 delta: P=0.7063/R=0.7422/F1=0.7238\n","Running fold 5/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model_8\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_4[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:35:10.358787: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_93301\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 19s 158ms/step - loss: 1.9518\n","Epoch 2/5\n","73/73 [==============================] - 11s 158ms/step - loss: 0.6870\n","Epoch 3/5\n","73/73 [==============================] - 11s 150ms/step - loss: 0.6239\n","Epoch 4/5\n","73/73 [==============================] - 12s 160ms/step - loss: 0.6447\n","Epoch 5/5\n","73/73 [==============================] - 12s 161ms/step - loss: 0.5857\n","2021-03-13 14:36:15.576714: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_104706\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 66ms/step\n","2021-03-13 14:36:19.684387: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_108356\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","2021-03-13 14:36:23.118387: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 246205400 exceeds 10% of free system memory.\n","Collected words+weights saved to /tmp/visualization-context3/fold5.json\n","Evaluating after 5 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       439       218       657\n","     delta       139       499       638\n","     [sum]       578       717      1295\n","Accuracy: 0.7243 (95ppCI: 0.0243)  Macro F1: 0.7264\n","ah: P=0.7595/R=0.6682/F1=0.7109 delta: P=0.6960/R=0.7821/F1=0.7365\n","Running fold 6/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model_10\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_5 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_5[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:36:26.364825: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_115691\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 20s 165ms/step - loss: 2.0123\n","Epoch 2/5\n","73/73 [==============================] - 12s 163ms/step - loss: 0.6385\n","Epoch 3/5\n","73/73 [==============================] - 12s 162ms/step - loss: 0.6172\n","Epoch 4/5\n","73/73 [==============================] - 12s 163ms/step - loss: 0.6205\n","Epoch 5/5\n","73/73 [==============================] - 11s 156ms/step - loss: 0.5758\n","2021-03-13 14:37:33.541179: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_127096\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 79ms/step\n","2021-03-13 14:37:37.235188: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_130746\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Collected words+weights saved to /tmp/visualization-context3/fold6.json\n","Evaluating after 6 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       539       237       776\n","     delta       195       583       778\n","     [sum]       734       820      1554\n","Accuracy: 0.7220 (95ppCI: 0.0223)  Macro F1: 0.7223\n","ah: P=0.7343/R=0.6946/F1=0.7139 delta: P=0.7110/R=0.7494/F1=0.7297\n","Running fold 7/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model_12\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_6 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_6[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:37:43.646644: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_138081\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 19s 150ms/step - loss: 1.9742\n","Epoch 2/5\n","73/73 [==============================] - 11s 157ms/step - loss: 0.6718\n","Epoch 3/5\n","73/73 [==============================] - 11s 155ms/step - loss: 0.6048\n","Epoch 4/5\n","73/73 [==============================] - 12s 160ms/step - loss: 0.5816\n","Epoch 5/5\n","73/73 [==============================] - 12s 159ms/step - loss: 0.5862\n","2021-03-13 14:38:49.364798: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_149486\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 85ms/step\n","2021-03-13 14:38:53.052219: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_153136\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Collected words+weights saved to /tmp/visualization-context3/fold7.json\n","Evaluating after 7 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       604       284       888\n","     delta       217       708       925\n","     [sum]       821       992      1813\n","Accuracy: 0.7237 (95ppCI: 0.0206)  Macro F1: 0.7237\n","ah: P=0.7357/R=0.6802/F1=0.7068 delta: P=0.7137/R=0.7654/F1=0.7387\n","Running fold 8/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model_14\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_7 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_7[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:38:59.733910: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_160471\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 20s 157ms/step - loss: 1.8863\n","Epoch 2/5\n","73/73 [==============================] - 12s 162ms/step - loss: 0.6536\n","Epoch 3/5\n","73/73 [==============================] - 11s 157ms/step - loss: 0.6199\n","Epoch 4/5\n","73/73 [==============================] - 12s 165ms/step - loss: 0.6558\n","Epoch 5/5\n","73/73 [==============================] - 12s 159ms/step - loss: 0.5836\n","2021-03-13 14:40:07.259854: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_171876\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 104ms/step\n","2021-03-13 14:40:11.145306: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_175526\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Collected words+weights saved to /tmp/visualization-context3/fold8.json\n","Evaluating after 8 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       718       300      1018\n","     delta       277       777      1054\n","     [sum]       995      1077      2072\n","Accuracy: 0.7215 (95ppCI: 0.0193)  Macro F1: 0.7214\n","ah: P=0.7216/R=0.7053/F1=0.7134 delta: P=0.7214/R=0.7372/F1=0.7292\n","Running fold 9/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model_16\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_8 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_8[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:40:17.970102: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_182861\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 20s 158ms/step - loss: 2.1359\n","Epoch 2/5\n","73/73 [==============================] - 12s 161ms/step - loss: 0.6531\n","Epoch 3/5\n","73/73 [==============================] - 12s 164ms/step - loss: 0.6358\n","Epoch 4/5\n","73/73 [==============================] - 11s 157ms/step - loss: 0.6392\n","Epoch 5/5\n","73/73 [==============================] - 11s 153ms/step - loss: 0.5807\n","2021-03-13 14:41:24.102215: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_194266\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","9/9 [==============================] - 4s 82ms/step\n","2021-03-13 14:41:27.733636: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_197916\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Collected words+weights saved to /tmp/visualization-context3/fold9.json\n","Evaluating after 9 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       827       327      1154\n","     delta       325       852      1177\n","     [sum]      1152      1179      2331\n","Accuracy: 0.7203 (95ppCI: 0.0182)  Macro F1: 0.7203\n","ah: P=0.7179/R=0.7166/F1=0.7173 delta: P=0.7226/R=0.7239/F1=0.7233\n","Running fold 10/10\n","Max length in training data:  4753\n","Embeddings shape: (100004, 300)\n","Model: \"model_18\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_sequence (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embeddings (Embedding)          (None, None, 300)    30001200    input_sequence[0][0]             \n","__________________________________________________________________________________________________\n","BiLSTM (Bidirectional)          (None, None, 128)    186880      embeddings[0][0]                 \n","__________________________________________________________________________________________________\n","tanh_Ws1_HT (Dense)             (None, None, 300)    38400       BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","A_matrix (Dense)                (None, None, 50)     15000       tanh_Ws1_HT[0][0]                \n","__________________________________________________________________________________________________\n","A_softmax (Lambda)              (None, None, 50)     0           A_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","M_matrix (Lambda)               (None, 50, 128)      0           A_softmax[0][0]                  \n","                                                                 BiLSTM[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_9 (Flatten)             (None, 6400)         0           M_matrix[0][0]                   \n","__________________________________________________________________________________________________\n","Output_dense (Dense)            (None, 2)            12802       flatten_9[0][0]                  \n","==================================================================================================\n","Total params: 30,254,282\n","Trainable params: 253,082\n","Non-trainable params: 30,001,200\n","__________________________________________________________________________________________________\n","Model compiled\n","2021-03-13 14:41:34.039943: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_205251\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Epoch 1/5\n","73/73 [==============================] - 19s 154ms/step - loss: 1.6998\n","Epoch 2/5\n","73/73 [==============================] - 12s 160ms/step - loss: 0.6179\n","Epoch 3/5\n","73/73 [==============================] - 12s 164ms/step - loss: 0.6255\n","Epoch 4/5\n","73/73 [==============================] - 11s 156ms/step - loss: 0.5878\n","Epoch 5/5\n","73/73 [==============================] - 12s 163ms/step - loss: 0.5712\n","2021-03-13 14:42:40.968149: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_216656\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","8/8 [==============================] - 3s 91ms/step\n","2021-03-13 14:42:44.583144: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n","op: \"FlatMapDataset\"\n","input: \"PrefetchDataset/_8\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_slice_batch_indices_220305\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_INT64\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","Collected words+weights saved to /tmp/visualization-context3/fold10.json\n","Evaluating after 10 folds\n","↓gold pr.→        ah     delta     [sum]\n","        ah       932       359      1291\n","     delta       365       926      1291\n","     [sum]      1297      1285      2582\n","Accuracy: 0.7196 (95ppCI: 0.0173)  Macro F1: 0.7196\n","ah: P=0.7186/R=0.7219/F1=0.7202 delta: P=0.7206/R=0.7173/F1=0.7189\n","Final evaluation; reader.input_path_train was data/sampled-threads-ah-delta-context3\n","↓gold pr.→        ah     delta     [sum]\n","        ah       932       359      1291\n","     delta       365       926      1291\n","     [sum]      1297      1285      2582\n","Accuracy: 0.7196 (95ppCI: 0.0173)  Macro F1: 0.7196\n","ah: P=0.7186/R=0.7219/F1=0.7202 delta: P=0.7206/R=0.7173/F1=0.7189\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"UfGbpEH262w2"},"source":[""],"execution_count":null,"outputs":[]}]}